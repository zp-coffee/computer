# 操作系统概述

## 操作系统的概念

*   计算机系统从下往上分为：硬件，操作系统，应用程序，用户
    *   **硬件：**提供基本的计算资源，如中央处理器，内存，输入/输出设备
    *   **操作系统：**管理各种计算机硬件，为应用程序提供基础，并充当计算机硬件与用户之间的中介
    *   **应用程序：**规定按何种方式使用这些资源来解决用户的计算问题，如字处理程序，电子制表软件，编译器，网络浏览器
*   **操作系统(Operating System，OS)：**指**控制和管理**整个计算机系统的**硬件和软件资源**，合理地**组织，调度**计算机的**工作与资源的分配**，进而**为客户和其他软件**提供**方便接口与环境的程序集合**
*   操作系统是计算机系统中最基本的系统软件



### 操作系统的特征

*   操作系统的基本特征包括**并发，共享，虚拟，异步**
*   **并发：**
    *   并发是指**两个或多个事件在同一时间间隔内发生**
    *   操作系统的并发性通过分时得以实现
    *   并发指的是一段时间间隔内多个程序交替执行，每个时刻实际上只有一个程序在执行
*   **共享：**
    *   共享即资源共享，指系统中的资源可供内存中多个并发执行的进程共同使用，可分为**互斥共享方式和同时共享方式**
    *   互斥：同一个资源同一时间只有一个访问者可以进行访问，其他访问者需要等前一个访问者访问结束才可以开始访问该资源，但互斥无法限制访问者对资源的访问顺序，即访问是无序的
    *   同步：分布在不同进程之间的若干程序片断，它们的运行必须严格按照规定的某种先后次序来运行，这种先后次序依赖于要完成的特定的任务，所以同步就是在互斥的基础上，通过其它机制实现访问者对资源的有序访问
*   **虚拟：**
    *   虚拟是指把一个物理上的实体变为若干逻辑上的对应物，可分为**时分复用技术和空分复用技术**
    *   **虚拟处理器技术**是通过多道程序设计技术，采用让多道程序并发执行的方法，来分时使用一个处理器达到多个处理器的效果
    *   可以使用**虚拟存储器技术**将一台机器的物理存储器变为虚拟存储器，达到从逻辑上扩充存储器的容量
    *   可以使用**虚拟设备技术**将一台物理I/O设备虚拟成多台逻辑上的I/O设备，并允许每个用户占用一条逻辑上的I/O设备
*   **异步：**
    *   异步是指当一个任务在执行时，系统不会等待它执行完成，而是直接执行下一个任务，可以让系统更有效率地利用资源，但不保证任务的执行顺序



### 操作系统的功能

*   操作系统的功能可分为：管理计算机系统资源，作为用户和计算机硬件系统之间的接口，实现对计算机资源的扩充
*   **管理计算机系统资源**分为：处理机管理，存储器管理，设备管理，文件管理
    *   处理机管理：在多道程序环境下，处理机的分配和运行都以进程(或线程)为基本单位，对处理机的管理可归结为对进程的管理
        *   目的：处理**进程何时创建，何时撤销，如何管理，如何避免冲突，合理共享**的问题
        *   功能：进程控制，进程同步，进程通信，死锁处理，处理机调度
    *   存储器管理：
        *   目的：给多道程序的运行提供良好的环境，方便用户使用及提高内存的利用率
        *   功能：内存分配与回收，地址映射，内存保护与共享，内存扩充
    *   文件管理：
        *   操作系统中负责文件管理的部分称为文件系统
        *   功能：文件存储空间的管理，目录管理，文件读写管理和保护
    *   设备管理：
        *   目的：完成用户的I/O请求，方便用户使用各种设备，并提高设备的利用率
        *   功能：缓冲管理，设备分配，设备处理，虚拟设备
*   **用户和计算机硬件系统之间的接口分为：**命令接口，程序接口
    *   命令接口进行作业控制的方式有两类：联机控制方式，脱机控制方式
    *   命令接口按照控制方式的不同可分为：联机命令接口和脱机命令接口
        *   **联机命令接口：**又称交互式命令接口，适用于分时或实时系统的接口
            *   由一组键盘操作命令组成
            *   用户通过**控制台或终端**输入操作命令，向系统提出各种服务要求，控制权就从控制台或终端转移到操作系统的**命令解释程序**，然后由命令解释程序解释并执行输入的命令，完成指定的功能，之后控制权转回到控制台或终端
        *   **脱机命令接口：**批处理命令接口，适用于批处理系统，由一组作业控制命令组成
            *   脱机用户事先用相应的作业控制命令写出一份作业操作说明书，连同作业一起提交给系统，系统调度到该作业时，由系统中的命令解释程序逐条解释执行作业说明书上的命令
    *   程序接口：由一组系统调用组成
        *   用户通过在程序中使用这些系统调用来请求操作系统为其提供服务，比如图形用户界面(GUI)，即图形接口，GUI最终通过调用程序接口来实现
*   **扩充计算机资源：**
    *   没有任何软件支持的计算机称为**裸机**
    *   覆盖了软件的机器称为**扩充机器或虚拟机**





### 习题

*   源程序是一种计算机代码，是用应用程序设计语言编写的程序，经编译或解释后可形成具有一定功能的可执行文件，是直接面向用户的，不是操作系统的管理内容
*   系统调用是操作系统为应用程序使用内核功能所提供的接口
*   广义指令就是系统调用命令，命令解释器属于命令接口，shell是命令解释器，系统中的缓存全部由操作系统管理，操作系统不提供管理系统缓存的系统调用
*   多道程序设计没有封闭性和顺序性，**顺序性**是单道程序设计的基本特性
*   库函数属于用户程序而非系统调用，是系统调用的上层
*   计算机开机后，操作系统的程序会被自动加载到内存中的系统区，属于**RAM**
*   在多道程序系统中，进程数量越多，进程之间的资源竞争越激烈，可能因为资源竞争出现死锁现象，导致CPU利用率低
*   库函数与系统调用的区别：
    *   库函数是语言或应用程序的一部分，可以运行在用户空间中，许多库函数使用系统调用来实现功能，未使用系统调用的库函数的执行效率通常比系统调用高，因为使用系统调用需要上下文的切换及状态的转换(由用户态转向核心态)
    *   系统调用是操作系统的一部分，是内核为用户提供的程序接口，运行在内核空间中







## 操作系统发展历程

*   早期存在的主要问题：**人机矛盾和CPU与I/O之间速度不匹配**



### 单道批处理系统

*   单道批处理系统的特点：
    *   自动性：在顺利的情况下，作业自动完成
    *   顺序性：作业顺序进入内存，作业顺序完成
    *   单道性：内存中仅有一道程序运行
*   在运行期间发出输入/输出请求后，高速的CPU要等待低速的I/O完成，为了进一步提高资源的利用率和系统的吞吐量，提出多道程序技术



### 多道批处理系统

*   多道程序设计技术允许多个程序同时进入内存并允许他们在CPU中交替地进行，这些程序共享系统中的各种硬/软件资源
*   多道程序设计的特点：
    *   多道：内存中同时存放多道相互独立的程序
    *   宏观上并行：同时进入系统的多道程序都处于运行过程
    *   微观上串行：内存中的程序轮流占用CPU
*   多道程序设计技术解决的问题：
    *   如何分配处理器
    *   多道程序的内存分配问题
    *   I/O设备如何分配
    *   如何组织和存放大量的程序和数据，以方便用户使用并保证其安全性和一致性
*   批处理系统中采用多道程序设计技术就形成了**多道批处理系统**
*   优点：
    *   资源利用率高
    *   系统吞吐量大
*   缺点：
    *   用户响应的时间长
    *   不提供人机交互能力



### 分时操作系统

*   为了解决人机交互问题，提出分时操作系统
*   分时技术：把处理器的运行时间分成很短的时间片，按时间片轮流把处理器分配给各联机作业使用
*   分时操作系统：多个用户通过终端同时共享一台主机而互不干扰
*   分时系统是实现人机交互的系统，具有与批处理系统不同的特征：
    *   同时性：也称多路性，指允许多个终端用户同时使用一台计算机
    *   交互性：用户通过终端采用人机对话的方式直接控制程序运行
    *   独立性：系统中多个用户之间独立操作互不干扰
    *   及时性：用户请求能在很短的时间内获得响应
*   但是在一些场合，需要系统能对外部的信息在规定时间内(短于时间片)完成，所以出现了实时操作系统



### 实时操作系统

*   实时操作系统分为**硬实时系统和软实时系统**
*   硬实时操作系统**必须**使任务在确定的时间内完成
*   软实时操作系统能让**绝大多数任务**在确定的时间内完成
*   特点：及时性和可靠性
*   实时操作系统追求的是最小的中断延时和线程切换延时



### 网络操作系统和分布式计算机系统

*   网络操作系统：把计算机网络中的计算机有机地结合起来，提供一种统一，经济而有效的使用各台计算机的方法，实现各台计算机之间数据的相互传送
*   网络操作系统的特点：网络中的各种资源的共享及各台计算机之间的通信
*   分布式计算机系统：
    *   系统中任意两台计算机通过通信方式交换信息
    *   系统中的每台计算机都具有同等的地位，没有主机和从机
    *   每台计算机上的资源为所有用户共享
    *   系统中的任意一台计算机都可以构成一个子系统，并且还能重构
    *   任何工作都可以分布在几台计算机上，由它们并行工作，协同完成
*   分布式计算机系统的特点：分布性和并行性
*   分布式操作系统和网络操作系统的不同：分布式操作系统中的若干计算机相互协同完成同一个任务



### 个人计算机操作系统

*   个人计算机操作系统是目前使用最广泛的操作系统，应用于文字处理，电子表格，游戏
*   常见的有Windows，Linux，MacOS，嵌入式操作系统，服务器操作系统，智能手机操作系统



### 习题

*   多道程序设计没有封闭性和顺序性，具有断续性，制约性，共享性
*   多道批处理系统的I/O设备可与CPU并行工作借助于中断技术的实现







## 操作系统运行环境

### 处理器运行模式

*   CPU中运行两种程序：操作系统内核程序，用户自编程序(应用程序)
*   操作系统内核程序中执行**特权指令**，用户自编程序中执行**非特权指令**
*   特权指令：指不允许用户直接使用的指令，如I/O指令，置中断指令，存取用于内存保护的寄存器，送程序状态字到程序状态字寄存器的指令
*   非特权指令：指允许用户直接使用的指令，不能直接访问系统中的软硬件资源，仅限于访问用户的地址空间
*   CPU的运行模式分为：用户态(目态)，内核态(管态)
*   应用程序向操作系统请求服务时通过使用访管指令，从而产生一个中断事件将操作系统转换为内核态
*   操作系统的内核分为：
    *   最底层的时钟管理，中断处理，设备驱动模块
    *   运行频率较高的程序，如进程管理，存储器管理，设备管理

*   大多数操作系统的内核包括四个内容：
    *   **时钟管理**：负责计时，向用户提供系统时间，另外实现进程切换
    *   **中断机制**：只有一小部分功能属于内核，负责保护和恢复中断现场的信息，转移控制权到相关的处理程序，减少中断的处理时间，提高系统的并行处理能力
    *   **原语**：系统中的设备驱动，CPU切换，进程通信中的部分操作
        *   处于操作系统的最底层，是最接近硬件的部分
        *   这些程序的运行具有原子性，操作必须不间断执行完，关闭中断，使所有动作不可分割地完成后打开中断
        *   这些程序的运行时间都较短，而且频繁调用
    *   **系统控制的数据结构及处理：**如作业控制块，进程控制块(PCB)，设备控制块，链表，消息队列，缓冲区，空闲区登记表
        *   进程管理：进程状态管理，进程调度，分派，创建和撤销进程控制块
        *   存储器管理：存储器的空间分配和回收，内存信息保护程序，代码对换程序
        *   设备管理：缓冲区管理，设备分配和回收



### 中断和异常

*   通过中断和异常，从用户态进入内核态，通过硬件实现
*   中断(Interruption)：也称外中断，指来自CPU执行指令外部的事件，通常用于信息输入/输出
    *   可屏蔽中断INTR：通过INTR线发出的中断请求，通过改变屏蔽字可以实现多重中断
    *   不可屏蔽中断NMI：通过NMI线发出的中断请求，通常是紧急的硬件故障
*   异常(Exception)：也称内中断，指来自CPU执行指令内部的事件，如程序的非法操作码，地址越界，运算溢出，虚存系统的缺页和专门的陷入指令，不能屏蔽，出现就要处理
    *   故障Fault：指令执行引起的异常，如非法操作码，缺页故障，除数为0，运算溢出
    *   自陷Trap：一种事先安排的“异常”事件，用于在用户态下调用操作系统内核程序，如条件陷阱指令
    *   终止Abort：出现了使CPU无法继续执行的硬件故障，如控制器出错，存储器校验错
*   故障异常和自陷异常属于软件中断(程序性异常)，终止异常和外部中断属于硬件中断



### 系统调用

*   系统调用：指用户在程序中调用操作系统提供的一些子功能
*   系统调用按功能可分为：
    *   设备管理：完成设备的请求或释放，以及设备启动等功能
    *   文件管理：完成文件的读，写，创建及删除等功能
    *   进程控制：完成进程的创建，撤销，阻塞及唤醒等功能
    *   进程通信：完成进程之间的消息传递或信号传递等功能
    *   内存管理：完成内存的分配，回收以及获取作业占用内存区大小及始址等功能
*   系统调用的处理需要由操作系统内核程序来完成，运行在内核态，用户程序可以执行**陷入指令(访管指令或trap指令)**来发起系统调用
*   操作系统的运行环境：
    *   用户通过操作系统运行上层程序
    *   上层程序的运行依赖于操作系统的底层管理程序提供服务支持
        *   当上层程序需要管理程序服务时，系统通过硬件中断机制进入内核态，运行管理程序
        *   或上层程序运行时出现异常情况，被动地需要管理程序的服务，通过异常处理来进入内核态
    *   管理程序执行结束后，用户程序需要继续执行，通过保存相应的程序现场退出中断处理程序或异常处理程序，返回断点继续执行
*   由用户态转换成内核态的例子：
    *   用户程序要求操作系统的服务，即系统调用
    *   发生一次中断
    *   用户程序中产生了一个错误状态
    *   用户程序中企图执行一条特权指令
    *   从内核态向用户态由一条特权指令实现，一般是中断返回指令
*   在用户态进入内核态时，不仅状态发生切换，所用的堆栈也需要由用户堆栈切换为系统堆栈，这个系统堆栈也属于该进程
*   程序由用户态转换为内核态使用**访管指令**，在用户态下使用，所以不是特权指令



### 习题

*   通用操作系统使用时间片轮转调度算法
*   操作系统执行程序时，必须从起始地址开始执行
*   编译器是操作系统的上层软件，不是操作系统需要提供的功能
*   批处理操作系统的主要缺点是**缺少交互性**
*   输入/输出指令需要中断操作，中断必须在核心态下执行，所以输入/输出指令工作在核心态
*   多道性是为了提高系统利用率和吞吐量而提出的
*   I/O通道实际上是一种特殊的处理器，具有执行I/O指令的能力，并通过执行通道程序来控制I/O操作

*   中断是操作系统必须提供的功能，计算机的各种错误和核心态到用户态到转换都需要中断处理
*   内核可以执行处理能执行的任何指令，用户程序只能执行除特权指令外的指令
*   时钟管理中使用硬件计数器保持时钟的运行
*   进程调度由调度算法决定CPU使用权，由操作系统实现，不需要硬件的支持
*   计算机通过硬件完成操作系统由用户态到核心态的转换，通过中断机制来实现的
*   运行操作系统代码的状态为核心态
*   广义指令又称系统调用命令，只能工作在核心态
*   调用广义指令的那条指令不一定是特权指令，但广义指令存在于核心态中，执行也在核心态
*   子程序调用只需保存程序断点，即该指令的下一条指令的地址
*   中断处理不仅要保存断点(PC程序计数器)，还要保存程序状态字寄存器(PSW)
*   当CPU检测到中断后，由硬件自动保存被中断程序的断点(程序计数器PC和程序状态字寄存器PSW)，而通用寄存器内容由操作系统来保存
*   执行系统调用的过程：
    *   正在运行的进程先传递系统调用参数
    *   由陷入(Trap)指令负责将用户态转换为内核态
    *   将返回地址压入堆栈中
    *   CPU执行相应的内核态服务程序
    *   返回用户态

*   时钟中断的主要工作是处理和时间有关的信息及决定是否执行调度程序
*   操作系统不同，底层逻辑，实现方式都不同，为应用程序提供的系统调用接口也不同
*   通道技术和中断技术结合起来可实现CPU和I/O设备并行工作
    *   即CPU启动通道传输数据后便去执行其他程序的计算工作，而通道则进行输入/输出操作
    *   当通道工作结束时，再通过中断机构向CPU发出中断请求，CPU则暂停正在执行的操作，对出现的中断进行处理，处理完后再继续原来的工作



## 操作系统结构

### 分层法

*   **分层法：**是将操作系统分为若干层，最底层为硬件，最高层为用户接口，每层只能调用紧邻它的低层的功能和服务
*   优点：
    *   便于系统的调试和验证，简化了系统的设计和实现
    *   易扩充和易维护，在系统中增加，修改或替换一层中的模块或整层时，只要不改变响应层间的接口，就不影响其他层
*   缺点：
    *   合理定义各层比较困难
    *   效率较差，执行一个功能需要穿过多层，增加了开销



### 模块化

*   **模块化：**是将操作系统按功能划分为若干具有一定独立性的模块，各模块之间能够通过接口进行通信
*   模块太小：降低模块本身的复杂性，但使模块之间的联系过多，造成系统比较混乱
*   模块过大：增加模块内部的复杂性，但是模块之间的联系变少
*   衡量模块的独立性的标准：
    *   内聚性：模块内部各部分间联系的紧密程度，内聚性越高，模块独立性越好
    *   耦合性；模块间相互联系和相互影响的程度，耦合度越低，模块独立性越好
*   优点：
    *   提高了操作系统设计的正确性，可理解性和可维护性
    *   增强了操作系统的可适应性
    *   加速了操作系统的开发过程
*   缺点：
    *   模块间的接口规定很难满足对接口的实际需求



### 宏内核

*   从操作系统的内核架构来分：宏内核和微内核
*   **宏内核**，也称大内核或单内核，是指将系统的主要模块都作为一个紧密联系的整体运行在**内核态**，从而为用户程序提供高性能的系统服务
*   各管理模块之间共享信息，能有效利用相互之间的有效特性

*   目前的桌面操作系统：Windows，Android，IOS，macOS，Linux都是基于宏内核的构架



### 微内核

*   **微内核构架：**是指内核中最基本的功能保留在内核，而将那些不需要在内核态执行的功能移到用户态，从而降低内核的设计复杂性
*   那些在用户态运行的操作系统代码根据分层的原则被划分为若干服务程序
*   微内核结构将操作系统划分为：微内核和多个服务器
    *   微内核是指能实现操作系统最基本核心功能的小型内核，包括：
        *   与硬件处理紧密相关的部分
        *   一些较基本的功能
        *   客户和服务器之间的通信
    *   微内核外的服务器实现大多数的功能：(作为进程实现，工作在用户态，用户和服务器间借助微内核的消息传递机制来进行交互)
        *   提供对进程进行管理的进程服务器
        *   提供虚拟存储器管理功能的虚拟存储器服务器

*   微内核的功能：
    *   **进程(线程)管理：**进程或线程之间的通信功能是微内核OS最基本的功能，还有进程切换，进程调度，多处理机之间的同步
    *   **低级存储器管理：**微内核中只配置最基本的低级存储器管理机制，如用于实现将逻辑地址变换为物理地址等的页表机制和地址变换机制，都是依赖于硬件的部分
    *   **中断和陷入处理：**捕获所发生的中断和陷入事件，并进行中断响应处理，识别事件后再发送给相关的服务器处理
*   微内核结构通常利用“机制与策略分离”的原理来构造OS结构，所以一般与硬件紧密联系的部分放入微内核，有关软件，算法的部分放在外部服务器中
*   微内核的特点：
    *   **扩展性和灵活性**，许多功能在内核外部，方便扩展和修改
    *   **可靠性和安全性**，一个模块的错误只会使模块崩溃而不会使整个系统崩溃
    *   **可移植性**，CPU和I/O硬件的代码放在内核中，而服务器的实现与硬件无关，方便移植
    *   **分布式计算**，客户和服务器之间，服务器与服务器之间的通信采用消息传递机制
*   缺点：
    *   性能问题，需要在内核态和用户态之间不断进行切换，导致开销增大
*   应用：
    *   实时，工业，航空及军事应用，都需要有高度的可靠性



### 外核

*   外核在内核态中运行，为虚拟机分配资源，检查使用这些资源的企图，以确保没有机器会使用他人的资源
*   优点：
    *   减少了映射层
    *   将多道程序与用户操作系统代码分离







## 操作系统加载过程

*   操作系统是一种程序，程序以数据的形式存放在硬盘中，而硬盘中通常分为多个区，并且一个计算机有多个或多种外部存储设备

*   怎么在正确的存储设备中加载正确的分区从而启动操作系统？

*   **操作系统引导：**是指计算机利用CPU运行特定程序，通过程序识别硬盘，再识别硬盘分区，再识别硬盘分区上的操作系统，最后通过程序启动操作系统

*   常见的操作系统引导过程：

    *   **激活CPU：**激活的CPU读取ROM中的boot程序，将指令寄存器置为BIOS(基本输入/输出系统)的第一条指令，即开始执行BIOS的指令，BIOS是存储在计算机主板上的固件firmware
    *   **硬件自检：**启动BIOS程序后，BIOS先进行硬件自检，检查硬件是否出现故障
        *   有故障：主板发出不同含义的蜂鸣，启动中止
        *   无故障：屏幕显示CPU，内存，硬盘
    *   **加载带有操作系统的硬盘：**硬件自检后，BIOS开始读取Boot Sequence(通过CMOS保存的启动顺序)，把控制权交给启动顺序排在第一位的引导设备(硬盘，固态硬盘，光盘)
    *   **加载主引导记录MBR：**BIOS确定引导设备后开始读取MBR，MBR是一个特殊的扇区，位于硬盘的第一个扇区（通常是第0扇区），其中包含引导加载程序。引导加载程序负责加载操作系统的核心部分
    *   **扫描硬盘分区表，并加载硬盘活动分区：**MBR包含硬盘分区表，标识**活动分区和非活动分区**，MBR扫描硬盘分区表，识别含有操作系统的硬盘分区(活动分区)，之后开始加载硬盘活动分区，将控制权交给活动分区
    *   **加载分区引导记录PBR：**读取活动分区的第一个扇区，称为分区引导记录(PBR)，寻找并激活分区根目录下用于引导操作系统的程序(启动管理器)
    *   **加载启动管理器：**分区引导记录搜索活动分区中的启动管理器，加载启动管理器
    *   **加载操作系统：**控制权就交给了操作系统，操作系统内核是操作系统的核心组件，负责管理系统的资源和提供各种服务，操作系统内核被加载后，它会进行一系列初始化步骤，包括初始化设备驱动程序、建立内存管理、设置进程控制块等。这些步骤确保操作系统能够有效地运行，并为用户提供一个稳定的环境

    *   **用户登录或图形界面启动：** 最终，操作系统会进入用户登录界面或直接启动图形用户界面（GUI），用户可以通过输入用户名和密码登录系统。



























## 虚拟机

*   虚拟机是一台逻辑计算机，是指利用特殊的虚拟化技术，通过隐藏特定计算平台的实际物理特性，为用户提供抽象的，统一的，模拟的计算环境
*   有两种虚拟方法：
    *   第一类虚拟机管理程序(裸金属架构)
    *   第二类虚拟机管理程序(寄居架构)



### 第一类虚拟机管理程序

*   在裸机上运行并且具有多道程序功能，向上层提供若干台虚拟机，这些虚拟机是裸机硬件的精准复制品，所以不同的虚拟机上可以运行任何不同的操作系统
*   虚拟机作为用户态的一个进程运行，虚拟机上的操作系统认为自己运行在内核态(实际上运行在用户态)，这种称为**虚拟内核态**
    *   当虚拟机操作系统执行一条特权指令时，会陷入虚拟机管理程序，虚拟机管理程序将正确执行
    *   而如果是由虚拟机上的应用程序执行了特权指令，虚拟机管理程序将模拟真实硬件面对用户态执行特权指令时的行为



![img](/Users/coffeeboy/Desktop/考研/assets/aa52922936584d21993e724b64dd621d-1432145.png)



### 第二类虚拟机管理程序

*   第二类虚拟机管理程序，依赖于Windows，Linux等操作系统分配和调度资源，像一个进程
*   运行在两种虚拟机管理程序上的操作系统称为**客户操作系统**
*   对于第二类虚拟机管理程序，运行在底层硬件上的操作系统称为**宿主操作系统**
*   VMware Workstation是首个X86平台上的第二类虚拟机管理程序



### 习题

*   微内核OS：
    *   内核足够小
    *   基于客户/服务器模式(C/S模式)
    *   应用**机制与策略分离**原理
    *   采用面向对象技术
*   采用微内核，因为处于用户态的程序交互都借助于微内核进行通信，影响了系统的效率，并没有提高系统的高校
*   内核的服务越少，内核越稳定，所以微内核比宏内核稳定
*   操作系统的内核部分加载到内存中，其他部分仅在需要时加载到内存中
*   操作系统的引导程序：
    *   在传统BIOS系统中，它通常在**硬盘的MBR**中
    *   在UEFI系统中，它位于**EFI系统分区的特定目录**下

*   虚拟机可以使用软件实现，也可以使用硬件实现，并没有实现并行，因为本质上还是应用程序





![虚拟内存管理](/Users/coffeeboy/Desktop/考研/assets/虚拟内存管理.png)



# 进程和线程

## 进程

*   **进程：**相当于一个任务，Task

*   进程的实体(也称进程映像)包括：

    *   程序段
    *   相关数据段
    *   PCB(进程控制块)

*   进程的基本特征：

    *   动态性：进程有着创建，运行，就绪，阻塞，终止等状态，具有一定的生命周期，是动态地产生，变化和消亡的
    *   并发性：多个进程在一段时间内同时运行
    *   独立性：一个进程是独立运行，独立获得资源，独立接受调度的
    *   异步性：由于进程间的相互制约，各进程间独立运行，间断运行，执行的顺序不可知

*   进程的状态：

    *   运行态：进程正在CPU上运行，在单核中，一个时刻只能有一个进程在运行
    *   就绪态：进程获得了除CPU外的所有需要的资源，放入就绪队列中，等待调度
    *   阻塞态：又称等待态，进程在等待某一个事件的发生或某个资源，放入阻塞队列中
    *   创建态：进程正在被创建，创建的过程中首先申请一个PCB，再向PCB中填写用于控制和管理进程的信息，然后为该进程分配运行所需要的资源，如果资源全部满足则进入就绪态，否则一直处于创建态
    *   终止态：进程正常结束或因其他原因退出运行，设置为终止态之后处理资源释放和回收的工作

*   进程状态间的切换：

    *   就绪态->运行态：处于就绪态的进程得到调度，获得CPU资源
    *   运行态->就绪态：处于运行态的进程时间片用完，或在抢占式操作系统中有更高优先级的进程就绪
    *   运行态->阻塞态：进程请求某一个资源的使用和分配或等待某一个事件的发生，进程以系统调用的方式请求操作系统提供服务
    *   阻塞态->就绪态：进程等待的事件到来，中断处理程序将进程的状态从阻塞态转为就绪态

    ![讲解Linux内核操作系统——进程状态与转换](/Users/coffeeboy/Desktop/考研/assets/v2-708cbe6dac0647dfe4940ada850566ab_1440w-1591115.png)

### 进程组成

*   进程的组成：

    *   PCB(进程控制块)
    *   程序段
    *   数据段

*   PCB用于保存处理机的状态信息，设置该进程恢复运行的现场，并根据PCB中的程序和数据的内存始址，找到其程序和数据

*   **PCB中主要包括：**

    *   进程描述信息
        *   进程标识符PID：标志各个进程，每个进程都有一个唯一的进程标识符
        *   用户标识符UID：进程归属的用户，主要为共享和保护服务
    *   进程控制和管理信息
        *   进程当前状态：描述进程的状态信息
        *   进程优先级：进程抢占CPU的优先级
        *   代码运行入口地址
        *   程序的外存地址
        *   进入内存时间
        *   处理机占用时间
        *   信号量使用
    *   资源分配清单
        *   代码段指针
        *   数据段指针
        *   堆栈段指针
        *   文件描述符
        *   键盘
        *   鼠标
    *   处理机相关信息
        *   通用寄存器值
        *   地址寄存器值
        *   控制寄存器值
        *   标志寄存器值
        *   状态字

*   **程序段：**

    *   能被CPU执行的程序代码
    *   程序可被多个进程共享，即多个进程可运行同一个程序

*   **数据段：**

    *   进程运行过程中的数据变量

*   **FreeRtos中的PCB：**(FreeRtos中以任务为基本单位，类似于传统操作系统中的线程，并没有进程，这里使用FreeRtos来进行理解)

    ```c
    /*
     * Task control block.  A task control block (TCB) is allocated for each task,
     * and stores task state information, including a pointer to the task's context
     * (the task's run time environment, including register values)
     * 任务状态，任务上下文，任务运行环境，寄存器的值
     */
    typedef struct tskTaskControlBlock       /* The old naming convention is used to prevent breaking kernel aware debuggers. */
    {
        volatile StackType_t * pxTopOfStack; /*< Points to the location of the last item placed on the tasks stack.  THIS MUST BE THE FIRST MEMBER OF THE TCB STRUCT. */堆栈指针，栈顶，栈用来保存局部变量和任务相关的信息
    
        ListItem_t xStateListItem;    /*< The list that the state list item of a task is reference from denotes the state of that task (Ready, Blocked, Suspended ). */保存任务状态的双向链表
        
        ListItem_t xEventListItem;    /*< Used to reference a task from an event list. */保存事件的链表
        
        UBaseType_t uxPriority;       /*< The priority of the task.  0 is the lowest priority. */优先级
        
        StackType_t * pxStack;        /*< Points to the start of the stack. */栈尾
        
        char pcTaskName[ configMAX_TASK_NAME_LEN ]; /*< Descriptive name given to the task when created.  Facilitates debugging only. */ /*lint !e971 Unqualified char types are allowed for strings and single characters only. */任务名字
    
        ......         /*还有许多条件编译*/
    } tskTCB;
    ```

    



### 进程控制

*   进程控制主要对系统中的所有进程实施有效的管理，具有创建新进程，撤销已有进程，实现进程状态转换的功能
*   进程控制的程序段称为**原语**，原语在执行过程中不允许中断，是一个不可分割的基本单元
*   **进程创建：**
    *   允许一个进程创建另一个进程，创建者称为父进程，被创建的进程称为子进程
    *   子进程可以继承父进程的所有资源，子进程被撤销时，将资源全部归还给父进程，撤销父进程时，同时撤销所有子进程
    *   创建一个新进程的过程：(创建原语)
        *   为新进程分配一个唯一的进程标识号，并申请一个空白PCB，若PCB申请失败，则创建失败
        *   为进程分配其运行所需的资源，如内存，文件，I/O设备和CPU时间，如果资源不足，则一直处于创建态等待资源
        *   初始化PCB，包括初始化标志信息，初始化处理机状态信息，初始化处理机控制信息，设置进程的优先级
        *   若进程就绪队列能接纳新进程，则将新进程插入就绪队列，等待被调度执行

```c
BaseType_t xTaskCreate( TaskFunction_t pxTaskCode,                 指向任务函数
                        const char * const pcName,                 任务的名称
                        const configSTACK_DEPTH_TYPE usStackDepth, 堆栈大小
                        void * const pvParameters,                 传入参数
                        UBaseType_t uxPriority,                    任务优先级
                        TaskHandle_t * const pxCreatedTask )       任务句柄，也就是指向tcb的指针
{
    TCB_t * pxNewTCB;   //创建TCB
    BaseType_t xReturn; //设置函数返回值从而判断是否创建成功

    /* If the stack grows down then allocate the stack then the TCB so the stack does not grow into the TCB.  Likewise if the stack grows up then allocate the TCB then the stack. */
    向下增长(低地址向高地址)则先分配堆栈再分配TCB，向上增长则先分配TCB再分配堆栈
    #if ( portSTACK_GROWTH > 0 ) 判断堆栈增长方向
    {
        /* Allocate space for the TCB.  Where the memory comes from depends on
         * the implementation of the port malloc function and whether or not static
         * allocation is being used. */
        pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) );  //为TCB分配内存大小

        if( pxNewTCB != NULL ) //创建成功
        {
            memset( ( void * ) pxNewTCB, 0x00, sizeof( TCB_t ) );  //清0

            /* Allocate space for the stack used by the task being created.
             * The base of the stack memory stored in the TCB so the task can
             * be deleted later if required. */
            pxNewTCB->pxStack = ( StackType_t * ) pvPortMallocStack( ( ( ( size_t ) usStackDepth ) * sizeof( StackType_t ) ) );  //分配堆栈空间 
            /*lint !e961 MISRA exception as the casts are only redundant for some ports. */

            if( pxNewTCB->pxStack == NULL ) //分配堆栈失败则删除TCB
            {
                /* Could not allocate the stack.  Delete the allocated TCB. */
                vPortFree( pxNewTCB );
                pxNewTCB = NULL;
            }
        }
    }
    #else /* portSTACK_GROWTH */
    {
        StackType_t * pxStack;

        /* Allocate space for the stack used by the task being created. */
        pxStack = pvPortMallocStack( ( ( ( size_t ) usStackDepth ) * sizeof( StackType_t ) ) ); /*lint !e9079 All values returned by pvPortMalloc() have at least the alignment required by the MCU's stack and this allocation is the stack. */

        if( pxStack != NULL )
        {
            /* Allocate space for the TCB. */
            pxNewTCB = ( TCB_t * ) pvPortMalloc( sizeof( TCB_t ) ); /*lint !e9087 !e9079 All values returned by pvPortMalloc() have at least the alignment required by the MCU's stack, and the first member of TCB_t is always a pointer to the task's stack. */

            if( pxNewTCB != NULL )
            {
                memset( ( void * ) pxNewTCB, 0x00, sizeof( TCB_t ) );

                /* Store the stack location in the TCB. */
                pxNewTCB->pxStack = pxStack;
            }
            else
            {
                /* The stack cannot be used as the TCB was not created.  Free
                 * it again. */
                vPortFreeStack( pxStack );
            }
        }
        else
        {
            pxNewTCB = NULL;
        }
    }
    #endif /* portSTACK_GROWTH */

    if( pxNewTCB != NULL )  //创建成功
    {
        #if ( tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE != 0 ) //判断是动态分配还是静态分配
        {
            /* Tasks can be created statically or dynamically, so note this
             * task was created dynamically in case it is later deleted. */
            pxNewTCB->ucStaticallyAllocated = tskDYNAMICALLY_ALLOCATED_STACK_AND_TCB;
        }
        #endif /* tskSTATIC_AND_DYNAMIC_ALLOCATION_POSSIBLE */

        prvInitialiseNewTask( pxTaskCode, pcName, ( uint32_t ) usStackDepth, pvParameters, uxPriority, pxCreatedTask, pxNewTCB, NULL ); //实际创建函数
        prvAddNewTaskToReadyList( pxNewTCB ); //将TCB放入就绪链表中
        xReturn = pdPASS;
    }
    else
    {
        xReturn = errCOULD_NOT_ALLOCATE_REQUIRED_MEMORY;
    }

    return xReturn;
}
```

*   **进程终止：**
    *   引起进程终止的事件：
        *   正常结束：进程完成
        *   异常结束：进程运行时发生了某种异常事件，比如存储区越界，保护错，非法指令，特权指令错，运行超时，算术运算错
        *   外界干预：进程响应外界的请求终止运行
    *   进程终止的过程：
        *   根据被终止进程的标识符，检索出该进程的PCB，从中读出该进程的状态
        *   若被终止进程处于运行态，立即终止运行，将CPU分配给其他进程
        *   若该进程有子进程，则将子进程也同时终止
        *   将该进程所拥有的全部资源，还给父进程或还给操作系统
        *   将该PCB从所在队列(链表)中删除

```c
void vTaskDelete( TaskHandle_t xTaskToDelete )
{
    TCB_t * pxTCB;

    taskENTER_CRITICAL(); 进入临界区
    {
        /* If null is passed in here then it is the calling task that is
         * being deleted. */
        pxTCB = prvGetTCBFromHandle( xTaskToDelete );  获取被删除任务的TCB

        /* Remove task from the ready/delayed list. */ uxListRemove将任务从就绪/等待链表中移除
        if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
        {
            taskRESET_READY_PRIORITY( pxTCB->uxPriority );  清除相应的就绪标志位
        }
        else
        {
            mtCOVERAGE_TEST_MARKER();
        }

        /* Is the task waiting on an event also? */ 或将任务从阻塞链表中移除
        if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
        {
            ( void ) uxListRemove( &( pxTCB->xEventListItem ) );
        }
        else
        {
            mtCOVERAGE_TEST_MARKER();
        }

        /* Increment the uxTaskNumber also so kernel aware debuggers can
         * detect that the task lists need re-generating.  This is done before
         * portPRE_TASK_DELETE_HOOK() as in the Windows port that macro will
         * not return. */
        uxTaskNumber++;

        if( pxTCB == pxCurrentTCB )   这个任务是当前正在运行的任务
        {
            /* A task is deleting itself.  This cannot complete within the
             * task itself, as a context switch to another task is required.
             * Place the task in the termination list.  The idle task will
             * check the termination list and free up any memory allocated by
             * the scheduler for the TCB and stack of the deleted task. */
            vListInsertEnd( &xTasksWaitingTermination, &( pxTCB->xStateListItem ) );  将该任务加入删除链表中

            /* Increment the ucTasksDeleted variable so the idle task knows
             * there is a task that has been deleted and that it should therefore
             * check the xTasksWaitingTermination list. */
            ++uxDeletedTasksWaitingCleanUp;

            /* Call the delete hook before portPRE_TASK_DELETE_HOOK() as
             * portPRE_TASK_DELETE_HOOK() does not return in the Win32 port. */
            traceTASK_DELETE( pxTCB );   任务删除后的跟踪函数，用户自己实现，可用于获取被删除任务的信息

            /* The pre-delete hook is primarily for the Windows simulator,
             * in which Windows specific clean up operations are performed,
             * after which it is not possible to yield away from this task -
             * hence xYieldPending is used to latch that a context switch is
             * required. */
            portPRE_TASK_DELETE_HOOK( pxTCB, &xYieldPending );
        }
        else
        {
            --uxCurrentNumberOfTasks;
            traceTASK_DELETE( pxTCB );

            /* Reset the next expected unblock time in case it referred to
             * the task that has just been deleted. */
            prvResetNextTaskUnblockTime();
        }
    }
    taskEXIT_CRITICAL();  退出临界区

    /* If the task is not deleting itself, call prvDeleteTCB from outside of
     * critical section. If a task deletes itself, prvDeleteTCB is called
     * from prvCheckTasksWaitingTermination which is called from Idle task. */
    if( pxTCB != pxCurrentTCB )   删除的任务不是自身，则在临界区外将其删除
    {
        prvDeleteTCB( pxTCB );
    }

    /* Force a reschedule if it is the currently running task that has just
     * been deleted. */
    if( xSchedulerRunning != pdFALSE )
    {
        if( pxTCB == pxCurrentTCB )
        {
            configASSERT( uxSchedulerSuspended == 0 );
            portYIELD_WITHIN_API();   因为正在运行的任务被删除，需要立即进行调度
        }
        else
        {
            mtCOVERAGE_TEST_MARKER();
        }
    }
}
```



*   **进程阻塞和唤醒：**

    *   运行态的进程，请求系统资源失败，等待某种操作的完成，新数据尚未到达，无新任务可做，进程则通过调用阻塞原语(Block)使自己从运行态变为阻塞态，**只有运行态的进程才能转为阻塞态**
    *   进程阻塞的过程：
        *   找到将要被阻塞进程的标识符对应的PCB
        *   若该进程为运行态，则保护现场，将其状态转为阻塞态，停止运行
        *   把该PCB插入相应事件的等待队列，将处理机资源调度给其他就绪进程

    ```c
    void vTaskSuspend( TaskHandle_t xTaskToSuspend )
    {
        TCB_t * pxTCB;
    
        taskENTER_CRITICAL();    进入临界区
        {
            /* If null is passed in here then it is the running task that is
             * being suspended. */
            pxTCB = prvGetTCBFromHandle( xTaskToSuspend );   从队列中获取被阻塞的任务的TCB
    
            traceTASK_SUSPEND( pxTCB );  将任务阻塞
    
            /* Remove task from the ready/delayed list and place in the
             * suspended list. */  将任务从就绪/等待链表中移除并且放入阻塞链表中
            if( uxListRemove( &( pxTCB->xStateListItem ) ) == ( UBaseType_t ) 0 )
            {
                taskRESET_READY_PRIORITY( pxTCB->uxPriority );
            }
            else
            {
                mtCOVERAGE_TEST_MARKER();
            }
    
            /* Is the task waiting on an event also? */ 如果任务在等待事件，则将其从事件列表中移除
            if( listLIST_ITEM_CONTAINER( &( pxTCB->xEventListItem ) ) != NULL )
            {
                ( void ) uxListRemove( &( pxTCB->xEventListItem ) );
            }
            else
            {
                mtCOVERAGE_TEST_MARKER();
            }
    
            vListInsertEnd( &xSuspendedTaskList, &( pxTCB->xStateListItem ) );  将任务插入到阻塞链表中
    
            #if ( configUSE_TASK_NOTIFICATIONS == 1 )
            {
                BaseType_t x;
                如果任务在等待通知，则将通知状态清除
                for( x = 0; x < configTASK_NOTIFICATION_ARRAY_ENTRIES; x++ )
                {
                    if( pxTCB->ucNotifyState[ x ] == taskWAITING_NOTIFICATION )
                    {
                        /* The task was blocked to wait for a notification, but is
                         * now suspended, so no notification was received. */
                        pxTCB->ucNotifyState[ x ] = taskNOT_WAITING_NOTIFICATION;
                    }
                }
            }
            #endif /* if ( configUSE_TASK_NOTIFICATIONS == 1 ) */
        }
        taskEXIT_CRITICAL();
    
        if( xSchedulerRunning != pdFALSE )
        {
            /* Reset the next expected unblock time in case it referred to the
             * task that is now in the Suspended state. */
            taskENTER_CRITICAL();
            {
                prvResetNextTaskUnblockTime();
            }
            taskEXIT_CRITICAL();
        }
        else
        {
            mtCOVERAGE_TEST_MARKER();
        }
    
        if( pxTCB == pxCurrentTCB )
        {
            if( xSchedulerRunning != pdFALSE )
            {
                /* The current task has just been suspended. */
                configASSERT( uxSchedulerSuspended == 0 );
                portYIELD_WITHIN_API();
            }
            else
            {
                /* The scheduler is not running, but the task that was pointed
                 * to by pxCurrentTCB has just been suspended and pxCurrentTCB
                 * must be adjusted to point to a different task. */
                if( listCURRENT_LIST_LENGTH( &xSuspendedTaskList ) == uxCurrentNumberOfTasks ) /*lint !e931 Right has no side effect, just volatile. */
                {
                    /* No other tasks are ready, so set pxCurrentTCB back to
                     * NULL so when the next task is created pxCurrentTCB will
                     * be set to point to it no matter what its relative priority
                     * is. */
                    pxCurrentTCB = NULL;
                }
                else
                {
                    vTaskSwitchContext();
                }
            }
        }
        else
        {
            mtCOVERAGE_TEST_MARKER();
        }
    }
    ```

    

    *   当被阻塞的进程等待的资源或事件到来时，由**其他进程**调用唤醒原语(Wakeup)将该进程唤醒
        *   在该事件的等待队列中找到相应进程的PCB
        *   将其从阻塞态转为就绪态
        *   等待调度程序调度

```c
void vTaskResume( TaskHandle_t xTaskToResume )
{
    TCB_t * const pxTCB = xTaskToResume;

    /* It does not make sense to resume the calling task. */
    configASSERT( xTaskToResume );

    /* The parameter cannot be NULL as it is impossible to resume the
     * currently executing task. */
    if( ( pxTCB != pxCurrentTCB ) && ( pxTCB != NULL ) )
    {
        taskENTER_CRITICAL();
        {	检查任务是否被阻塞
            if( prvTaskIsTaskSuspended( pxTCB ) != pdFALSE )
            {
                traceTASK_RESUME( pxTCB );    唤醒任务

                /* The ready list can be accessed even if the scheduler is
                 * suspended because this is inside a critical section. */
                ( void ) uxListRemove( &( pxTCB->xStateListItem ) );
                prvAddTaskToReadyList( pxTCB ); 移除任务的阻塞状态，加入就绪链表中

                /* A higher priority task may have just been resumed. */
                if( pxTCB->uxPriority >= pxCurrentTCB->uxPriority ) 
                {     如果被唤醒的任务的优先级更高，则进行任务调度
                    /* This yield may not cause the task just resumed to run,
                     * but will leave the lists in the correct state for the
                     * next yield. */
                    taskYIELD_IF_USING_PREEMPTION();
                }
                else
                {
                    mtCOVERAGE_TEST_MARKER();
                }
            }
            else
            {
                mtCOVERAGE_TEST_MARKER();
            }
        }
        taskEXIT_CRITICAL();
    }
    else
    {
        mtCOVERAGE_TEST_MARKER();
    }
}
```



### 进程通信

*   进程通信是指进程之间的信息交换

    *   低级通信方式有：PV操作
    *   高级通信方式有：以较高速率传输大量数据的通信方式
        *   共享存储
        *   消息传递
        *   管道通信

*   **共享存储：**

    *   通信的两个进程之间存在一块可直接访问的共享空间

    *   共享存储又可分为基于数据结构的低级共享方式和基于存储区的高级共享方式

    *   操作系统只负责为通信进程提供可共享使用的存储空间和同步互斥工具，数据交换由用户自己安排读/写指令完成

        ![0](/Users/coffeeboy/Desktop/考研/assets/1680081-20230821195320748-858414710-1604829.png)

*   **消息传递：**

    *   进程间的数据交换以格式化的信息(Message)为单位
    *   利用操作系统提供的消息传递方式来实现，即通过系统提供的**发送信息和接受信息**两个原语进行数据交换
    *   **直接通信方式：**
        *   发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中取消息
    *   **间接通信方式：**
        *   发送进程把消息发送到某个中间实体，如**信箱**，接收进程从中间实体中取消息

*   **管道通信：**

    *   发送进程往管道的一端写，接收进程从管道的一端读
    *   数据在管道中是先进先出
    *   只要管道非空，读进程就能从管道中读出数据，若管道为空，则读进程阻塞，直到写进程往管道中写数据
    *   只要管道非满，写进程就能往管道中写入数据，若管道为满， 则写进程阻塞，知道读进程从管道中读数据
    *   管道机制必须提供三方面的协调能力：同步，互斥，确定对方的存在
    *   Linux中的管道是一种特殊的文件，能克服使用文件的两个问题：
        *   限制管道的大小
        *   读进程也可能工作得比写进程快
    *   管道只能由创建进程所访问，子进程可以通过父进程创建的管道来与父进程进行通信
    *   普通管道只允许单向通信，若要双向通信则需要两个管道



## 线程

*   引入进程的目的是使多道程序并发执行，提高资源利用率和系统吞吐量
*   引入线程的目的是减小程序在并发执行时所付出的时空开销，提高操作系统的并发性能
*   线程是进程中的一个实体，由**线程ID，程序计数器，寄存器集合，堆栈**组成
*   线程与同属一个进程中的其他线程共享进程所拥有的全部资源
*   一个进程中有多个线程，线程的切换发生在同一个进程内部，只需要很少的时空开销
*   进程和线程的区别：
    *   **定义：**
        -   进程是程序在执行过程中的一个实例。它是计算机中运行的程序的一个独立执行单元，有自己的地址空间、内存、文件描述符、以及其他系统资源
        -   线程是进程内的一个独立执行流。一个进程可以包含多个线程，它们共享进程的地址空间和系统资源
    *   **资源分配：**
        -   进程拥有独立的资源，如内存空间、文件句柄等。进程之间的通信需要使用进程间通信（Inter-Process Communication，IPC）机制
        -   线程共享进程的资源，包括地址空间、文件描述符等。线程之间可以通过共享内存等方式进行通信
    *   **创建和销毁：**
        -   进程的创建和销毁相对较慢，因为需要为其分配和释放独立的资源
        -   线程的创建和销毁相对较快，因为它们共享进程的资源，无需分配独立的内存空间
    *   **独立性：**
        -   进程是相对独立的，一个进程的崩溃通常不会影响其他进程
        -   线程是进程的一部分，线程之间的错误可能会影响整个进程的稳定性
    *   **切换开销：**
        -   进程切换的开销较大，涉及到上下文切换，需要保存和恢复整个进程的状态
        -   线程切换的开销相对较小，因为线程共享相同的地址空间，上下文切换时只需保存和恢复寄存器等少量状态
    *   **通信方式：**
        -   进程间通信通常采用消息传递、管道、共享内存等方式
        -   线程间通信可以通过共享内存、互斥锁、信号量等机制实现
    *   **适用场景：**
        -   进程适用于需要独立执行、相对独立的任务，例如运行一个应用程序
        -   线程适用于需要共享数据和相互协作的任务，例如图形界面应用程序
*   **线程的特点：**
    *   不同进程之间可以并发执行，一个进程中的多个线程也能并发执行，甚至不同进程中的线程也能并发执行
    *   支持多处理机系统，进程只能运行在一个CPU上，但对于多线程进程，可以将进程中的多个线程分配到多个CPU上
    *   每个线程都有唯一的标识符和一个线程控制块，线程控制块记录了线程执行的寄存器和栈等现场状态
    *   不同的线程可以执行相同的程序，即同一个服务程序被不同的用户调用时，操作系统把它们创建成不同的线程
    *   同一个进程中的所有线程共享该进程所拥有的资源
    *   在单核系统中，各线程可交替使用CPU，在多核系统中，各线程可同时占用了不同的CPU
*   **线程也具有三种基本状态：**
    *   执行状态
    *   就绪状态
    *   阻塞状态
*   **线程控制块：TCB**
    *   线程标识符
    *   一组寄存器，包括程序计数器，状态寄存器，通用寄存器
    *   线程运行状态，用于描述线程正处于何种状态
    *   优先级
    *   线程专用存储区，线程切换时用于保存现场
    *   堆栈指针，用于过程调用时保存局部变量和返回地址
*   同一个进程中的所有线程都完全共享进程中的地址空间和全局变量，各个线程都可以访问进程地址空间的每个单元，所以一个线程可以读，写或清除另一个线程的堆栈
*   **线程的终止：**
    *   线程被终止后并不立即释放它所占用的资源，只有当进程中的其他线程执行了分离函数后，被终止线程才与资源分离，此时的资源才能被其他线程利用
    *   被终止但未释放资源的线程仍可被其他线程调用，以使被终止线程重新恢复执行
*   **线程的实现方式：**用户级线程，内核级线程和组合方式
    *   用户级线程(User-Level Thread,ULT)
        *   有关线程管理的工作都由应用程序在用户空间中完成，应用程序通过使用线程库设计成多线程程序
        *   优点：
            *   线程切换不需要转换到内核空间，节省了模式切换的开销
            *   调度算法可以是进程专用的，不同的进程可根据自身的需要，对自己的线程选择不同的调度算法
            *   用户级线程的实现与操作系统平台无关，对线程管理的代码是属于用户程序的一部分
        *   缺点：
            *   系统调用的阻塞问题，当线程执行一个系统调用时，不仅该线程被阻塞，而且进程内的所有线程都被阻塞
            *   不能发挥多处理机的优势，内核每次分配给一个进程的仅有一个CPU，因此进程中仅有一个线程能执行
    *   内核级线程(Kernel-Level Thread,KLT)
        *   线程管理的所有工作都在内核空间中实现
        *   优点：
            *   能发挥多处理机的优势，内核能同时调度统一进程中的多个线程并行执行
            *   如果进程中的一个线程被阻塞，内核可以调度该进程中的其他线程占用处理机，也可以运行其他进程中的线程
            *   内核支持线程具有很小的数据结构和堆栈，线程切换比较快，开销小
            *   内核本身也可以采用多线程技术，可以提高系统的执行速度和小路
        *   缺点：
            *   同一个进程中的线程切换，需要从用户态转到内核态中进行，系统开销较大，因为用户进程的线程在用户态运行，而线程调度和管理在内核态中进行
    *   组合方式
        *   内核支持多个内核级线程的建立，调度和管理，同时允许用户程序建立，调度和管理用户级线程
        *   一些内核级线程对应多个用户级线程，这是用户级线程通过**时分多路复用**内核级线程实现的
        *   同一个进程中的多个线程可以同时在多处理机上并行运行，且阻塞一个线程时不需要将整个进程阻塞
*   **线程库：**为程序员提供创建和管理线程的API，实现方法有两种：
    *   在用户空间中提供一个没有内核支持的库，这种库的所有数据结构和代码都位于用户空间中
    *   由操作系统直接支持的内核级的一个库，库内的代码和数据结构都位于内核空间中，调用库会导致对内核的系统调用
*   目前有三种线程库：POSIX Pthreads，Windows API，Java
    *   POSIX Pthreads作为POSIX标准的扩展，可以提供用户级或内核级的库
    *   Windows API是用于Windosw系统的内核级线程库
    *   Java线程API允许线程在Java程序中直接创建和管理
*   **多线程模型：**
    *   多对一模型：将多个用户级线程映射到一个内核级线程，线程的调度和管理在用户空间中完成
        *   优点：线程管理是在用户空间中进行，因而效率比较高
        *   缺点：如果一个线程在访问内核时发生阻塞，则整个进程都被阻塞，任何时刻只有一个线程能访问内核，多个线程不能同时在多个处理机上运行
    *   一对一模型：将每个用户级线程映射到一个内核级线程上
        *   优点：当一个线程被阻塞后，允许调度到另一个线程运行，并发能力强
        *   缺点：没创建一个用户线程，就要创建一个内核线程，开销较大
    *   多对多模型：将n个用户线程映射到m个内核线程中，n大于等于m
        *   克服了上面两种的缺点又合并了优点



### 习题

*   进程获得CPU运行是通过调度得到的
*   操作系统是根据PCB(进程控制块)来对并发执行的进程进行控制和管理的
*   进程之间可能是无关的，也可能是有交互性的
*   PCB常驻内存中，进程的个数取决于内存的大小
*   打印机是独占资源同一时间只能有一个进程(线程)使用
*   I/O操作完成之前进程在等待结果，状态为阻塞态
*   I/O操作完成后进程等待的事件已经就绪，变为就绪态
*   程序封闭性是指进程执行的结果只取决于进程本身，不受外界的影响，进程的执行速度不会改变进程的执行结果
*   高级语言编写的程序在使用内存时分为三个段：
    *   正文段：存放二进制代码和常量
    *   数据堆段：动态分配的存储区
    *   数据栈段：临时使用的局部变量
*   进程的就绪数目越多，争夺CPU的进程就越多，但只要就绪队列不空，CPU就总是在执行，所以CPU的效率不会因为就绪进程的数目变化而变化
*   对进程的管理和控制功能是通过执行各种原语来实现的
*   使用一个线程来处理整个系统的键盘输入
*   全局变量是对同一进程而言的，在不同的进程中是不同的变量，没有联系，进程间不能通过全局变量来通信
*   **阻塞态进程等待的事件：**
    *   I/O完成：进程在进行输入/输出操作时处于阻塞，等待数据的读取或写入完成
    *   等待信号：进程在等待接受一个信号被阻塞
    *   锁或互斥体：进程可能在试图获取一个已被其他进程占用的锁或互斥体时被阻塞
    *   条件变量：进程可能在等待某个条件变量为真时被阻塞
    *   消息队列或缓冲区非空：进程可能在等待消息队列中有新的消息或某个缓冲区不再为空时被阻塞
    *   定时器超时：进程可能在等待某个定时器超时时被阻塞
    *   子进程结束：父进程可能在等待子进程结束时被阻塞
    *   资源可用：进程可能在等待某个资源变为可用时被阻
*   **进程之间的通信方式：**
    *   **管道（Pipe）：**
        -   管道是一种半双工通信机制，通常用于具有亲缘关系的父子进程之间。管道有两种类型：匿名管道和命名管道。匿名管道只能在有亲缘关系的进程之间使用，而命名管道可以在没有亲缘关系的进程之间使用。
    *   **消息队列（Message Queue）：**
        -   消息队列是一种通过消息进行通信的机制，适用于不同进程之间的通信。进程可以向消息队列发送消息，另一个进程则可以从中接收。消息队列允许异步通信，发送和接收进程之间的关系相对松散。
    *   **信号量（Semaphore）：**
        -   信号量是一种用于控制对共享资源的访问的同步机制。进程可以通过信号量来进行互斥访问，避免对共享资源的竞争。信号量可用于进程同步和进程互斥。
    *   **共享内存（Shared Memory）：**
        -   共享内存允许多个进程共享同一块内存区域。进程可以通过在共享内存中写入和读取数据来进行通信。共享内存通常是最快速的 IPC 方法之一，但需要谨慎处理同步和互斥问题。
    *   **套接字（Socket）：**
        -   套接字是一种用于在不同主机或同一主机上的不同进程之间进行通信的机制。套接字可以用于实现网络通信，也可以用于本地进程间通信。套接字通常用于 TCP 或 UDP 协议。
    *   **文件映射（File Mapping）：**
        -   文件映射允许一个或多个进程将同一个文件映射到它们的地址空间中，从而实现共享内存的效果。进程可以通过在文件映射中写入和读取数据来进行通信。
    *   **消息传递（Message Passing）：**
        -   消息传递是一种通过发送和接收消息进行通信的机制。进程可以通过消息传递来进行异步通信，其中消息的发送和接收是独立的。
    *   **信号（Signal）：**
        -   信号是一种进程间通信的简单方式，用于通知接收进程发生了某个事件。信号通常用于处理异步事件，例如进程的终止或某个条件的发生。
*   内核级线程的程序实体可以在内核态运行
*   **导致创建进程的事件：**
    *   **程序启动：** 
        *   当用户或系统启动一个程序时，操作系统需要创建一个新的进程来执行该程序。这是最常见的创建进程的事件之一。
    *   **系统初始化：** 
        *   在操作系统启动时，通常会创建一些初始化进程，用于执行系统初始化和设置任务。这些进程在系统启动时就被创建。
    *   **用户登录：** 
        *   当用户通过登录认证成功登录到计算机系统时，操作系统通常会创建一个新的进程以支持用户的会话。
    *   **后台任务启动：** 
        *   当系统需要执行一些后台任务，如定时任务、系统维护任务等，操作系统可能会创建相应的进程来执行这些任务。
    *   **处理外部事件：** 
        *   操作系统可能在响应外部事件时创建新的进程，例如硬件中断、网络数据到达等。
    *   **程序调用其他程序：** 
        *   一个程序在执行过程中调用了另一个程序，可能会导致创建新的进程来执行被调用的程序。这种情况通常发生在进程间通信和协作的场景中。
    *   **并行处理：** 
        *   在需要并行处理任务的情况下，操作系统可能会创建多个进程以充分利用多核处理器的性能。
    *   **服务请求：**
        *   当系统接收到服务请求时，例如网络请求、文件系统请求等，操作系统可能会创建新的进程来处理这些请求。
    *   **用户交互：** 
        *   当用户在图形用户界面（GUI）中启动应用程序、打开文件等操作时，操作系统可能会创建新的进程来处理用户请求。

*   进程是资源分配的基本单位，线程是处理机调度的基本单位
*   进程的代码段，进程打开的文件，进程的全局变量等都是进程的资源，只有进程中某线程的栈指针(包含在TCB中)属于线程
*   属于进程的资源线程之间可以共享，但是属于线程的栈指针是独享的，其他线程无法访问
*   管道是一种固定大小的缓冲区，管道的大小通常为内存的一页
*   多对一线程模型中，操作系统可能并不为每一个用户级线程建立一个TCB，而是映射到同一个内核级线程中共享同一个TCB
*   父进程可与子进程共享一部分资源，但不共享虚拟地址空间，创建子进程时为子进程分配虚拟地址空间
*   临界资源一次只能为一个进程所用
*   每个进程有自己独立的地址空间，在操作系统和硬件的地址保护机制下，进程无法访问其他进程的地址空间，必须借助于系统调用函数实现进程之间的通信



## 调度

### 概念

*   **CPU调度：**从就绪队列中按照一定的算法选择一个进程并将处理机分配给它运行来实现进程并发地执行

*   **调度的层次：**

    *   高级调度(作业调度)：从外存中处于后备队列中的作业挑选一个或多个，给它们分配内存，输入/输出设备等必要的资源，建立相应的进程，也就是**创建进程并将进程加入就绪队列中**，常用于多道批处理系统中，其他系统通常不需要
    *   中级调度(内存调度)：主要为了提高内存利用率和系统吞吐量，将那些暂时不能运行的进程调至外存等待，此时进程的状态称为挂起态，当它们具备运行条件且内存有空闲时再重新调入内存的就绪队列中，也就是**将暂时不能运行的进程挂起，能运行再加入到就绪队列中**
    *   低级调度(进程调度)：从就绪队列中选取一个进程，将CPU分配给它，也就是**将就绪队列中的一个进程切换为运行态**

*   **三级调度的关系：**

    *   作业调度为进程活动做准备，进程调度使进程正常活动起来
    *   中级调度将暂时不能运行的进程挂起，中级调度处于作业调度和进程调度之间
    *   作业调度次数最少，中级调度次数略多，进程调度频率最高
    *   进程调度是最基本的，不可或缺的

*   **调度的性能标准：**

    *   CPU利用率：

        *   $cpu的利用率=\frac{cpu有效工作时间}{cpu有效工作时间+cpu空闲等待时间}$

    *   系统吞吐量：

        *   表示单位时间内CPU完成作业的数量
        *   长作业需要消耗较长的处理机时间，降低系统的吞吐量
        *   短作业需要消耗较短的处理机时间，提高系统的吞吐量

    *   周转时间：

        *   从作业提交到作业完成所经历的时间，$周转时间=作业等待时间+在就绪队列中排队时间+处理机上运行时间+输入/输出操作所花费时间$

            ​		 $=作业完成时间-作业提交时间$

        *   平均周转时间 = 所有作业的周转时间/作业数量

        *   $带权周转时间 = \frac{作业周转时间}{作业实际运行时间}$

        *   平均带权周转时间 = 所有作业周转时间/作业数量

    *   等待时间：

        *   进程处于等处理机的时间之和，等待时间越长，用户满意度越低，**衡量调度算法的优劣只需看等待时间**

    *   响应时间：

        *   从用户提交请求到系统首次产生响应所用的时间，在交互式系统中，一般采用响应时间作为衡量调度算法的准则



### 调度的实现

*   用于调度和分派CPU的组件称为**调度程序**，通常由三部分组成：排队器，分派器，上下文切换器
    *   排队器：
        *   将系统中的所有就绪进程按照一定的策略排成一个或多个队列
    *   分派器：
        *   依据调度程序所选的进程将其从就绪队列中取出，分配CPU，切换为运行态
    *   上下文切换器：
        *   对CPU进行进程切换时，有两对上下文的切换操作
        *   第一对：将当前进程的上下文保存到其PCB中，再装入待运行程序的上下文，以便待运行程序运行
        *   第二对：移出运行程序的上下文，将所选进程的CPU现场信息装入处理机的各个对应寄存器
        *   现在采用两组寄存器，一组供内核使用，一组供用户使用，上下文切换时只需要改变指针

*   **不能进行调度的情况：**
    *   在处理中断的过程中
    *   进程在操作系统内核临界区中
    *   其他需要完全屏蔽中断的原子操作过程中
*   **应该进行进程调度和切换的情况：**
    *   发生引起调度条件且当前进程无法继续运行下去时，可以马上进行调度与切换，也就是非剥夺调度
    *   中断处理结束或自陷处理结束后，返回被中断进程的用户态程序执行现场前，若请求调度标志置一，则马上进行进程调度与切换，也就是剥夺调度
*   进程切换往往在调度后立刻发生，现场切换时，操作系统内核将原进程的现场信息推入内核堆栈中来保存它们，并更新堆栈指针，内核从新进程的内核栈中装入新进程的现场信息，更新当前运行进程空间指针，重设PC寄存器，开始新的进程
*   **进程调度方式：**
    *   非抢占调度方式，也称非剥夺方式，实现简单，系统开销小，适用于大多数的批处理系统，但不能用于分时系统和大多数的实时系统
    *   抢占调度方式，也称剥夺方式，允许调度程序根据某种原则去暂停正在执行的进程，将处理机分配给更为重要的进程，提高系统吞吐率和响应效率
*   **空闲进程：**
    *   进程切换时，就绪队列中没有进程则运行空闲进程，空闲进程的优先级最低，空闲进程不需要CPU之外的资源，不会被阻塞
*   **两种线程调度：**
    *   用户级线程调度：由进程中调度程序决定哪个线程执行
    *   内核级线程调度：内核对选中的线程赋予一个时间片，超过时间片，强制挂起该线程
    *   用户级线程切换在同一进程中进行，仅需少量的机器指令，内核级线程切换需要完成的上下文切换，修改内存映像，使高速缓存失效，导致延迟



### 调度算法

*   **先来先服务调度算法(FCFS)：**适用于作业调度和进程调度，选择**最先**进入队列的进程
    *   属于不可剥夺算法，不能作为分时系统或实时系统
    *   算法简单，效率低
    *   对长作业有利，对短作业不利
    *   有利于CPU繁忙型作业，不利于I/O繁忙型作业
*   **短作业优先调度算法(SJF)：**对短作业优先调度的算法，选择**运行时间最短**的进程
    *   对长作业不利，可能导致长作业饥饿
    *   不能保证紧迫性作业被及时处理
    *   作业多长短是根据用户所提供的估计执行时间而定
    *   SJF调度算法的平均等待时间和平均周转时间最少
*   **优先级调度算法：**适用于作业调度和进程调度，选择**优先级最高**的进程
    *   非抢占式优先级调度算法：即使更高优先级的进程就绪了也要等待现在的进程执行完毕
    *   抢占式优先级调度算法：有更高优先级的进程就绪立即暂停现在的进程转而让高优先级进程执行
    *   进程的优先级可分为：
        *   静态优先级：在创建进程时确定，取决于进程类型，进程对资源的要求，用户要求
        *   动态优先级：根据进程情况的变化动态调整优先级，取决于进程占用CPU时间的长短，就绪进程等待CPU时间的长短
    *   优先级的参考原则：
        *   系统进程>用户进程
        *   交互型进程>非交互型进程
        *   I/O型进程>计算型进程，I/O型进程指的是那些频繁使用I/O设备的进程，计算型进程指的是频繁使用CPU的进程(很少使用I/O设备)

*   **高响应比优先调度算法：**主要用于作业调度，是FCFS和SJF的平衡，选择**响应比最高**的进程，$响应比=\frac{已等待时间+要求服务时间}{要求服务时间}$
    *   作业的等待时间相同时，要求服务时间越短，响应比越高，有利于短作业
    *   要求服务时间相同时，作业的响应比由已等待时间决定，等待时间越长，响应比越高，类似于FCFS
    *   响应比随等待时间变大，有利于长作业
*   **时间片轮转调度算法：**适用于分时系统，按FCFS排列，每个进程分配一个时间片
    *   时间片过大使所有进程能在一个时间片中完成，则时间片轮转调度算法就变成FCFS
    *   时间片过小导致进程间频繁切换，使处理机的开销增大
    *   时间片取决于系统的响应时间，就绪队列中的进程数目和系统的处理能力
*   **多级队列调度算法：**
    *   设置多个就绪队列，不同类型或性质的进程固定分配到不同的就绪队列中
    *   每个队列实施不同的调度算法
    *   同一队列中的进程可以设置不同的优先级
    *   不同队列本身可以设置不同的优先级
*   **多级反馈队列调度算法：**结合了时间片轮转调度算法和优先级调度算法，动态调整**进程优先级和时间片大小**
    *   **算法思想：**
        *   设置多个就绪队列，每个队列的优先级不同，第一级队列的优先级最高
        *   每个队列的进程时间片不同，优先级越高，时间片越小
        *   每个队列采用FCFS，新进程都是从末尾插入，如果一个进程在一个时间片内不能完成，则插入下一级队列的末尾
        *   按队列优先级调度，只有前一级队列为空时才能执行本队列，如果在进程执行过程中高优先级队列中插入进程则立即暂停将正在执行的进程插入末尾再让高优先级的进程先执行
    *   **优点：**
        *   终端型作业用户：短作业优先
        *   短批处理作业用户：周转时间较短
        *   长批处理作业用户：经过前面队列的部分执行，不会长期得不到执行



### 进程切换

*   创建，撤销及要求由系统设备完成的I/O操作，都是利用系统调用进入内核，再由内核中的相应处理程序来完成的
*   **上下文切换：**切换CPU到另一个进程需要保存当前进程状态并恢复另一个进程的状态
*   上下文：某一个时刻CPU寄存器和程序计数器的内容
*   上下文切换的流程：
    *   挂起一个进程，保存CPU上下文，包括程序计数器和其他寄存器
    *   更新PCB信息
    *   把进程的PCB移入相应的队列，如就绪，在某事件阻塞等队列
    *   选择另一个进程执行，并更新其PCB
    *   跳转到新进程PCB中的程序计数器所指向的位置执行
    *   恢复处理机上下文
*   每次上下文切换都需要纳秒量级的时间，上下文切换对系统来说意味着消耗大量的CPU时间，有些处理器提供多个寄存器组，这样上下文切换就只需要简单改变当前寄存器组的指针
*   **模式切换：**用户态和内核态之间的切换，没有改变当前的进程
*   上下文切换只发生在内核态



### 习题

*   时间片轮转的主要目的：使多个交互的用户能够得到及时响应
*   时间片轮转增加了系统开销，吞吐量和周转时间都不如批处理
*   交互式系统为改善用户的响应时间大多数采用时间片轮转调度算法
*   CPU繁忙型作业需要使用很长时间CPU时间，类似于长作业，I/O型作业需要频繁请求I/O操作，CPU时间使用短，使用完成就要重新调度，类似于短作业
*   作业是从用户角度出发，由用户提交，以用户任务为单位
*   进程是从操作系统的角度出发，由系统生成，是操作系统的资源分配和独立运行的基本单位
*   分时系统中，响应时间与时间片和用户数成正比
*   中断向量：存放中断服务程序的入口地址
*   当进程处于临界区时，说明进程正在占用CPU，只要不破坏临界资源的使用规则，就不会影响CPU的调度，所以可以调度

*   计算响应比时注意$等待时间 = 调度的时刻 - 到达就绪队列的时刻$
*   响应比越高，优先级越高
*   具有两道作业的批处理系统代表能够将内存中能同时放入2个作业





![进程和现场](/Users/coffeeboy/Desktop/考研/assets/进程和现场-3764356.png)



# 同步与互斥

*   **临界资源：**一次仅允许一个进程使用的资源
*   **临界区：**进程中访问临界资源的那段代码
*   **临界资源的访问过程：**
    *   进入区：在进入区检查可否进入临界区，若能，则设置正在访问临界区的标志
    *   临界区：进程中访问临界资源的那段代码，也称临界段
    *   退出区：将正在访问临界区的标志清除
    *   剩余区：进程中代码的其他部分
*   **同步：**也称直接制约关系，指协调多个进程之间的**工作次序**而等待，传递信息所产生的制约关系
*   **同步遵循的准则：**
    *   空闲让进：临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区
    *   忙则等待：已有进程进入临界区后，其他请求进入的进程必须等待
    *   有限等待：对请求访问的进程，保证在有限时间内进入临界区
    *   让权等待：当进程不能进入临界区时，必须立即释放CPU，防止进程忙等待
*   **互斥：**也称间接制约关系，当一个进程进入临界区使用临界资源时，另一个进程必须等待，占用临界资源的进程退出临界区后，另一个进程才允许访问此临界资源



## 实现互斥的方法

*   **软件实现方法：Peterson's Algorithm**

```c
P1进程：                       					P2进程：
flag[i] = true; 								  flag[j] = true;
turn    = j;									  turn    = i;							   
while (flag[j] == true && turn == j){};			  while (flag[i] == true && turn == i){};  进入区
critical section;								  critical section;						   临界区
flag[i] = false;								  flag[j] = false;                         退出区
remainder section;								  remainder section						   剩余区
```

*   用`flag`来表示其他进程是否想要进入临界区，用`turn`来保证要想进入临界区必须对方的`flag`为false

*   **硬件实现方法：**

    *   中断屏蔽方法：CPU只在发生中断时引起进程切换，所以屏蔽中断能够保证当前运行的进程让临界区代码顺利执行完

        ```c
        taskENTER_CRITICAL();
        临界区代码；
        taskEXIT_CRITICAL();
        ```

        *   硬件方法限制了CPU交替执行程序的能力，执行的效率会明显降低

    *   硬件指令方法：

        *   TestAndSet指令：这条指令是原子操作，即执行该代码时不允许被中断，功能为读出指定标志并设置为true

            ```c
            bool TestAndSet (bool *lock)
            {
                bool old;
                old = *lock;
                *lock = true;
                return old;
            }
            ```

        *   为每个临界资源设置一个共享布尔变量lock，true表示正在被使用，进程进入临界区前先用TestAndSet检查

            ```c
            while (TestAndSet(&lock) == true){}
            临界区代码
            lock = false;
            剩余区代码
            ```

        *   Swap指令：交换两个字(或字节)的内容

            ```c
            void Swap(bool *a, bool *b)
            {
                bool temp;
                temp = *a;
                *a = *b;
                *b = temp;
            }
            ```

        *   为每个临界资源设置一个全局共享布尔变量lock，在每个进程中设置一个局部变量key，进入临界区前先利用Swap交换key与lock的值，然后在检查key的值

            ```c
            key = true;
            while(key == true)
            {
                Swap(&lock, &key);
            }
            临界区代码;
            lock = false;
            剩余区代码;
            ```

    *   **以上代码仅表示该硬件方法的实现思想，实际上是由硬件逻辑直接实现的，不会被中断**
    *   硬件方法的优点：
        *   适用于任意数目的进程，不管是单处理机还是多处理机
        *   简单，容易验证其正确性
        *   可以支持进程内有多个临界区，只需为每个临界区设置一个布尔变量
    *   硬件方法的缺点：
        *   进程等待进入临界区时要消耗CPU时间，不能实现**让权等待**
        *   从等待进程中随机选择一个进入临界区，有的进程可能导致“饥饿”现象

    

## 互斥锁

*   互斥锁通常使用**硬件机制**来实现，且获得锁和释放锁操作都是原子操作

*   互斥锁缺点：忙等待，常用于多处理器系统

    ```c
    acquire()
    {
        while (!available){};
        available = false;
    }
    
    release()
    {
        available = true;
    }
    ```

    

## 信号量

*   信号量可用来解决互斥和同步的问题，只能被两个标准的原语wait(S)和signal(S)访问，记为“P操作”和“V操作”

*   **整形信号量：**使用一个表示资源数目的整型量S

    ```c
    wait(S)
    {
        while(S<=0){};
        S = S - 1;
    }
    signal(S)
    {
        S = S + 1;
    }
    ```

*   只要S<=0，就会一直循环等待，不遵循“让权等待”的准则，而是使进程处于“忙等”的状态

*   **记录型信号量：**使用一个表示资源数量的整型变量value和一个进程链表L

    ```c
    typedef struct{
        int value;
        struct process *L;
    }semaphore;
    
    void wait(semaphore S)
    {
        S.value --;
        if (S.value < 0)             	 表示资源已分配完
        {
            add this process to S.L;     将进程放入等待队列
            block(S.L);                  进程自我阻塞
        }
    }
    
    void signal(semaphore S)
    {
        S.value ++;
        if (S.value <= 0)                表示有进程在等待
        {
            remove a process P from S.L; 将等待的进程移出等待队列
            wakeup(P);					 唤醒等待的进程
        }
    }
    ```

*   **利用信号量实现同步：**

    ```c
    semaphore S = 0;
    P1()
    {
        代码段X;
        V(S);   代码段X已经执行完成，可以进行下一步   
    }
    
    P2()
    {
        P(s);   请求信号量，等待X执行完再执行Y
        代码段Y;
    }
    ```

*   **利用信号量实现互斥：**

    ```c
    semaphore S = 1;
    P1()
    {
        其他代码;
        P(S);
        进程P1的临界区;
        V(S);
        其他代码;
    }
    
    P2()
    {
        其他代码;
        P(S);
        进程P2的临界区;
        V(S);
        其他代码;
    }
    ```

*   **利用信号量实现前驱关系：**比如S2和S3的进行需要S1完成，S4的进行需要S的完成

    ```c
    semaphore a1=a2=b1=0;
    S1()
    {
        其他代码;
        V(a1);
        V(a2);     S1完成释放a1和a2
    }
    
    S2()
    {
        其他代码；
        P(a1);     等待S1完成
    }
    
    S3()
    {
        其他代码;
        P(a2);     等待S1完成
        其他代码;
        V(b1);
    }
    
    S4()
    {
        其他代码;
        P(b1);     等待S2完成
        其他代码;
    }
    ```

*   **FreeRtos中实现的数据结构：**

    ```c
    typedef struct QueueDefinition 
    {
        int8_t * pcHead;           /*头指针*/
        int8_t * pcWriteTo;        /*尾指针*/
    
        union  					   /*联合，共享内存，可以用作队列，也可以用作信号量*/
        {
            QueuePointers_t xQueue;     
            SemaphoreData_t xSemaphore; 
        } u;
    
        List_t xTasksWaitingToSend;               /*一个链表用来存放等待往队列或信号量里放数据的阻塞的任务*/
        List_t xTasksWaitingToReceive;            /*一个链表用来存放等待往队列或信号量里读数据的阻塞的任务*/
    
        volatile UBaseType_t uxMessagesWaiting;   /*当前队列中的任务数量*/
        UBaseType_t uxLength;           		  /*能够存放的任务个数*/         
        UBaseType_t uxItemSize;                   /*存放任务的大小*/
    
        volatile int8_t cRxLock;                  /*互斥锁*/         
        /*< Stores the number of items received from the queue (removed from the queue) while the queue was locked.  Set to queueUNLOCKED when the queue is not locked. */
        volatile int8_t cTxLock;                  /*互斥锁*/
        /*< Stores the number of items transmitted to the queue (added to the queue) while the queue was locked.  Set to queueUNLOCKED when the queue is not locked. */
    } xQUEUE;
    ```

*   **FreeRtos中请求信号量(部分)P操作：**

    ```c
    taskENTER_CRITICAL();
    const UBaseType_t uxSemaphoreCount = pxQueue->uxMessagesWaiting;
    if( uxSemaphoreCount > ( UBaseType_t ) 0 )
    {
        traceQUEUE_RECEIVE( pxQueue );
    
        /* Semaphores are queues with a data size of zero and where the
         * messages waiting is the semaphore's count.  Reduce the count. */
        pxQueue->uxMessagesWaiting = uxSemaphoreCount - ( UBaseType_t ) 1;  //请求信号量
    
        #if ( configUSE_MUTEXES == 1 )
        {
            if( pxQueue->uxQueueType == queueQUEUE_IS_MUTEX )  //互斥
            {
                /* Record the information required to implement
                 * priority inheritance should it become necessary. */
                pxQueue->u.xSemaphore.xMutexHolder = pvTaskIncrementMutexHeldCount();
            }
            else
            {
                mtCOVERAGE_TEST_MARKER();
            }
        }
        #endif /* configUSE_MUTEXES */
    
        /* Check to see if other tasks are blocked waiting to give the 判断其他任务是否等待释放信号量而阻塞
         * semaphore, and if so, unblock the highest priority such task. */
        if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToSend ) ) == pdFALSE )
        {
            if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToSend ) ) != pdFALSE )
            {
                queueYIELD_IF_USING_PREEMPTION();
            }
            else
            {
                mtCOVERAGE_TEST_MARKER();
            }
        }
        else
        {
            mtCOVERAGE_TEST_MARKER();
        }
    
        taskEXIT_CRITICAL();
        return pdPASS;
    }
    taskEXIT_CRITICAL();
    ```

*   **FreeRtos中释放信号量(部分)V操作：**

    ```c
    taskENTER_CRITICAL();
    pxQueue->uxMessagesWaiting = uxMessagesWaiting + ( UBaseType_t ) 1;
    if( listLIST_IS_EMPTY( &( pxQueue->xTasksWaitingToReceive ) ) == pdFALSE )
    {
        if( xTaskRemoveFromEventList( &( pxQueue->xTasksWaitingToReceive ) ) != pdFALSE )
        {
            /* The unblocked task has a priority higher than
             * our own so yield immediately.  Yes it is ok to do
             * this from within the critical section - the kernel
             * takes care of that. */
            queueYIELD_IF_USING_PREEMPTION();
        }
        else
        {
            mtCOVERAGE_TEST_MARKER();
        }
    }
    else if( xYieldRequired != pdFALSE )
    {
        /* This path is a special case that will only get
         * executed if the task was holding multiple mutexes and
         * the mutexes were given back in an order that is
         * different to that in which they were taken. */
        queueYIELD_IF_USING_PREEMPTION();
    }
    else
    {
        mtCOVERAGE_TEST_MARKER();
    }
    taskEXIT_CRITICAL();
    ```



## 管程

*   信号量机制的缺点：进程自备同步操作，P(S)、V(S)操作大量分散在各个进程中，还要仔细安排P(S)的顺序，不易管理，易发生死锁

*   引入**管程**的目的：

    *   **把分散在各进程中的临界区集中起来进行管理**
    *   防止进程的非法同步操作
    *   便于利用高级语言来编程，便于验证程序正确性

*   管程相当于一个类，包含：

    *   **局部共享变量和条件变量**组成管程内的数据结构
    *   对数据结构进行操作的一组过程
    *   对数据结构进行初始化的语句
    *   一个互斥锁(由编译器添加)

    ```c
    monitor Demo  定义一个叫做Demo的管程
    {
        共享数据结构S；
        
        condition x;  一系列条件变量
        ......
            
        init_code()
        {
           S = 5; 对共享数据结构进行初始化
        }
        
        take_away()
        {
            对共享数据结构S的一系列处理;
            S--;
            if(x的资源不满足)
            {
                x.wait();   资源不满足，进入等待队列，让出管程
    		}
            其他代码;
    	}
        
        give_back()
        {
            对共享数据结构S的一系列处理;
            S++;
            if(有进程在等待条件变量x并且条件变量x满足){
                x.signal();   释放因条件变量x而阻塞的进程
            }
            其他代码;
        }
    }
    ```

*   管程内的共享数据结构只能被管程内的过程所访问

*   一个进程只有通过调用管程内的过程才能进程管程访问共享数据结构

*   每次仅允许一个进程进入管程，从而实现互斥

*   对于**条件变量：**
    *   当一个进程进入管程之后被阻塞，则如果该进程不释放管程会导致其他进程无法进入管程，所以需要使用条件变量来将阻塞的进程放入一个等待队列并释放管程
    *   将阻塞原因定义为条件变量condition，通常阻塞原因有多个，所以有多个条件变量
    *   每个条件变量都保存一个等待队列，用于记录因该条件变量而阻塞的所有进程
    *   对条件变量只能进行两种操作：wait和signal
    *   **x.wait：**当x对应的条件不满足进入阻塞前，调用x.wait将自己插入x条件变量的等待队列，并释放管程
    *   **x.signal：**x对应的条件发生变化，由其他进程调用x.signal唤醒一个因x条件而阻塞的进程



## 经典同步互斥问题

*   **生产者-消费者问题：**

    *   生产者和消费者共享一个大小为n的缓存区
    *   缓冲区不满生产者就能放入消息，缓冲区不空消费者就能读取消息
    *   同时只能有一个生产者或一个消费者使用缓冲区

    ```c
    semaphore mutex = 1;
    semaphore empty = n;
    semaphore full  = 0;
    
    producer()
    {
        while(1)
        {
            produce an item in nextp;
            p(empty);
            p(mutex);
            add nextp to buffer;
            V(mutex);
            V(full);
        }
    }
    
    consumer()
    {
        while(1)
        {
            P(full);
            P(mutex);
            remove an item from buffer;
            V(mutex);
            V(empty);
            consume the item;
        }
    }
    ```


*   **生产者消费者问题：**

    *   两个生产车间和一个装配车间，一个车间生产A，一个车间生产B
    *   两个车间每生产一个放在装配车间上的F1，F2装配线上，F1和F2上均可放10个(生产者和消费者共享大小为10的缓冲区)
    *   装配工人从F1和F2上分别取A和B装配成产品，不能同时放和取(同时只能有一个生产者或消费者访问缓冲区)

    ```c
    empty_A = 10; empty_B = 10; mutex_A = 1; mutex_B = 1; full_A = 0; full_B = 0;
    process A()         		process B()
    {							{
        while(1)					while(1)
        {							{
            P(empty_A);					P(empty_B);
            P(mutex_A);					P(mutex_B);
            将A放在F1上;		 		将B放在F2上;
            V(mutex_A);					V(mutex_B);
            V(full_A);					V(full_B); 
        }							}
    }							}
    
    compose()
    {
        while(1)
        {
            P(full_A);
            P(mutex_A);
            取A;
            V(mutex_A);
            V(empty_A);
            
            P(full_B);
            P(mutex_B);
            取B;
            V(mutex_B);
            V(empty_B);
            将A和B合成
        }
    }
    ```

*   **生产者消费者问题：**

    *   有若干小和尚和老和尚，小和尚负责从井里打水并放入水缸中，老和尚从水缸中取水喝
    *   共有三个桶，每次只能用一个桶从井里打水或从缸中打水，缸中一共能放10桶水

    ```c
    bucket = 3; empty_water = 10; full_water = 0; well = 1; water_tank = 1;
    young monk()
    {
        P(empty_water);
        P(bucket);
        P(well);
        从井里打水;
        V(well);
        P(water_tank);
        将水倒入缸中
        V(water_tank);
        V(bucket);
        V(full_water);
    }
    
    old monk()
    {
        P(full_water);
        P(bucket);
        P(well);
        从水缸里打水
        V(well);
        V(bucket);
        V(empty_water);
    }
    ```

*   **生产者消费者问题：(资源不限量，两个生产者互斥，一个缓冲区互斥)**

    *   有一条路，可以从北到南，从南到北，中间有一个桥，只允许一辆车通过
    *   允许同方向多辆车一起通过

    ```c
    int countN_S = 0; int countS_N = 0;
    semaphore mutexN_S = 1; semaphore mutexS_N = 1;
    semaphore bridge = 1;
    StoN()								NtoS()
    {									{
        P(mutexS_N);						P(mutexN_S);
        if(countS_N == 0)					if(countN_S == 0)
        {									{
            P(bridge);							P(bridge);
        }									}
        countS_N ++;						countN_S ++;
        V(mutexS_N);						V(mutexN_S);
        through the bridge;					through the bridge;
        P(mutexS_N);						P(mutexN_S);
        countS_N --;						countN_S --;
        if (countS_N == 0)					if (countN_S == 0)
        {									{
            V(bridge);							V(bridge);
        }									}
        V(mutexS_N);						V(mutexN_S);
    }									}
    ```

*   **生产者消费者问题：(两种资源有最大值)**

    *   自行车装配线上有一个箱子，里面有N个位置，每个位置可以放一个车架或一个车轮
    *   一共三名工人，第一个生产车架放进箱子里，第二个生产车轮放进箱子里，第三个拿一个车架和两个车轮装配
    *   要求不死锁

    ```c
    frame_max_num = N-2; wheel_max_num = N-1; frame = 0; wheel = 0; empty = N;
    worker1()										worker2()
    {												{
        while(1)										while(1)
        {												{
            produce a frame;								produce a wheel;
            P(frame_max_num);								P(wheel_max_num);
            P(empty);										P(empty);
            put the frame in the box;						put the whell in the box;
            V(frame);										V(wheel);
        }												}
    }												}
    worker3()
    {
        while(1)
        {
            P(frame);
            get a frame;
            V(empty);
            V(frame_max_num);
            
            P(wheel);
            P(wheel);
            get two wheels;
            V(empty);
            V(empty);
            V(wheel_max_num);
            V(wheel_max_num);
            compose a bike;
        }
    }
    ```

*   **生产者消费者问题：(即能当生产者又能当消费者)**

    ```c
    produce_consumer()
    {
        if (empty == 1)
        {
            P(empty);
            P(mutex);
            product one;
            V(mutex);
            V(full);
        }
        if (full == 1)
        {
            P(full);
            P(mutex);
            consume one;
            V(mutex);
            V(empty);
        }
    }
    ```












*   **生产者消费者问题2：**

    *   桌子上一个盘子，每次只能往其中放入一个水果
    *   爸爸放苹果，妈妈放橘子
    *   儿子等着吃盘子里的橘子，女儿等着吃盘子里的苹果
    *   只有盘子为空时，才能往盘子里放水果
    *   只有当盘子中有想要的水果时才从盘子中取出

    ```c
    semaphore plate = 1, apple = 0, orange = 0;
    dad()
    {
        while(1)
        {
            P(plate);
            put the apple on the plate;
            V(apple);
    	}
    }
    
    mom()
    {
        while(1)
        {
            P(plate);
            put the orange on the plate;
            V(orange);
    	}
    }
    
    son()
    {
        while(1)
        {
            P(orange);
            V(plate);
            eat the orange ;
    	}
    }
    
    daughter()
    {
        while(1)
        {
            P(apple);
            V(plate);
            eat the apple;
        }
    }
    ```

    

*   **读者写者问题：**

    *   读者和写者共享一个文件，允许多个读者读文件
    *   只允许一个写者写文件
    *   写者在写完前其他读者和写者不能进行读和写
    *   写者在写之前，其他的写者或读者应该退出

    ```c
    int count = 0;
    semaphore mutex = 1;
    semaphore rw = 1;
    semaphore w = 1;
    
    writer()
    {
        while (1)
        {
            P(w);
            p(rw);
            writing;
            V(rw);
            V(w);
        }
    }
    
    reader()
    {
        while(1)
        {
            P(w);           读者与写者之间的互斥
            P(mutex);       互斥访问count
            if (count == 0) 仅在第一次的时候请求rw
            {
                P(rw);      多个读者和写者之间的互斥
    		}
            count ++;
            V(mutex);
            V(w);
            reading;
            P(mutex);
            count --;
            if (count == 0)
            {
                V(rw);
            }
            V(mutex);
        }
    }
    ```

*   **同步问题：**

    *   现有三个进程P1，P2，P3，需要轮流输入数据a，b，c，然后进行计算，输入设备互斥使用
    *   P1:x=a+b; P2:y=a*b; P3:z=y+c-a;
    *   计算完后由P1进行打印

    ```c
    P1->P2->P3 设置三个信号量 S1 = 1; S2 = 0; S3 = 0;
    x需要b，设置s_b = 0，y需要a，设置s_a = 0，z需要y，设置s_y = 0; 打印需要z，设置s_z = 0;
    P1()
    {
        P(S1);
        write a;  写完再释放
        V(S2);
        P(s_b);
        x = a + b;
        P(s_z); z有代表y有
        printf x,y,z;
    }
    
    P2()
    {
        P(S2);
        write b;
        V(S3);
        V(s_b);
        y=a*b;
        V(s_y);
    }
    
    P3()
    {
        P(S3);
        write c;
        P(s_y);
        z = y + c - a;
        V(s_z);
    }
    ```

    

*   **哲学家进餐问题：**

    *   5个哲学家围着圆桌思考，每个哲学家左边和右边都有一个筷子

    *   当哲学家饿时才试图拿起左右两根筷子，如果左右都有则进行进餐，否则进行等待

    *   进餐完毕后放下筷子继续思考

        ![img](/Users/coffeeboy/Desktop/考研/assets/1012348-20170801224805396-1023500983.png)

    ```c
    semaphore chopstick[5] = {1,1,1,1,1}; 哲学家分别为0-4，哲学家i左边筷子的编号为i，右边为i+1
    Pi()
    {
        while(1)
        {
            P(chopstick[i]);     拿起左边筷子
            P(chopstick[i+1]%5); 拿起右边筷子
            eat;
            V(chopstick[i+1]%5);
            V(chopstick[i]);
            think;
        }
    }
    ```

    *   上述算法中，如果5位哲学家都想进餐并都执行到拿起左边筷子那一步，则会导致死锁
    *   加入一些限制条件：
        *   至多允许4位哲学家同时进餐
        *   仅当一位哲学家左右筷子都可用时才允许拿起筷子
        *   对哲学家进行编号，奇数的哲学家先拿左边的，偶数的哲学家先拿右边的
    *   对于第二种：

    ```c
    semaphore chopstick[5] = {1,1,1,1,1};
    semaphore mutex = 1;
    Pi()
    {
        while(1)
        {
            P(mutex);
            P(chopstick[i]);
            P(chopstick[i+1]%5);
            V(mutex);
            eat;
            V(chopstick[i+1]%5);
            V(chopstick[i]);
            think
        }
    }
    ```

*   **吸烟者问题：**

    *   三个抽烟者和一个供应者
    *   抽烟需要三种东西：烟草，卷纸，胶水
    *   供应者每次将两种材料放在桌子上，后面放另外两种，一直重复
    *   三个抽烟者都有不同的材料
    *   只有抽烟者抽完了供应者才能放材料

    ```c
    int num = 0;
    semaphore offer1 = 0;
    semaphore offer2 = 0;
    semaphore offer3 = 0;
    semaphore finish = 0;
    process P1()
    {
        while(1)
        {
            num ++;
            num = num%3;
            if (num == 0)
            {
                V(offer1);
    		}
            else if (num == 1)
            {
                V(offer2);
            }
            else
            {
                V(offer3);
            }
            P(finish);
        }
    }
    
    smoker1()
    {
        while(1)
        {
            P(offer1);
            smoking;
            V(finish);
        }
    }
    
    smoker2()
    {
        while(1)
        {
            P(offer2);
            smoking;
            V(finish);
        }
    }
    
    smoker3()
    {
        while(1)
        {
            P(offer3);
            smoking;
            V(finish);
        }
    }
    ```

*   **数量差问题：**

    *   一个仓库中放入A和B
    *   每次只能往仓库中放一种
    *   A-B>M-1
    *   B-A>N-1

    ```c
    Sa:A剩余能放入的件数，Sb:B剩余能放入的件数，mutex:互斥访问仓库
    produce A()
    {
        P(Sa);
        P(mutex);
        将A放入仓库中
        V(mutex);
        V(Sb);
    }
    
    produce A()
    {
        P(Sb);
        P(mutex);
        将B放入仓库中
        V(mutex);
        V(Sa);
    }
    ```


*   访问临界资源的那段代码称为**临界区**，也就是P/V操作，加减锁
*   可重入的程序代码一次可供多个进程使用
*   执行P操作时的进程处于运行态
*   不允许修改的代码称为**可重入代码**，也称纯代码，即允许多个进程同时访问的代码
*   PV操作是一种低级的进程通信原语，不是系统调用
*   银行家算法是避免死锁的算法
*   信箱通信是一种间接通信
*   只有一个进程在离开管程时才能调用signal()操作
*   “让权等待”准则在互斥准则中不一定需要实现



![同步与互斥](/Users/coffeeboy/Desktop/考研/assets/同步与互斥.png)



# 死锁

*   **死锁：**指多个进程因竞争资源而造成的一种互相等待，若无外力作用，这些进程都将无法向前推进

*   **死锁产生的原因：**

    *   系统资源的竞争：对不可剥夺资源的竞争才会导致死锁，比如磁带机，打印机
    *   进程推进顺序非法：进程在运行过程中，请求和释放资源的顺序不当，双方都在等待对方的资源而进入死锁

*   **死锁产生的必要条件：**只要其中任意一个条件不成立则死锁不会发生

    *   互斥条件：进程要求对所分配的资源进行排他性使用

    *   不剥夺条件：进程所获得的资源在未使用完之前，不能被其他进程强行夺走，只能由获得该资源的进程自己来释放

    *   请求并保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占用，请求进程被阻塞并不释放已获得的资源

    *   循环等待条件：存在一种进程资源的循环等待链，链中每个进程已获得的资源同时被链中下一个进程所请求，但只是必要条件，如果同类资源数大于1，则该圈可以被打破

        ![img](/Users/coffeeboy/Desktop/考研/assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTYwNTkzNw==,size_16,color_FFFFFF,t_70-2521064.png)

*   死锁的处理策略：

    *   死锁预防：设置某些限制条件，破坏产生死锁的4个必要条件中的一个或多个
    *   避免死锁：在资源的动态分配过程中，用某种方法防止系统进入不安全状态
    *   死锁的检测及解除：不采取任何限制性措施，允许发生死锁，及时检测出死锁并解除死锁

    |          | 资源分配策略                   | 各种可能模式                             | 主要优点                                     | 主要缺点                                                 |
    | -------- | ------------------------------ | ---------------------------------------- | -------------------------------------------- | -------------------------------------------------------- |
    | 死锁预防 | 保守，宁可资源闲置             | 一次请求所有资源，资源剥夺，资源按序分配 | 适用于突发式处理的进程，不必进行剥夺         | 效率低，进程初始化时间长，剥夺次数多，不便灵活申请新资源 |
    | 死锁避免 | 中等，在运行时判断是否可能死锁 | 寻找可能的安全允许顺序                   | 不必进行剥夺                                 | 必须知道将来的资源需求，进程不能被长时间阻塞             |
    | 死锁检测 | 宽松，只要允许就分配资源       | 定期检查死锁是否已经发生                 | 不延长进程初始化时间，允许对死锁进行现场处理 | 通过剥夺解除死锁，造成损失                               |



## 死锁预防

*   通过破坏死锁产生的必要条件
*   **破坏互斥条件：**
    *   若允许系统资源都能共享使用则不会出现死锁，但临界资源只能进行互斥访问，所以破坏互斥条件来预防死锁的方法不太可行
*   **破坏不可剥夺条件：**
    *   当一个已保持了某些不可剥夺资源的进程请求新的资源被阻塞时，该进程必须释放已经保持的**所有资源**，之后再重新申请
    *   释放已获得的资源可能造成前一阶段工作的失效，反复地申请和释放资源会增加系统开销，降低系统吞吐率量
    *   这种方法常用于状态易于保存和恢复的资源，如CPU的寄存器及内存资源，一般不能用于打印机之类的资源
*   **破坏请求并保持条件：**
    *   采用**预先静态分配方法**：即进程在运行前一次申请完它所需要的全部资源，在所有资源未满足前，不能投入运行
    *   一旦投入运行，代表所有资源都能满足，则不会再请求新的资源，也就不会进入死锁
    *   系统资源被严重浪费，其中有些资源可能仅在运行初期或运行快结束时才使用，甚至根本不使用
    *   会导致“饥饿”现象，由于个别资源长期被其他进程占用，导致进程一直不能运行
*   **破坏循环等待条件：**
    *   采用**顺序资源分配法**，首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源一次申请完(同编号的资源全部拿走)，所以进程申请的资源编号只能变大，不能向前申请，所以也就不会出现循环
    *   限制了新类型设备的增加
    *   作业使用资源的顺序和系统规定的顺序不同导致资源浪费
    *   给用户编程带来麻烦



## 死锁避免

*   并不事先采取某种限制措施破坏必要条件，而是在资源动态分配过程中，防止系统进入不安全状态，以避免发生死锁
*   **安全状态：**系统能按某种进程推进顺序为每个进程分配其所需的资源，直至满足每个进程对资源的最大需求，使每个进程都可顺序完成，若系统无法找到一个安全序列，则称系统处于不安全状态
*   **系统安全状态：**
    *   允许进程动态地申请资源，但系统在进行资源分配之前，先计算此次分配的安全性
    *   若此次分配不会导致系统进入不安全状态，则允许分配，否则让进程等待
    *   系统进入不安全状态后，**可能**进入死锁状态，只要系统处于安全状态，系统便可避免进入死锁状态
*   **银行家算法：**
    *   可利用资源向量Available：所有资源都可用数的矩阵
    *   最大需求矩阵Max：每一行代表一个进程对共m个资源的需求数，共有n个进程，则有n行，所以为n*m的矩阵
    *   分配矩阵Allocation：每一行代表一个进程对共m个资源已占用数，共有n个进程，则有n行，所以为n*m的矩阵
    *   需求矩阵Need：每一行代表一个进程对共m个资源还需要的个数，共有n个进程，则有n行，所以为n*m的矩阵
    *   Need = Max - Allocation
*   **算法描述：**
    *   设Request是进程P的请求向量
    *   若Request <= Need，则下一步，否则认为出错，因为所需要的数目已超过最大需求数
    *   若Request <= Available，则下一步，否则认为出错，因为资源不够，进行等待
    *   系统重新计算各个矩阵：
        *   Available = Available - Request
        *   Need = Need - Request
        *   Allocation = Allocation + Request
    *   再执行系统**安全算法**，检查资源分配后，系统是否处于安全状态，若安全，则将资源分配给P，否则，恢复计算过的矩阵，P等待
*   **安全算法：**
    *   设置工作向量Work，表示系统中可用资源数，初始时Work = Available
    *   初始时安全序列为空，从Need中寻找符合要求的进程P：
        *   该进程不在安全序列中
        *   该行小于或等于Work
    *   找到后将该进程P加入到安全序列，执行下一步，如果没找到则执行最后一步
    *   进程P进入安全序列后，可顺利执行， 直至完成，释放分配给它的所有资源，所以Work = Work + Allocation
    *   若此时安全序列中已有所有进程，则系统处于安全状态，否则系统处于不安全状态



## 死锁检测与解除

*   **资源分配图：**

    *   圆圈代表一个进程

    *   方框代表一种资源

    *   方框内的圆圈代表一种资源有多少个

    *   由方框指向圆圈的有向线段代表已分配的资源数量

    *   由圆圈指向方框的有向线段代表进程请求的资源数量

        ![img](/Users/coffeeboy/Desktop/考研/assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ppYW5iYWlf,size_16,color_FFFFFF,t_70-2543449.png)

*   **死锁定理：**当且仅当某一状态的资源分配图是不可完全简化的，那么该状态进入死锁
*   **简化资源分配图：**
    *   判断每个资源已分配的数量和剩余的数量，判断能不能满足某个进程对所有资源数量的请求
    *   如果能找到一个，则运行该进程并运行完成后进行释放寻找下一个满足条件的进程
*   **死锁解除：**
    *   资源剥夺法：将某些死锁进程挂起，抢占它的资源，将这些资源分配给其他的死锁进程，但防止被挂起的进程长时间得不到资源而处于饥饿的状态
    *   撤销进程法：强制撤销部分甚至所有死锁进程并剥夺这些进程的资源，撤销的原则可以按进程优先级和撤销进程代价的高低进行
    *   进程回退法：让一个或多个进程回退到足以回避死锁的地步，进程回退时自愿释放资源而非被剥夺，要求系统保持进程的历史信息，设置还原点



## 习题

*   死锁检测方法可以获得最大的并发性，即次为死锁避免，死锁预防
*   进程是程序及其数据在计算机上的一次运行活动，是一个动态的概念
*   程序是一组有序的指令集合，是一种静态的概念
*   一个进程可以执行一个或多个程序，一个程序也可构成多个进程
*   进程可创建进程，而程序不能形成新的程序
*   发生“饥饿”的进程的状态可能是就绪态(长期得不到处理机)，也可能是阻塞态(如长期得不到所需的I/O设备)，而发生死锁的进程的状态则必定是阻塞态



![死锁](/Users/coffeeboy/Desktop/考研/assets/死锁.png)



# 内存管理

*   **内存管理：**操作系统对内存的划分和动态分配
*   内存管理的功能：
    *   **内存空间的分配与回收：**由操作系统来完成主存储器空间的分配和管理，减少程序员存储分配的麻烦，提高编程效率
    *   **地址转换：**在多道程序环境下，程序中的逻辑地址和内存中的物理地址不一致，存储管理必须提供地址变换功能，把逻辑地址转换为对应的物理地址
    *   **内存空间的扩充：**利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存
    *   **内存共享：**允许多个进程访问内存中的同一个部分，必须支持对内存共享区域进行受控访问
    *   **存储保护：**保证各道作业在各自的存储空间内运行，互不干扰



## 基本概念

*   **程序的链接和装入过程：**
    *   编译：由编译程序将用户**源代码**编译成若干**目标模块**
    *   链接：由链接程序将编译后形成的一组**目标模块**及它们所需要的**库函数**链接在一起，形成一个完整的**装入模块**
    *   装入：由装入程序将**装入模块**装入内存中运行



*   **程序链接的方式：**
    *   静态链接：
        *   在程序运行之前，将各目标模块及它们需要的库函数链接成一个完整的装入模块，之后不再拆开
        *   将几个目标模块链接成一个模块时，需要**修改相对地址**，编译后的所有目标模块的地址都是从0开始的
        *   **变换外部调用符号，**将每个模块中所用的所有外部调用符号都变换为相对地址
    *   装入时动态链接：
        *   在将目标模块装入内存时采用**边装入边链接的方式**
        *   便于修改和更新，便于实现对目标模块的共享
    *   运行时动态链接：
        *   对某些目标模块，在程序执行过程中需要该模块时再链接
        *   执行过程中未被使用到的目标模块，不会被调入内存和被链接到装入模块中
        *   能加快程序的装入过程，还可节省大量的内存空间



*   **装入模块装入内存的方式：**
    *   绝对装入：
        *   只适用于**单道程序环境**
        *   在编译的时候，如果知道程序将驻留在内存的某个位置，则编译程序将产生**绝对地址**的目标代码
        *   绝对装入程序按照装入模块中的地址，将程序和数据装入内存
        *   由于是单道程序环境，所以程序中的逻辑地址和实际内存地址完全相同，不需要进行转换
        *   程序中所用的绝对地址，可在编译或汇编时给出，也可由程序员直接赋予，通常在程序中采用符号地址，编译或汇编时再转换为绝对地址，如STM32中，将各种绝对地址宏定义成字符串方便程序员使用，在编译时再转换为绝对地址
    *   可重定位装入：
        *   在多道程序环境下，多个目标模块的起始地址都从0开始，需要采用可重定位装入方式，根据内存的当前情况，将装入模块装入到内存中适当的位置
        *   在装入时对目标程序中指令和数据地址的修改过程称为重定位
        *   因为地址变换通常是在进程装入时一次完成的，故称为静态重定位
        *   作业一旦装入内存，整个运行期间就不能在内存中移动，也不能申请内存空间
    *   动态运行时装入：
        *   也称动态重定位，程序在内存中若发生移动，则需要使用动态的装入方式
        *   装入程序把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地址转换推迟到程序真正要执行时才进行
        *   所以装入内存后到所有地址都是相对地址，需要一个**重定位寄存器**来辅助转换为绝对地址
        *   优点：
            *   可以将程序分配到不连续的存储区
            *   在程序运行之前可以只装入部分代码即可投入运行，然后在程序运行期间，根据需要动态申请分配内存
            *   便于程序段的共享

![img](/Users/coffeeboy/Desktop/考研/assets/70.png)

![img](/Users/coffeeboy/Desktop/考研/assets/70-20231215103717955-2607844.png)



*   **逻辑地址和物理地址：**
    *   编译后，每个目标模块都从0号单元开始编址，称为该目标模块的**相对地址(或逻辑地址)**
    *   链接程序将各个模块链接成一个完整的可执行目标程序，地址统一从0号单元开始编制，称为**逻辑地址空间(或虚拟地址空间)**
        *   进程在运行时，看到和使用的都是逻辑地址，不同进程可以有相同的逻辑地址，这些逻辑地址会映射到主存的不同位置
    *   **物理地址空间**是指内存中物理单元的集合，是地址转换的最终地址
        *   进程在运行时执行指令和访问数据，最后都是通过物理地址从主存中存取
        *   当装入程序将可执行代码装入内存时，必须通过地址转换将逻辑地址转换成物理地址，这个过程称为**地址重定位**
    *   操作系统通过**内存管理部件(MMU)**将进程使用的逻辑地址转换为物理地址
    *   进程使用虚拟内存空间中的地址，操作系统在相关硬件的协助下，转换为实际的物理地址
    *   逻辑地址通过页表映射到物理内存，页表由操作系统维护并被处理器引用



*   **进程在内存中的映像：**

    *   当一个程序调入内存中运行时，就构成了进程的内存映像

    *   一个进程的内存映像通常包括：

        *   代码段：程序的二进制代码，代码段是只读的，可以被多个进程共享
        *   数据段：程序运行时加工的对象，包括全局变量和静态变量
        *   进程控制块(PCB)：存放在系统区，操作系统通过PCB来控制和管理进程
        *   堆：用来存放动态分配的变量，通过调用malloc函数动态地向高地址分配空间
        *   栈：用来实现函数调用，从用户空间的最大地址往低地址方向增长

    *   代码段和数据段在程序调入内存时就指定了大小

    *   堆和栈可以在运行时动态地扩展和收缩

        *   程序在调用像malloc和free这样的函数时，堆的大小进行改变
        *   程序每次调用一个函数，栈就会增长，从一个函数返回，栈就会收缩

        ![img](/Users/coffeeboy/Desktop/考研/assets/1324606-20210307094129919-1888740420.png)

    *   共享库：用来存放进程用到的共享函数库代码，如printf()函数等
    *   只读代码段：`.init`是程序初始化时调用的`_init`函数，`.text`是用户程序的机器代码，`.rodata`是只读数据
    *   读/写数据段：`.data`是已初始化的全局变量和静态变量，`.bss`是未初始化及所有初始化为0的全局变量和静态变量



*   **内存保护：**

    *   在运行过程中，需要确保每个进程都有一个单独的内存空间

    *   内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响

    *   内存保护可采用两种方法：

        *   在CPU中设置一对上，下限寄存器，存放用户作业在主存中的下限和上限地址，每当CPU要访问一个地址时，分别和两个寄存器的值相比，判断有无越界
        *   采用**重定位寄存器(或基地址寄存器)和界地址寄存器(或限长寄存器)**来实现这种保护，重定位寄存器中包含最小的物理地址值，界地址寄存器含逻辑地址的最大值，内存管理机构动态地将逻辑地址与界地址寄存器进行比较，若未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再交送内存单元

    *   加载重定位寄存器和界地址寄存器时必须使用特权指令，只有操作系统内核才能加载这两个存储器

    *   使用第二种方案允许操作系统内核修改这两个寄存器的值，而不允许用户程序修改

        ![img](/Users/coffeeboy/Desktop/考研/assets/7ef79e0a555f09cef6baebc6d354630b-2611887.png)

*   **内存共享：**
    *   只有只读的区域才可以共享
    *   可重入代码又称纯代码，指一种允许多个进程同时访问但不允许被任何进程修改的代码
    *   在实际执行时，可以为每个进程配以局部数据区，把在执行中可能改变的部分复制到该数据区，程序在执行时只需对该**私有数据区**中的内存进行修改，并不去改变共享的代码



*   **内存的分配和回收：**
    *   在操作系统从单道向多道发展时，存储管理方式便由**单一连续分配**发展为**固定分区分配**
    *   为了更好地适应不同大小的程序要求，从**固定分区分配**发展为**动态分区分配**
    *   为了更好地提高内存的利用率，从**连续分配方式**发展为**离散分配方式-页式存储管理**
    *   引入**分段存储管理**的目的：为了满足用户在编程和使用方面的要求，其中某些要求是其他几种存储管理方式难以满足的



>   覆盖与交换：
>
>   ​	覆盖与交换技术是在多道程序环境下扩充内存的两种方法
>
>   覆盖：
>
>   ​	由于程序运行时并非任何时候都要访问程序及数据的各个部分(尤其是大程序)，所以分为了固定区和覆盖区，可以把常用的部分放在固定区，将不常用的放在外存中，当即将使用这些部分时再调入到覆盖区中
>
>   特点：
>
>   ​	打破了必须将一个进程的全部信息装入主存后才能运行的限制，但是当同时运行程序的代码量大于主存时仍不能运行
>
>   ​	内存中能够更新的地方只有覆盖区的段，不在覆盖区的段会常驻内存
>
>   
>
>   交换：
>
>   ​	把处于等待状态的程序从内存移到辅存，称为换出，将处于就绪状态的程序从辅存移到内存中运行，称为换入
>
>   注意问题：
>
>   ​	交换需要备份存储，通常是磁盘，必须足够大
>
>   ​	为了有效使用CPU，需要使每个进程的执行时间比交换时间长
>
>   ​	若换出进程，则必须确保进程处于空闲状态
>
>   ​	交换空间通常作为磁盘的一整块，且独立于文件系统
>
>   ​	交换通常在有许多进程运行且内存空间不够用时启动，在系统负荷降低时就暂停
>
>   ​	普通的交换使用不多，但交换策略的某些变体在许多系统中仍发挥作用(如UNIX)
>
>   交换技术主要在**不同进程之间**进行，覆盖则用于**同一个程序或进程**中，现在使用虚拟内存技术来解决内存不够的问题，所以覆盖已成为历史，而交换仍发挥着作用



## 连续分配管理方式

*   连续分配方式主要包括**单一连续分配，固定分区分配，动态分区分配**
*   **单一连续分配：**
    *   内存分为系统区和用户区
        *   系统区仅供操作系统使用，通常在低地址部分
        *   用户区中，仅有一道用户程序，即整个内存的用户空间由该程序独占
    *   优点：
        *   简单，无外部碎片，无须进行内存保护
    *   缺点：
        *   只能用于单用户，单任务的操作系统中
        *   有内部碎片，存储器的利用率极低
*   **固定分区分配：**
    *   最简单的一种多道程序存储管理方式，将用户内存空间划分为若干固定大小的区域，每个分区只装入一道作业
    *   当有空闲分区时，便可再从外存的后备作业队列中选择适当大小的作业装入该分区
    *   划分分区时：
        *   分区大小相等：程序太小会造成浪费，程序太大又无法装入，缺乏灵活性
        *   分区大小不等：划分为多个较小的分区，适量的中等分区和少量大分区
    *   建立一张分区使用表，通常按分区大小排队，各表项包括每个分区的**起始地址，大小，状态(是否已分配)**，当分配内存时，检索该表，查找是否有足够大的分区，有就分配，无就拒绝分配
    *   存在的问题：
        *   程序可能太大而放不进任何一个分区，这时就需要采用覆盖技术来使用内存空间
        *   当程序小于固定分区大小是，会造成空间浪费，产生**内部碎片**，但是无外部碎片
        *   不能实现多进程共享一个主存区，所以存储空间利用率低
*   **动态分区分配：**
    *   也称**可变分区分配**，在进程装入内存中时，动态地为之分配内存，系统中的分区大小和数目是可变的
    *   随着时间推移，内存中出现越来越多的小内存块，称为**外部碎片**
    *   克服外部碎片使用**紧凑**技术来解决，即操作系统不时地对进程进行移动和整理，但是需要动态重定位寄存器的支持，相对费时
    *   动态分配分区有多个策略：
        *   **首次适应算法(First Fit)：**空闲分区以地址递增的次序链接，分配内存时从链首开始顺序查找，找到第一个能满足进程大小的分区进行分配
        *   **邻近适应算法(Next Fit)：**又称循环首次适应算法，在首次适应算法的基础上，分配内存时从上次查找结束的地方开始
        *   **最佳适应算法(Best Fit)：**空闲分区按照容量递增的次序形成空闲分区链，找到第一个能满足要求且最小的空闲分区分配
        *   **最坏适应算法(Worst Fit)：**空闲分区按照容量递减的次序形成空闲分区链，找到第一个能满足要求且最大的空闲分区分配
    *   各算法的特点：
        *   首次适应算法：最简单，通常也是最好和最快的，不过会使得内存的低地址部分出现很多小分区块，每次查找分配都要经过这些分区，增加了开销
        *   邻近适应算法：试图解决首次适应算法中低地址中碎片多的问题，但是常导致高地址的大空闲块被分割，没有大分区
        *   最佳适应算法：性能通常很差，每次最佳的分配会留下很小的难以利用的内存块，会产生很多的外部碎片
        *   最坏适应算法：一直把最大的空闲块划分，导致没有可用的大内存块，性能也非常差
    *   在回收时，系统根据回收分区的始址，从空闲分区链中找到对应的插入点：
        *   当回收区与插入点的前一个空闲分区相邻，则进行合并，修改表项的分区大小
        *   当回收区与插入点的后一个空闲分区相邻，则进行合并，修改表项的分区大小
        *   当回收区与插入点的前，后两个空闲分区相邻，则将三个分区进行合并，删除后一分区的表项，修改前一分区的大小
        *   当回收区不与其他空闲分区相邻，则新建一个表项，填写始址和大小，并插入空闲分区链



## 非连续分配存储管理

*   连续分配管理方式中，用户程序在主存中都是连续存放的，如果采用非连续分配管理方式，作业的空间可以分散地分配在内存的各个区域，但是需要额外的空间去存储它们(分散区域的索引)，使得非连续分配方式的存储密度低于连续分配方式
*   非连续分配管理方式，分为：**分页存储管理和分段存储管理**
    *   分页存储管理中，根据运行作业时是否要把作业的所有页面都装入内存才能运行分为：基本分页存储管理和请求分页存储管理



### 基本分页存储管理

*   固定分区会产生内部碎片，动态分区会产生外部碎片，这两种技术对内存的利用率都比较低

*   怎样避免碎片的产生呢？**引入分页的思想**

*   分页：把主存空间划分为大小相等且固定的块，块相对较小，作为主存的基本单位，每个进程也以块进行划分，在执行时，以块为单位逐个申请主存中的块空间

*   分页就不会产生外部碎片，进程只在申请最后一个块的时候产生内部碎片，且每个进程平均只产生半个块大小的内部碎片(页内碎片)

*   **分页存储的几个基本概念：**

    *   **页面/页：**进程中的块

        *   页面太小：使进程的页面数过多，页表过长，占用大量内存，增加硬件地址转换的开销，降低页面换入/换出的效率
        *   页面过大：使页内碎片增多，降低内存的利用率

    *   **页框/页帧：**内存中的块

    *   **块/盘块：**外存中的块

    *   **地址空间：**分页存储管理的逻辑地址结构

        *   12位的页内地址(页内偏移量)，即页的大小为4KB
        *   20位的页号，即最多允许$2^{20}$页

        <img src="/Users/coffeeboy/Desktop/考研/assets/image-20231215161820968.png" alt="image-20231215161820968" style="zoom:50%;" />

    *   **页表：**存放从页号到物理块号到地址映射
        *   页表一般存放在内存中
        *   页表由页表项组成：页号，物理内存中对应的块号

*   **基本地址变换机构：**将逻辑地址转换为内存中的物理地址，借助页表实现

![img](/Users/coffeeboy/Desktop/考研/assets/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5bq35bq35LiO6Iqx,size_20,color_FFFFFF,t_70,g_se,x_16.png)

*   系统中设置一个**页表寄存器(PTR)**来存放页表在内存的起始地址F和页表长度M
*   进程未执行时，页表的始址和页表长度存放在本进程的PCB中，当进程被调度执行时，才将页表始址和页表长度装入页表寄存器中
*   设页面大小为L，逻辑地址为A，转换到物理地址E的变换过程：
    *   计算页号：P = A/L
    *   计算页内偏移量：W = A%L
    *   比较页号和页表长度：若P>=M，产生越界中断，否则继续执行
    *   计算逻辑地址对应的页表中的页表项地址：页表始址F + 页号P * 页表项长度**(找到所执行的页在页表中对应的位置)**
    *   找到页表项后，取出里面存放的物理块号：b(页号对应的块号是不确定的)
    *   计算物理地址：b*L + W

*   在计算页表项时，怎么确定页表项的大小？
    *   假设为32位逻辑地址空间，字节编址单位，一页4KB
    *   所以地址空间中一共有$2^{32}B/4KB=1M$页
    *   因此需要$log_21M=20$位才能保证表示范围能包含所有页面
    *   以字节编址单位，所以页表项的大小$>=(20/8)=3B$
    *   所以为了保证页表项能指向所有页面，页表项的大小应该大于等于3B，也可以选择更大的页表项
*   **分页管理方式的问题：**
    *   每次访存操作都需要进行逻辑地址到物理地址到转换，地址转换过程必须足够快，否则访存速度会降低
    *   每个进程引入页表，用于存储映射机制，页表不能太大，否则内存利用率会降低

*   **具有快表的地址变换机构：**
    *   上述地址变换中，若页表全部存放在内存中，则存取一个数据或指令至少要访问两次内存：第一次访问**内存中的页表**，确定所存取的数据或指令的物理地址，第二次访问**内存中的物理地址**存取数据或指令，而通常执行指令只需要访问一次，速度慢了一倍
    *   因此，增设一个具有并行查找能力的高速缓冲存储器-**快表**，又称**相联存储器(TLB)**，用来存放当前访问的若干页表项，以加速地址转换的过程，对应的，主存中的页表称为慢表
    *   因此，地址的变换过程变为：
        *   CPU给出逻辑地址后，由硬件进行地址转换，将页号送入高速缓存寄存器，并将此页号与快表中的所有页号进行比较
        *   若在快表中找到匹配的页号，则直接从中取出该页对应的页框号，与页内偏移量形成物理地址，访问快表不用进内存，则存取数据仅一次访存就可
        *   若未找到匹配的页号，则访问主存中的页表，读出页表项后，同时将其存入快表，以便后面可能的再次访问，若快表已满，则须按特定的算法淘汰一个旧页表项

>   有些处理机设计为快表和慢表同时查找，若在快表中查找成功就终止慢表的查找

*   快表的命中率可达90%以上，这样分页带来的速度损失就可降低到10%之下，快表的有效性基于著名的**局部性原理**

*   **两级页表：**

    *   如果进程过大，导致页数过多，而使页表项过多，页表项是连续的，所以不利于查找和存放，采用二级页表

    *   规定顶级页表最多只能有1个页面

    *   32位逻辑地址空间中，前10位用来代表顶级页表，中间10位用来代表底级页表，后12位用来作为页内地址偏移

        | 一级页号 | 二级页号 | 页内偏移 |
        | -------- | -------- | -------- |

        



### 基本段式存储管理

*   分页管理方式是从计算机的角度考虑设计的，目的是**提高内存的利用率，提升计算机的性能**，分页通过硬件机制实现，对用户透明

*   分段管理方式是从用户和程序员角度设计的，目的是**方便编程，信息保护的共享，动态增长，动态链接**

*   **分段：**

    *   段式管理方式按照用户进程中的自然段划分，例如用户进程由主程序段，两个子程序段，栈段，堆段，则划分为5段，每段从0开始编址，并分配一段连续的地址空间

    *   段内要求连续，段间不要求连续

    *   **逻辑地址**由段号S和段内偏移量W两部分组成

        | 段号S | 段内偏移量 |
        | ----- | ---------- |

    *   页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，但在段式系统中，段号和段内偏移量必须由用户直接提供

*   **段表：**

    *   和页式系统一样，每个进程也有一张段表，段表中包括：段号，段长，本段在主存的始址

        | 段号 | 段长 | 本段在主存的始址 |
        | ---- | ---- | ---------------- |

    *   运行中的进程通过查找段表来找到每段所对应的内存区，段表用于实现从逻辑段到物理内存区的映射

        ![image-20231215223100708](/Users/coffeeboy/Desktop/考研/assets/image-20231215223100708-2650668.png)

*   **地址变换机构：**

    *   操作系统设置段表寄存器，存放段表始址F和段表长度M

        ![image-20200927081520616](https://mysticalyu.gitee.io/pic/hexo/image-20200927081520616.png)

        *   从逻辑地址A中取出前几位为段号S，后几位为段内偏移量W
        *   比较段号S和段表长度M，若S>=M，则产生越界中断，否则继续执行
        *   段表项地址 = 段表始址F + 段号S * 段表项长度，再取出段表项中的段长C
        *   比较偏移量W和段长C，如果W>=C，则产生越界中断，否则继续执行
        *   取出段表项中该段的始址b，E = b + W，得到物理地址

*   **段的保护和共享：**

    *   段的共享是指两个进程的段表项中指向同一个物理地址
    *   有两种方法进行保护：
        *   存取控制保护
        *   地址越界保护：段式管理中有两次比较
            *   段表寄存器中的段表长度和逻辑地址中的段号进行比较
            *   再将段表项中的段长和逻辑地址中的段内偏移量进行比较
    *   分页管理中只需要判断页号是否越界
    *   段号和段内偏移必须直接给出

*   分段管理的地址空间是二维的



### 段页式管理

*   分页存储管理能有效地提高内存利用率，分段存储管理能反映程序的逻辑结构并有利于段的共享和保护

*   在段页式系统中，作业的地址空间首先被**分成若干逻辑段**，每段都有自己的段号，然后将**每段分成若干大小固定的页**，进行页式管理

*   作业的逻辑地址分为：段号，页号，页内偏移量

    ![在这里插入图片描述](/Users/coffeeboy/Desktop/考研/assets/20150923210719885.jpeg)

    ![在这里插入图片描述](/Users/coffeeboy/Desktop/考研/assets/20150923210806703.png)

*   同时为了实现地址变换，系统为每个进程建立一张**段表**，每个分段都有一张**页表**

    *   段表项中包含：**段号，页表长度(表示有多少个页)，页表始址**
    *   页表项中包含：**页号，块号**

*   系统还有一个段表寄存器，包含作业的**段表始址，段表长度(表示有多少个段)**

*   一个进程中段表只有一个，但是页表可以有多个

*   地址变换的过程：

    ![在这里插入图片描述](/Users/coffeeboy/Desktop/考研/assets/20150923211453791.jpeg)

    *   先从逻辑地址中取得**段号S**，将**段号S**与段表寄存器中的**段表长度M**进行越界比较
    *   如果S<=M，则计算对应段的**段表项地址 = 段表起始地址F + 段号S * 段表项长度 **
    *   取出段表项中的**页表长度和页表始址**，将逻辑地址中的**页号P**与**页表长度C**进行越界比较
    *   如果P<=C，则计算对应页的**页表项地址 = 页表始址d + 页号P * 页表项长度**
    *   取出页表项中的**块号**，从而得出对应的**物理地址 = 块号b + 页内偏移量W**

*   进程一次访问实际需要三次访问主存：访问段表，访问页表，访问物理地址

*   同样可以使用快表来加快查找速度

*   段页式管理的地址空间是二维的



## 习题

*   编址空间的大小取决于硬件的访存能力，一般由地址总线宽度决定
*   虚拟内存的管理需要由相关的硬件和软件支持，有请求分页页表机制，缺页中断机构，地址变换机构
*   内存保护是内存管理的一部分，是操作系统的任务，出于安全性和效率考虑，必须由硬件实现，所以需要操作系统和硬件机构合作
*   覆盖技术是早期连续存储管理中使用的扩大存储容量的技术，同样适用于固定分区分配的存储管理
*   **静态装入：**指在编程阶段就把物理地址计算好然后直接装入不需要地址变换
*   **可重定位：**指在装入时把逻辑地址转换成物理地址，装入后不能改变
*   **动态重定位：**指在执行时再决定装入的地址并装入，装入后有可能会换出，所以同一个模块在内存中的物理地址是可能改变的，同时在作业运行过程中执行一条访存指令时，再把逻辑地址转换为主存中的物理地址，实际中是通过硬件地址转换机制来完成的
*   系统提供给用户的物理地址空间为总空间大小减去页表或段表的长度，由于页表和段表的长度不能确定，所以提供给用户的物理地址空间大小不能确定
*   页表的功能由一组专门的存储器实现，其始址放在页表基址寄存器(PTBR)中，这样能满足较快的地址变换
*   在执行程序或访问数据时，真正访问的内存地址由相对地址和重定位寄存器中的地址相加而成，这时将始址存入重定位寄存器，之后的地址访问即可通过硬件变换来实现，只需在切换程序执行时重置寄存器内容
*   分段是指在用户编程时，将程序按照逻辑划分为几个逻辑阶段
*   程序的动态链接与程序的逻辑结构有关，分段存储管理将程序按照逻辑段进行划分，因此有利于其动态链接
*   可重入程序主要是通过共享来使用同一块存储空间的，或通过动态链接的方式将所需的程序段映射到相关进程中，优点是减少了对程序段的调入/调出，因此减少了对换数量
*   分区存储管理是满足多道程序设计的最简单的存储管理方案，适合嵌入式等微型设备
*   在非虚拟存储器中，作业必须全部装入内存并在运行过程中也一直驻留在内存中，在虚拟存储器中，作业不必全部装入内存且在运行过程中也不用一直驻留内存
*   确定页面的大小有很多因素，如进程的平均大小，页表占用的长度，但是一旦确定之后，所有的页面大小都是等长的，一般取2的整数幂倍，以方便系统管理
*   段式存储管理方式主要为了：方便编程，分段共享，分段保护，动态链接和动态增长
*   对主存的访问是以字节或字为单位的
*   在段式分配中，CPU每次从内存中取一次数据需要访问2次内存：先从内存中访问段表，再拼成物理地址后访问内存
*   在页式分配中，CPU每次从内存中取一次数据需要访问2次内存：先从内存中访问页表，再拼成物理地址后访问内存
*   在段页式分配中，先段表再页表再物理地址，一共3次
*   在多个进程并发执行时，所有进程的页表大多驻留在内存中，在系统中只设置一个页表寄存器(PTR)，进程未执行时，页表的始址和页表的长度存放在本进程的PCB中，当调度到某进程时，才将这两个数据装入页表寄存器中
*   最佳适应算法会产生最多的内部碎片

*   **为什么要引入内存管理？**
    *   因为运行程序需要编译，链接，加载到内存中，CPU才会执行，但是不可能将所有用户进程和系统所需要的全部程序和数据放入内存，所以需要进行内存管理
    *   因为在多道程序中，进程之间共享的不仅仅是处理机，还有主存储器，不对内存进行管理容易导致内存数据的混乱，影响并发执行，为了更好地支持多道程序并发执行，必须进行内存管理
*   **实施内存管理采取了什么方法？**
    *   先采用了连续分配管理
        *   单一连续分配
        *   固定分区分配
        *   动态分区分配
    *   之后发现很多碎片，浪费了内存，所以又引入了分页的思想
        *   将主存和进程都分成很小的块，一个块一个块地申请，这样内存的利用率就提高了很多，而页里面存储的是什么呢？
        *   页就是进程的一部分，进程分为数据段，代码段，栈，堆，就是将这些进行分页，而这些页中通常进行操作本质上是在操作硬件，所以需要硬件地址，操作系统为每个进程提供了页表，页表中有m个页表项，来对应m个页的物理地址
    *   如果进程过大的话，需要的页数页也就越多，一个页数就对应一个页表项，而一个页表项的大小取决于页数的最大值，所以就导致单单页表项就非常多且大，而且页表项必须连续存储，因为查找页表项就是连续查找的，为了使页表项不是**连续的**且**查找更加方便**所以就有了二级页表
        *   二级页表：用新的一页作为**顶级页表**，先查顶级页表，再查进程页表，最后从进程页表的页表项中查物理地址

*   **32位的逻辑地址空间代表什么意思？**
    *   逻辑地址空间是虚拟内存的概念，用来映射到内存中的地址，使每个进程都以为自己有32位的独立地址空间，每个进程的逻辑地址空间中的地址可以映射到内存中的同一个物理地址
    *   采用页笔机制来进行映射，所以这所有32位都是用来作为映射的
    *   采用二级页表，前10位用来代表顶级页表，中间10位用来代表底级页表，后12位用来作为页内地址偏移

*   **多级页表解决了什么问题？**
    *   多级页表解决了当逻辑地址空间过大时，页表的长度会大大增加的问题，但是采用多级页表时，一次访盘需要多次访问内存甚至磁盘，会大大增加一次访存的时间



![内存管理](/Users/coffeeboy/Desktop/考研/assets/内存管理.png)





# 虚拟内存管理

## 虚拟内存基本概念

*   **为什么要引入虚拟内存？**
    *   传统存储管理方式都是为了同时将多个进程保存在内存中，以便允许进行多道程序设计，都有共同的特征：
        *   **一次性：**作业必须一次性全部装入内存后才能开始运行，可能导致：
            *   当作业很大而不能全部被装入内存时，该作业无法运行
            *   但大量作业要求运行时，由于内存不足容纳所有作业只能使少数作业运行，导致多道程序并发度下降
        *   **驻留性：**作业被装入内存后，就一直驻留在内存中，直到作业运行结束，运行中的进程会因等待I/O而被阻塞，可能出于长期等待状态
    *   所以传统存储管理方式中，许多在程序运行中不用或暂时不用的程序占据了大量的内存空间，而一些需要运行的作业又无法装入，浪费了内存资源
*   **局部性原理：**
    *   时间局部性：
        *   程序中的某条指令一旦执行，不久后该指令可能再次执行
        *   某数据被访问过，不久后该数据可能再次被访问
        *   产生的原因是程序中存在大量的循环
    *   空间局部性：
        *   一旦程序访问了某个存储单元，不久后其附近的存储单元也将被访问，即程序在一段时间内所访问的地址，可能集中在一定的范围之内
        *   产生的原因是指令通常是顺序存放，顺序执行的，数据也一般是以向量，数组，表等形式存储的
    *   时间局部性通过将近来使用的指令和数据保存在高速缓存中，并使用高速缓存的层次结构实现
    *   空间局部性通常使用较大的高速缓存，并将预取机制集成到高速缓存控制逻辑中实现
*   **虚拟存储器的定义和特征：**
    *   虚拟存储器：这种存储器实际上并不存在，只是由于系统提供了部分装入，请求调入，置换功能后，给用户的感觉好像存在一个比实际物理内存大的多的存储器
    *   特征：
        *   多次性：
            *   无须在作业运行时一次性全部装入内存，允许被分成多次调入内存运行
            *   只需将当前要运行的那部分程序和数据装入内存即可开始运行
            *   以后每当要运行到尚未调入的那部分程序，再将它调入
            *   虚拟存储器最重要的特征
        *   对换性：
            *   无须在作业运行时一直常驻内存，在进程运行期间，允许将那些暂不使用的程序和数据从内存调至外存的对换区(换出)，等到以后需要时再从外存调至内存(换进)
            *   保证虚拟存储器正常运行
        *   虚拟性：
            *   从逻辑上扩充内存的容量，使用户所看到的内存容量远大于实际的内存容量
            *   虚拟存储器所表现出的最重要的特征，也是实现虚拟存储器的最重要目标
*   **虚拟内存技术的实现：**
    *   采用连续分配方式会使相当一部分内存空间出于暂时或永久的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存的容量，所以，虚拟内存的实现建立在**离散分配**的内存管理方式上
    *   实现的方法：
        *   请求分页存储管理
        *   请求分段存储管理
        *   请求段页式存储管理
    *   上述实现方法都需要一定的硬件支持，包括：
        *   一定容量的内存和外存
        *   页表机制(或段表机制)，作为主要的数据结构
        *   中断机构，当用户程序要访问的部分尚未调入内存时，则产生中断
        *   地址变换机构，逻辑地址到物理地址的变换



## 请求分页管理方式

*   请求分页管理在基本分页管理基础上为了支持虚拟存储器功能而增加了**请求调页功能和页面置换功能**，是最常用的实现虚拟存储器的方法

*   在请求分页系统中，只要求将当前需要的一部分页面装入内存就能启动作业运行，运行过程中，当所要访问的页面不在内存中时再通过**调页功能**将其调入，同时可通过**置换功能**将暂时不用的页面换出到外存中

*   实现请求分页还需要硬件支持：一定容量的内存和外存的计算机系统，页表机制，缺页中断机构，地址变换机构

*   **页表机构：**

    *   在基本分页系统的页表项基础上增加四个字段：

        ![img](/Users/coffeeboy/Desktop/考研/assets/c6927bd6-abdd-4bf2-8500-a90357a85578.png)

        *   状态位P：用于指示该页是否已调入内存，供程序访问时参考
        *   访问字段A：用于记录本页在一段时间内被访问的次数，或记录本页最近已有多长时间未被访问，供置换算法换出页面时用
        *   修改位M：标识该页在调入内存后是否被修改过，以确定页面置换时是否写回外存
        *   外存地址：用于指示该页在外存中的地址，通常是物理块号，供调入该页时使用

*   **缺页中断机构：**

    *   每当访问的页面不在内存中时产生一个缺页中断，请求操作系统将所缺的页调入内存，此时将缺页的进程阻塞(调页完成唤醒)
    *   若内存中有空闲块，则分配一个块，将要调入的页装入该块，并修改页表中的相应页表项
    *   若此时内存中没有空闲块，则淘汰某页(若被淘汰页在内存期间被修改过，则要将其写回外存)
    *   缺页中断作为中断，同样要经历：保护CPU环境，分析中断原因，转入缺页中断处理程序，恢复CPU环境
    *   缺页中断与一般中断的区别：
        *   在指令执行期间而非一条指令执行完后产生和处理中断信号，属于**内部异常**
        *   一条指令在执行期间，可能产生多次缺页中断

*   **地址变换机构：**

    *   先检索快表
    *   若找到要访问的页，则修改页表项中的访问位(写指令还需要重置修改位)，然后利用页表项中给出的物理块号和页内地址形成物理地址
    *   若未找到该页的页表项，则到内存中去查找页表，再对比页表项中的状态位P，判断该页是否已调入内存
        *   若页面已调入，则将该页的页表写入快表
            *   若快表已满，则需采用某种算法替换
        *   若页面未调入，则产生缺页中断，请求从外存中把该页调入内存

    ![img](/Users/coffeeboy/Desktop/考研/assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MTU2MzE2MQ==,size_16,color_FFFFFF,t_70.png)



## 页框分配

*   对于分页式的虚拟内存，在进程准备执行时，不需要将一个进程的所有页都读入到内存中，因此，**操作系统必须决定读取多少页，也就是给特定的进程分配几个页框**
*   **驻留集：**给一个进程分配的物理页框的集合就是这个进程的驻留集
*   需要考虑的问题有：
    *   分配给一个进程的页框越少，驻留在主存中的进程就越多，从而可提高CPU的利用率
    *   若一个进程在主存中的页面过少，则尽管有局部性原理，缺页率也相对较高
    *   若分配的页框过多，则由于局部性原理，对该进程的缺页率没有太明显的影响
*   **内存分配策略：**
    *   在请求分页系统中，有两种内存分配策略：固定和可变分配策略，置换时也有两种策略：全局置换和局部置换，所以组合出三种使用的策略：
        *   固定分配局部置换：
            *   为每个进程分配一定数目的物理块，在进程运行期间不改变
            *   如果发生缺页，则只能从该进程在内存中的页面中选出一页换出，然后再调入一页保证分配给该进程的内存空间不变
            *   这种策略难以确定为每个进程分配的物理块数目，太少导致缺页频繁，太多降低CPU和其他资源的利用率
        *   可变分配全局置换：
            *   先为每个进程分配一定数目的物理块，在进程运行期间可适当的增加或减少
            *   如果发生缺页，系统从空闲的物理队列中取出一块分配给该进程，并将所缺页调入
            *   这种策略比固定分配局部置换灵活，但如果盲目地给进程增加物理块会导致系统多道程序的并发能力下降
        *   可变分配局部置换：
            *   先为每个进程分配一定数目的物理块，当某进程发生缺页时，只允许从该进程在内存的页面中选出一页换出
            *   如果运行时频繁缺页，则系统再为该进程分配若干物理块，直至该进程的缺页率趋于适当程度
            *   如果运行时缺页率特别低，则可适当减少分配给该进程的物理块，但不能引起缺页率的明显增加
            *   这种策略在保证进程不会过多地调页的同时也保证了系统的多道程序并发能力
            *   但是需要更复杂的实现，更大的开销，但是对比频繁地换入/换出所浪费的计算机资源是值得的
*   **物理块调入算法：**
    *   采用固定分配策略时，将系统中的空闲物理块分配给各个进程，可采用如下算法：
        *   平均分配算法：将系统中所有可供分配的物理块平均分配给各个进程
        *   按比例分配算法：根据进程的大小按比例分配物理块
        *   优先权分配算法：为重要和紧迫的进程分配较多的物理块，通常采取的方法是把所有可分配的物理块分为两部分，一部分按比例分配给各个进程，一部分则根据优先权分配
*   **调入页面的时机：**
    *   为确定系统将进程运行时所缺的页面调入内存的时机，可采取两种调页策略：
        *   预调页策略：
            *   根据局部性原理，一次调入若干相邻的页会比一次调入一页更高效
            *   但若调入的一批页面中的大多数都未被访问，则又是低效的
            *   采用以**预测**为基础的预调页策略，将那些预计不久之后便会被访问的页面预先调入内存
            *   但目前预调页的成功率仅约为50%，因此主要用于进程的首次调入，由程序员指出应先调入哪些页
        *   请求调页策略：
            *   进程在运行时发生缺页，则提出请求，由系统将其所需页面调入内存
            *   大多数虚拟内存都采用该策略
            *   缺点是每次仅调入一页，增加了磁盘I/O开销
        *   预调页实际上是运行前的调入，请求调页实际上是运行期间调入
*   **从何处调入页面：**
    *   请求分页系统中的外存分为：存放文件的文件区，存放对换页面的对换区
    *   文件区采用离散分配方式，对换区采用连续分配方式
    *   对换区的磁盘I/O速度比文件区的更快
    *   发生缺页请求时，系统从何处将缺页调入内存就分为三种情况：
        *   系统拥有足够的对换区空间：可以全部从对换区调入所需页面，以提高调页速度，所以在进程运行前，需将与该进程有关的文件从文件区复制到对换区
        *   系统缺少足够的对换区空间：凡是不会被修改的文件都直接从文件区调入，而当换出这些页面时，由于未被修改，所以不必将它们换出，但对于那些可能被修改的部分，在将它们换出时须调到对换区，以后需要时再从对换区调入(因为读比写快)
        *   UNIX方式：与进程有关的文件都放在文件区，因此未运行过的页面都应从文件区调入，曾经运行过但又被换出的页面，由于是放在对换区，因此在下次调入时应从对换区调入，进程请求的共享页面若被其他进程调入内存，则无须再从对换区调入
*   **如何调入页面：**
    *   当进程所访问的页面不在内存中时(存在位为0)，便向CPU发出缺页中断，中断响应后便转入缺页中断处理程序
    *   中断处理程序通过查找页表来得到所需页的物理地址
        *   此时如果内存未满，则启动磁盘I/O，将所缺页调入内存，并修改页表
        *   如果内存已满，则先按某种置换算法从内存中选出一页准备换出
            *   如果被换出的页未被修改过(修改位为0)，则无须将该页写回磁盘
            *   如果被换出的页已经被修改了(修改位为1)，则必须将该页写回磁盘，然后将所缺页调入内存，并修改页表中的相应表项，置其存在位为1
    *   调入完成后，进程就可利用修改后的页表形成所要访问数据的内存地址



## 页面置换算法

*   进程运行时出现缺页中断，而内存中无空闲位置时，需要进行页面置换

*   好的页面置换算法应有较低的页面更换频率，也就是应将以后不会再访问或以后较长时间内不会再访问的页面先调出

*   **最佳(OPT)置换算法：**

    *   选择的淘汰页面是**以后永不使用的页面或在最长时间内不再被访问的页面**，以便保证获得最低的缺页率

    *   然而无法预知进程在内存下的若干页面中哪个是未来最长时间内不再被访问的，因而该算法无法实现，但可利用该算法去评价其他算法

        ![img](/Users/coffeeboy/Desktop/考研/assets/9fb8f273ea2946c587cd391d631723b2.png)

*   **先进先出(FIFO)页面置换算法：**

    *   优先淘汰最先进入内存的页面，即淘汰在内存中驻留时间最久的页面

    *   该算法实现简单，但与进程实际运行时的规律不适应，因为在进程中，有些页面经常被访问，算法性能差

    *   FIFO算法还会导致所分配的物理块数增大而页故障数也增加的异常现象，称为Belady异常，只有FIFO算法存在

        ![在这里插入图片描述](/Users/coffeeboy/Desktop/考研/assets/d0b79c03d2df4c4da6f5425c8acfd935.png)

*   **最近最久未使用(LRU)置换算法：**

    *   优先淘汰最近最长时间未访问过的页面进行淘汰

    *   该算法为每个页面设置一个访问字段，用来记录页面自上次被访问以来所经历的时间，淘汰值最大的

        ![在这里插入图片描述](/Users/coffeeboy/Desktop/考研/assets/6ff26c885ec0410c9b7ba96487ff8f03.png)

        ![在这里插入图片描述](/Users/coffeeboy/Desktop/考研/assets/bd1fc7181c9944b6a9462f4b5ed0360c.png)

    *   该算法性能较好，但需要寄存器和栈的硬件支持，LRU是堆栈类的算法，堆栈类算法不可能出现Belady异常，FIFO基于队列

*   **时钟(CLOCK)置换算法：**

    *   LRU算法的性能接近OPT算法，但实现的开销大，试图找到更小开销实现接近LRU算法的性能

    *   **简单的CLOCK置换算法：**

        *   为每一帧都设置一个访问位，当某页第一次被装入或被访问时，将其访问位置为1，设置一个替换指针，当某一页被替换时，该指针被设置指向被替换页面的下一页
        *   在选择一页淘汰时，只检查页的访问位，若为0，则换出该页，若为1，则置0，指针指向下一页，进行循环检查，直到出现一个访问位为0的页
        *   由于该算法只有一位访问位，而置换时将未使用过的页面换出，所以又称**最近未用(NRU)算法**

        ![img](/Users/coffeeboy/Desktop/考研/assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3podWl4dW5f,size_16,color_FFFFFF,t_70.jpeg)

    *   **改进型CLOCK置换算法：**

        *   将一个页面换出时，若该页已被修改过，则将该页写回磁盘，若未被修改，则不写回磁盘
        *   改进型CLOCK算法，除了考虑页面使用情况外，还增加了置换代价——修改位
        *   由**访问位A**和**修改位M**可以组合成下面四种类型的页面：
            *   A=0，M=0，最近未访问且未修改，是最佳淘汰页
            *   A=0，M=1，最近未被访问，但已被修改，不是很好的淘汰页
            *   A=1，M=0，最近已被访问，但未被修改，可能再被访问
            *   A=1，M=1，最近已被访问，也已被修改，可能再被访问
        *   算法执行过程如下：
            *   从指针的当前位置开始，扫描循环队列，寻找A=0，M=0的页面，将遇到的第一个这种页面作为选中的淘汰页，在第一次扫描期间不改变访问位A
            *   若第一轮循环中没有找到A=0，M=0的页面，则进行第二轮循环，寻找A=0，M=1的页面，将遇到的第一个这种页面作为淘汰页，在第二轮循环中，将所有扫描过的页面的访问位A都置0
            *   若第二轮循环中没有找到A=0，M=1的页面，则将指针返回到开始的位置，并将所有帧的访问位置0，重复第一步，并且如有必要执行第二步
        *   改进型CLOCK算法能减少磁盘的I/O操作次数，但是多次扫描导致开销增加



## 抖动和工作集

*   **抖动/颠簸：**刚刚换出的页面马上又要换入主存，刚刚换入的页面马上又要换出主存，这种频繁的页面调度行为
*   **产生抖动的原因：**系统中同时运行的进程太多，分配给每个进程的物理块太少
*   **导致的后果：**使在系统中排队等待页面调入/调出的进程数目增加，对磁盘的有效访问时间也急剧增加，造成每个进程的大部分时间都用于页面的换入/换出，导致处理机的利用率急剧下降并趋于零的情况
*   由于抖动的发生与系统为进程分配物理块的多少有关，于是提出了关于进程工作集的概念
*   **工作集：**在某段时间间隔内，进程要访问的页面集合
    *   工作集W由**时间t**和**工作集窗口大小b**来确定
    *   实际应用中，工作集窗口会设置得很大，即对于局部性好的程序，工作集大小一般会比工作集窗口小很多
    *   工作集反映了进程在接下来的一段时间内很有可能会频繁访问的页面集合，因此若分配给进程的物理块小于工作集大小，则该进程就很有可能频繁缺页，所以为了防止这种抖动现象，一般分配给进程的物理块书(即驻留集大小)要大于工作集大小
    *   工作集模型的原理是：
        *   让操作系统跟踪每个进程的工作集，并为进程分配大于其工作集的物理块
        *   落在工作集内的页面需要调入驻留集中，落在工作集外的页面可从驻留集中换出
        *   若还有空闲物理块，则可再调一个进程到内存
        *   若所有进程的工作集之和超过了可用物理块总数，则操作系统会暂停一个进程，将其页面调出并将物理块分配给其他进程，防止出现抖动现象



## 内存映射文件

*   **内存映射文件**将磁盘文件的全部或部分内容与进程虚拟地址空间的某个区域建立映射关系，便可直接访问被映射的文件，而不必执行文件I/O操作，也无须对文件内容进行缓存处理
*   这种特性非常适合用来管理大尺寸文件
*   只是建立磁盘地址和虚拟地址空间中的地址之间的映射关系，并没有将文件从磁盘读到内存中，相当于缺页状态，当读映射地址时，操作系统会自动将磁盘中的内容读到内存中
*   使用内存映射文件所进行的任何实际交互都是在内存中进行的，并且是以标准的内存地址形式来访问的
*   磁盘的周期性分页是由操作系统在后台隐蔽实现的，对应用程序而言是完全透明的
*   系统内存中的所有页面都由虚拟存储器负责管理，虚拟存储器以统一的方式处理所有磁盘I/O
*   当进程推出或显式得解除文件映射时，所有被改动的页面会被写回磁盘文件
*   多个进程允许并发地内存映射同一文件，以便允许数据共享
*   实际上，共享内存是通过内存映射来实现的，进程间通过共享内存来进行通信



## 虚拟存储器性能影响因素

*   **缺页率**是影响虚拟存储器性能的主要因素，且缺页率又受到**页面大小，分配给进程的物理块数(取决于工作集)，页面置换算法以及程序的编制方法**的影响
*   根据局部性原理：页面较大则缺页率较低，页面较小则缺页率较高
    *   页面较小时，一方面减少了内存碎片，有利于提高内存利用率，同时使每个进程要求较多的页面，导致页表过长，占用大量内存
    *   页面较大时，虽然可以减少页表长度，但会使页内碎片增大
*   分配给进程的物理块数越多，缺页率就越低
    *   当物理块超过某个数目时，再为进程增加一个物理块对缺页率低改善是不明显的
    *   只要保证活跃页面在内存中，保持缺页率在一个很低的范围即可
*   好的页面置换算法可使进程在运行过程中具有较低的缺页率
    *   选择LRU，CLOCK等置换算法，将未来有可能访问的页面尽量保留在内存中，从而提高页面的访问速度
*   写回磁盘的速度也影响缺页率：
    *   建立一个已修改换出页面的链表，对每个要换出的页面暂时不放入磁盘，而是放入链表中，当换出页面数达到给定值时，统一将它们写入磁盘，可显著减少磁盘I/O的次数，即减少已修改页面换出的开销
    *   如果有进程在这批数据还没写回磁盘时需要再次访问这些页面，就不需从外存调入，而直接从已修改换出页面链表上获取，可减少页面从磁盘读入内存的频率，减少页面换进的开销
*   编写程序的局部化程序越高，执行时的缺页率就越低
    *   如果存储采用的是按行存储，访问时就要尽量采用相同的访问方式，避免按列访问造成缺页率过高的现象



## 习题

*   虚拟存储技术并未实际扩充内存，外存，而是采用相关技术相对地扩充主存，所以扩充的是内存逻辑空间

*   无论采用什么页面置换算法，每种页面第一次访问时不可能在内存中，必然发生缺页，所以缺页次数大于或等于n

*   若采用FIFO页面淘汰算法，可能会产生当驻留集增大时页故障数不减反增的Belady异常，所以若采用FIFO，当可供分配的页帧数增加时，缺页中断的次数可能增加，也可能减少

*   虚拟存储器的实际容量由主存容量和外存容量的和决定，而最大容量由计算机的地址结构决定

*   LRU算法需要对所有页最近一次被访问的时间进行记录，查找时间最久的进行替换，这涉及排序，为此需要在页表项中增加LRU位，所以LRU算法开销大的根本原因是需要对所有的页进行排序，表现出来的后果就是需要硬件的特殊支持

*   页表项中的合法位信息显示本页面是否在内存中，即决定了是否会发生页面故障(缺页中断)

*   所有的页面调度策略都不可能完全避免抖动

*   内存抖动是由页面置换算法不合理引起的一种现象

*   采用多级页表时，最高级页表项不能超出一页大小，可通过一页能容纳多少页表项来判断出需要使用几级页表

*   当系统处于频繁的换入/换出过程中，即使采用更快的磁盘交换区，其换入/换出频率也不会改变，对提高CPU的利用率无用

*   当发生了缺页中断后，之后的操作不会出现越界错误

*   影响请求分页系统有效访存时间的有：缺页率，磁盘读写时间，内存访问时间，执行缺页处理程序的CPU时间

    *   缺页率影响缺页中断的频率，缺页率越高，平均访存时间越长
    *   磁盘读写时间和内存访问时间影响缺页中断的处理时间，中断处理时间越长，平均访存时间越长
    *   执行缺页中断处理程序的CPU时间影响访问页表和访问目标物理地址的时间

*   页面引用串也称页面走向，指的是调用页面的顺序串，比如：4，2，5，1，5，3，2，3，4，1，5

*   覆盖技术与虚拟存储技术的区别：

    *   覆盖程序段段最大长度受内存容量大小限制，虚拟存储器中的程序最大长度不受内存容量大小限制，而是受到计算机地址结构的限制
    *   覆盖技术中的覆盖段由程序员设计，且其要求覆盖段中的各个覆盖具有相对独立性，不存在直接联系或相互交叉访问

*   交换技术与虚拟存储里的调入/调出的区别：

    *   交换技术是把暂时不用的某个程序及数据从内存移到外存中，来腾出必要的内存空间，交换技术调入/调出整个进程，一个进程的大小要受到内存容量大小的限制
    *   虚拟存储中调入/调出技术在内存和外存之间来回传递的是页面或分段，而不是整个进程，从而使进程的地址映射具有更大的灵活性，且允许进程的大小比可用的内存空间大

*   求物理地址时：

    ```c
    页框号为101H，偏移量为565H 12位偏移量
        101H：0001 0000 0001
        565H：0101 0110 0101
        物理地址：0001 0000 0001 0101 0110 0101 = 101565H
        
    页框号为7，一页大小为1KB，偏移量为3CAH，10位偏移量
        7H：0111
        3CAH：11 1010 1100
        物理地址：0001 1111 1010 1100 =1FCAH
    ```

*   缺页的次数与内存中数据存放的方式及程序执行的顺序有很大关系



![虚拟内存管理 (1)](/Users/coffeeboy/Desktop/考研/assets/虚拟内存管理 (1).png)





# 文件管理

## 文件系统基础

### 文件的概念

*   **文件：**以硬盘为载体的存储在计算机上的信息集合，文件可以是文本文档，图片，程序等
*   系统运行时，计算机以**进程为基本单位**进行资源等调度和分配
*   用户进行的输入，输出中，以**文件为基本单位**
*   文件的结构：
    *   数据项：文件系统中最低级的数据组织形式，可分为：
        *   基本数据项：用于描述一个对象的某种属性的一个值，是数据中的最小逻辑单位
        *   组合数据项：由多个基本数据项组成
    *   记录：一组相关的数据项的集合，用于描述一个对象在某方面的属性
    *   文件：由创建者所定义的，具有文件名的一组相关元素的集合，可分为：
        *   有结构文件：文件由若干个相似的记录组成
        *   无结构文件：被视为一个字符流，比如一个二进制文件或字符文件
*   **为什么我们需要文件系统？**
    *   当用户将文件用于程序的输入，输出时，还想要可以访问，修改和保存文件，实现对文件的维护管理，所以需要一个文件管理系统来进行统一管理



### 文件控制块和索引结点

*   **文件的属性：**

    *   名称：文件名称唯一，以容易读取的形式保存
    *   类型：被支持不同类型的文件系统所使用
    *   创建者：文件创建者的ID
    *   所有者：文件当前所有者的ID
    *   位置：指向设备和设备上文件的指针
    *   大小：文件当前大小(用字节，字或块来表示)，也包含文件允许的最大值
    *   保护：对文件进行保护的访问控制信息
    *   创建时间，最后一次修改时间和最后一次存取时间：文件创建，上次修改和上次访问的相关信息，用于保护和跟踪文件的使用

*   **文件控制块(FCB)：**用来存放控制文件需要的各种信息的数据结构，来实现**按名存取**

*   FCB的有序集合称为**文件目录**，一个FCB就是一个**文件目录项**

*   为了创建一个新文件，系统将分配一个FCB并存放在文件目录中，称为**目录项**

*   FCB主要包含：

    *   **基本信息：**如文件名，文件的物理地址，文件的逻辑结构，文件的物理结构等
    *   **存取控制信息：**包括文件主的存取权限，核准用户的存取权限以及一般用户的存取权限
    *   **使用信息：**如文件建立时间，上次修改时间等

*   一个文件目录也被称为一个文件，称为目录文件

    ![img](/Users/coffeeboy/Desktop/考研/assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxNTg3NzQw,size_16,color_FFFFFF,t_70.png)

*   **索引结点：**一个存放文件描述信息的数据结构，简称**i结点(inode)**

*   **为什么需要索引结点？**

    *   在查找一个文件的时候，需要从多级目录中进行查找，所以需要不断从磁盘中将目录调入到内存中进行查找，如果每个目录中存放的都是整个FCB，则当文件数多时一个目录将非常大，所以我们可以将一个文件分为两部分：文件名和一个索引指针，这样将大大减小目录的大小，减少平均启动磁盘次数，**查找文件时可以大大减少其I/O信息量**

*   **磁盘索引结点：**存放在磁盘上的索引结点，每个文件有唯一的磁盘索引结点，主要包括：

    *   文件主标识符：拥有该文件的个人或小组的标识符
    *   文件类型：包括普通文件，目录文件或特别文件
    *   文件存取权限：各类用户对该文件的存取权限
    *   文件物理地址：每个索引结点中含有13个地址项，即iaddr(0)-iaddr(12)，以直接或间接方式给出数据文件所在盘块的编号
    *   文件长度：指以字节为单位的文件长度
    *   文件链接计数：在本文件系统中所有指向该文件的文件名的指针计数
    *   文件存取时间：本文件最近被进程存取的时间，最近被修改的时间及索引结点最近被修改的时间

*   **内存索引结点：**存放在内存中的索引结点，当文件被打开时，要将磁盘索引结点复制到内存的索引结点，在磁盘索引结点的基础上增加了以下几项：

    *   索引结点编号：用于标识内存索引结点
    *   状态：指示**i结点**是否上锁或被修改
    *   访问计数：每当有一进程要访问此**i结点**时，计数加1，访问结束减1
    *   逻辑设备号：文件所属文件系统的逻辑设备号
    *   链接指针：设置分别指向空闲链表和散列队列的指针



### 文件的操作

*   操作系统提供系统调用，它对文件进行创建，写，读，重定位，删除，截断等操作
    *   **创建文件：**创建文件有两个必要步骤：
        *   为新文件分配必要的外存空间
        *   在目录中为之创建一个目录项，目录项记录了新文件名，在外存中的地址及其他可能的信息
    *   **写文件：**执行一个系统调用
        *   对于给定文件名，搜索目录以查找文件位置
        *   系统必须为该文件维护一个写位置的指针，每当发生写操作时，便更新写指针
    *   **读文件：**执行一个系统调用
        *   搜索目录找到对应的目录项
        *   维护一个读位置的指针，每当发生读操作时，更新读指针
        *   一个进程通常只对一个文件读或写，所以当前操作位置就是每个进程当前文件位置的指针
        *   由于读和写操作都使用同一个指针，因此节省了空间，降低了系统复杂度
    *   **重新定位文件：**也称文件定位
        *   搜索目录找到对应的目录项，并将当前文件位置指针重新定位到给定值
        *   重新定位文件不涉及读，写文件
    *   **删除文件：**
        *   先从目录中检索指定文件名的目录项，然后释放该文件所占的存储空间，以便可被其他文件重复使用，并删除目录条目
    *   **截断文件：**
        *   允许文件所有属性不变，并删除文件内容，将其长度置为0并释放其空间
*   当用户对一个文件实施操作时都需要从检索目录开始，为了避免多次重复地检索目录，使用**系统调用open**进行显式打开
*   操作系统中维护一个包含所有已经打开的文件信息的表：**打开文件表**
*   使用调用open打开一个文件时：
    *   根据文件名搜索目录，将文件的属性(包含该文件在外存上的物理地址)，从外存**复制**到内存**打开文件表**的一个表目中，并将该表目的编号(索引)返回给用户
    *   当用户再次访问该文件时，直接通过索引在**打开文件表**中查找文件信息，节省再次搜索目录的开销
*   当文件不再使用时，利用系统调用close关闭一个文件：
    *   从**打开文件表**中删除这一条目
*   在多进程系统中，通常采用两级表：整个系统表，每个进程表
    *   系统表包含FCB的副本及其他信息
    *   进程表包含进程打开的所有文件和指向系统表中适当条目的指针(当多个进程打开同一个文件，而系统表中已经存放了FCB)
*   系统表为每个文件关联一个**打开计数器(Open Count)**，记录多少进程打开了该文件，当计数器为0时，表示该文件不再被使用，可从系统打开文件表中删除相应条目
*   文件名不必是打开文件表中条目的一部分，因为完成了对FCB在磁盘上的定位，系统就不再使用文件名
*   对于访问打开文件表的索引，UNIX称为**文件描述符**，Windows称为**文件句柄**

*   每个打开文件包含：
    *   **文件指针：**读/写指针，对一个进程来说是唯一的，要与磁盘文件属性分开保存
    *   **文件打开计数：**计数器跟踪当前文件打开和关闭的数量
    *   **文件磁盘位置：**大多数文件操作要求修改文件数据，查找磁盘上的文件所需的信息保存在内存中，方便修改
    *   **访问权限：**每个进程打开文件都需要有一个访问模式(创建，只读，读写，添加等)，该信息保存在进程的打开文件表中，以便操作系统能够允许或拒绝后续的I/O请求



### 文件保护

*   **为什么需要进行文件保护？**
    *   为了防止文件共享导致文件被破坏或未经核准的用户修改文件，文件系统必须控制用户对文件的存取
*   文件保护机制有：口令保护，加密保护，访问控制
    *   口令和加密是为了防止用户文件被他人存取或窃取
    *   访问控制则用于控制用户对文件的访问方式
*   **访问类型：**
    *   读：从文件中读
    *   写：从文件中写
    *   执行：将文件装入内存并执行
    *   添加：将新信息添加到文件结尾部分
    *   删除：删除文件，释放空间
    *   列表清单：列出文件名和文件属性
*   一些高级功能比如重命名，复制，编辑可以通过系统程序调用低层系统调用来实现
*   **访问控制：**最常用的方法为根据用户身份进行控制，为每个文件和目录增加一个**访问控制列表(Access-Control List,ACL)**来规定每个用户名及其所允许的访问类型
    *   优点：可以使用复杂的访问方法
    *   缺点：长度无法预计并且可能导致复杂的空间管理，可以使用精简的访问列表来解决
*   **精简访问列表**中的用户类型：拥有者，组和其他
    *   拥有者：创建文件的用户
    *   组：一组需要共享文件且具有类似访问的用户
    *   其他：系统内的所有其他用户
*   系统在创建文件时将创建文件的用户的名字，所属的组存入该文件的FCB中
    *   用户访问该文件时，若用户是文件主，按照文件主所拥有的权限进行访问
    *   若用户和文件主在同一个组内，则按照同组权限访问
    *   否则按其他用户权限访问
*   **口令：**
    *   口令是指用户在建立一个文件时提供一个口令，系统为其建立FCB时附上相应口令，同时告知共享该文件的其他用户
    *   当用户请求访问时必须提供相应的口令
    *   优点：这种方法在时间和空间上的开销不多
    *   缺点：口令直接存在系统内部，不够安全
*   **密码：**
    *   用户对文件进行加密，文件被访问时需要使用密钥
    *   优点：保密性强，节省了存储空间
    *   缺点：编码和译码需要时间
*   口令和密码都是防止用户文件被他人存取或窃取，并没有控制用户对文件的访问类型
*   现代操作系统常用的文件保护方法：将访问控制列表和用户，组，其他成员访问控制方案一起组合使用
*   对于多级目录结构：不仅需要保护单个文件，而且需要保护子目录内的文件，即需要提供目录保护机制，目录操作和文件操作不同，需要提供不同的保护机制



### 文件的逻辑结构

*   文件的逻辑结构与存储介质特性无关，实际上指的是在文件的内部，数据逻辑上是如何组织起来的

*   按逻辑结构分为：无结构文件，有结构文件

*   **无结构文件：(流式文件)**

    *   最简单的文件组织形式
    *   无结构文件将数据按顺序组织成记录并积累，保存
    *   是有序相关信息项的集合，以字节(Byte)为单位
    *   由于没有结构，对记录的访问只能通过**穷举搜索**的方式，因此这种文件形式对大多数应用不适用
    *   但是字符流的无结构文件管理简单，用户可以方便地对其进行操作
    *   对基本信息单位操作不多的文件较适于采用字符流的无结构方式，如源程序文件，目标代码文件

*   **有结构文件：(记录式文件)**

*   按记录的组织形式可分为：顺序文件，索引文件，索引顺序文件，直接文件或散列文件(Hash File)

    *   **顺序文件：**文件中的记录按顺序排列，记录通常是定长的，可以顺序存储或以链表形式存储

        *   顺序文件有以下两种结构：串结构，顺序结构
            *   **串结构：**记录之间的顺序与关键字无关，通常按存入时间的先后进行排列，对串结构文件进行检索必须从头开始顺序依次查找，比较费时
            *   **顺序结构：**指文件中的所有记录按关键字顺序排列，可采用折半查找法，提高了检索效率
        *   在对记录进行**批量操作**时，顺序文件的效率是所有逻辑文件中最高的
        *   对于顺序存储设备，如磁带，**只有**顺序文件才能被存储并能有效工作
        *   在经常需要查找，修改，增加或删除单个记录的场合，顺序文件的性能也比较差

    *   **索引文件：**变长记录文件只能顺序查找，效率低，所以可以建立一张索引表，为主文件的每个记录在索引表中分别设置一个表项

        *   索引表表项包含：指向记录的逻辑起始地址的指针，记录的长度

        *   索引表按关键字排序，本身也是一个定长记录的顺序文件

        *   这样将对变长记录顺序文件的检索转变为对定长记录索引文件的随机检索，加快了记录的检索速度

            ![输入图片说明](/Users/coffeeboy/Desktop/考研/assets/110007_7abf7d1f_508704.png)

    *   **索引顺序文件：**顺序文件和索引文件的结合

        *   将顺序文件中的所有记录分为若干组，为顺序文件建立一张索引表

        *   在索引表中为每组的第一条记录建立一个索引项，包含：该记录的关键字值，指向该记录的指针

            ![文件存储 架构 文件架构分为_顺序查找_04](/Users/coffeeboy/Desktop/考研/assets/resize,m_fixed,w_1184)

        *   同一组内的关键字可以无序，但组与组之间的关键字必须有序

        *   查找一条记录时，首先通过索引表找到其所在的组，然后在该组中使用顺序查找，就能很快找到记录

        *   对于N条记录，查找某关键字的记录时，若是顺序文件，平均需要N/2次，若是索引顺序文件，平均需要$\sqrt{N}$次

        *   索引文件和索引顺序文件都提高了存取的速度，但是配置索引表增加了存储空间

    *   **直接文件或散列文件(Hash File)：**

        *   给定记录的健值或通过散列函数转换的健值直接决定记录的物理地址
        *   不同于顺序文件或索引文件，**没有顺序的特性**
        *   散列文件有很高的存取速度，但是会引起冲突，即不同关键字的散列函数值相同



### 文件的物理结构

*   文件的逻辑结构是**从用户观点出发看到的文件的组织形式**，文件的物理结构(文件的存储结构)是从实现观点出发看到的文件**在外存上的存储组织形式**

*   **如何为文件分配磁盘块？**有连续分配，链接分配，索引分配

    *   **连续分配：**要求每个文件在磁盘上占有一组连续的块

        ![图 1 磁盘空间的连续分配](/Users/coffeeboy/Desktop/考研/assets/20210727152430400.gif)

        *   逻辑文件中的记录也顺序存储在相邻接的块中
        *   一个文件的目录项中“文件物理地址”字段应包括：第一块的地址，该文件所分配区域的长度
        *   连续分配支持顺序访问，直接访问
        *   优点：实现简单，存取速度快
        *   缺点：
            *   文件长度不宜动态增加，因为一个文件末尾后的盘块可能已分配给其他文件，一旦需要增加，就需要大量移动盘块
            *   为保持文件的有序性，删除和插入都需要对相邻的记录做物理上的移动，还会动态改变文件的长度
            *   反复删除文件后会产生外部碎片
            *   很难确定一个文件需要的空间大小，因而只适用于长度固定的文件

    *   **链接分配：**离散分配

        *   消除了磁盘的外部碎片，提高了磁盘的利用率，可以动态地为文件分配盘块，对文件的插入，删除，修改也非常方便，分为隐式链接，显式链接

            *   **隐式链接：**

                *   目录项中含有文件的第一块磁盘的指针和最后一块磁盘的指针

                *   每个文件对应一个磁盘块的链表

                *   只适合顺序访问，随机访问效率很低

                *   稳定性有问题：系统在运行过程中由于软件或硬件错误导致链表中的指针丢失或损坏，会导致文件数据的丢失

                *   解决方法：将几个盘块组成**簇(cluster)**，按簇而不是块来分配，可以成倍地减少查找时间，代价是增加了内部碎片

                *   使用簇可以改善许多算法的磁盘访问时间，因此应用于大多数操作系统

                    ![img](/Users/coffeeboy/Desktop/考研/assets/assets%2F-MEmUhsvIFBb8ar2-Um3%2F-MFVqzp4gYCaGTb63ovP%2F-MFVrVAkd6wYgx-FkndX%2Fimage.png)

            *   **显式链接：**

                *   把用于链接文件各物理块的指针，从每个物理块的末尾中提取出来，显式地存放在**内存的一张链接表**中

                *   该链接表在整个磁盘中仅设置一张，称为**文件分配表(File Allocation Table,FAT)**

                *   每个表项中存放链接指针，即下一个盘块号

                *   文件的第一个盘块号存放在目录项“物理地址”字段中，后续的盘块可以通过查找FAT获得

                *   FAT的表项与全部磁盘块进行对应，可以用-1表示文件的最后一块，用-2(-3,-4)来表示该磁盘是空闲的

                *   FAT不仅记录了文件各块之间的先后链接关系，同时标记了空闲的磁盘块，操作系统可以通过FAT对文件存储空间进行管理

                *   FAT表在系统启动时就会被读入内存中，所以查找记录之间在内存中进行，提高了检索速度，减少了访问磁盘的次数

                    ![img](/Users/coffeeboy/Desktop/考研/assets/assets%2F-MEmUhsvIFBb8ar2-Um3%2F-MFVu-6UNsEcQ3Cggo-w%2F-MFVu1phIN2Zv0ps2tq4%2Fimage.png)

    *   **索引分配：**链接分配解决了连续分配存在的外部碎片和文件大小管理的问题，但是存在**不能有效支持直接访问(FAT除外)**和**FAT需要占用较大的内存空间**的问题

        *   索引分配将每个文件所有的盘块号集中在一起构成**索引块(表)**

            ![img](/Users/coffeeboy/Desktop/考研/assets/assets%2F-MEmUhsvIFBb8ar2-Um3%2F-MFVvP35JOaqI_DXkqxD%2F-MFVvhhQdUyT39ugdXFh%2Fimage.png)

        *   每个文件都有对应的一个或多个索引块

        *   索引块的第i个条目指向文件的第i个块，要读第i个块，通过索引块的第i个条目的指针来查找和读入所需的块

        *   索引分配的优点是：支持直接访问，且没有外部碎片问题

        *   缺点是：由于索引块的分配，增加了系统存储空间的开销

        *   当索引块太小时就无法支持大文件，可以采用以下机制来解决：

            *   链接方案：可以使用多个索引块，并将它们链接起来
            *   多层索引：通过第一层索引来指向第二层索引块，再通过第二层索引块来查找文件块
            *   混合索引：将多种索引分配方式相结合

        *   访问文件需要两次访问外存，先读取索引块的内容，再读取具体的磁盘块，降低了文件的存取速度，所以通常将文件的索引块读入内存，提高访问速度

    *   **混合索引分配：**能针对小型，中型，大型，特大型文件进行不同的分配方式

        *   对于小型文件：为了提高对众多小文件的访问速度，将它们的每个盘块地址直接放入FCB中，即为**直接寻址**

        *   对于中型文件：采用单级索引方式，需要先从FCB中找到该文件的索引表，从中获得该文件的盘块地址，即**一次间址**

        *   对于大型文件：采用两级索引方式

        *   对于特大型文件：采用三级索引方式

        *   UNIX系统采用的就是这种分配方式，在其索引结点中，设有13个地址项，即i.addr(0)~i.addr(12)

            ![img](/Users/coffeeboy/Desktop/考研/assets/v2-e80f68fa78fc781ab4a3b14201a5ec7a_1440w.webp)

        *   **直接地址：**在索引结点中设置10个直接地址项，即用i.addr(0)~i.addr(9)来存放直接地址(指针)，即文件数据盘块的盘块号，假如每个盘块的大小为4KB，当文件不大于40KB时，便可直接从索引结点中读出该文件的全部盘块号

        *   **一次间接地址：**利用i.addr(10)来提供一次间接地址，存放索引块的地址，一次间址块中可存放1024个盘块号，因此允许文件长达4MB

        *   **多次间接地址：**当文件长度大于4MB+40KB时，可采用二次间接地址分配或三次间接地址分配，使用i.addr(11)提供二次间接地址，其允许文件最大长度可达4GB，使用i.addr(12)作为三次间址块，其允许文件最大长度可达4TB



### 习题

*   UNIX操作系统中，所有设备都视为特殊的文件
*   UNIX操作系统中，控制和访问外部设备的方式和访问一个文件的方式是相同的
*   打开文件之前要先找到指定的文件目录，打开文件操作是将该文件的FCB存入内存的活跃文件目录表中
*   目录文件是FCB的集合，一个目录中既可能有子目录，也可能有数据文件，因此目录文件中存放的是子目录和数据文件的信息
*   采用索引结点可在查找文件时大大减少其I/O信息量
*   访问控制机制的安全性比加密保护机制差，但灵活性好，访问控制机制由系统来实现
*   系统级安全管理包括注册和登录
*   逻辑结构中的索引是为了加快文件数据的定位，是从用户角度出发的，物理结构中的索引是为了管理不连续的物理块，是从系统角度出发
*   采用索引顺序文件时，共有10000条记录，可分为100组，每组100条记录，平均查找次数为：100组的平均查找次数+100条记录的平均查找次数 = (100 + 1) / 2  + (100 + 1) / 2 = 101次
*   直接存取即随机存取，采用连续分配和索引分配的文件都适合于直接存取方式，只有采用链接分配的文件不具有随机存取的特性
*   顺序文件占用连续的磁盘空间，容易导致存储碎片(外部碎片)的产生
*   索引表的表项中含有相应记录的关键字和存放该记录的逻辑地址
*   三级索引需要访问4次磁盘
*   无论是顺序存取还是随机存取，顺序文件通常都是速度最快的
*   索引结构适合随机存取且适合动态扩展
*   当所读文件的数据不在内存中时，产生中断(缺页中断)，原进程进入阻塞态，直到所需数据从外存中调入内存，才将进程唤醒
*   read系统调用通过陷入将CPU从用户态切换到核心态，从而获取操作系统提供的服务
*   open指令中的参数包含文件的路径名和文件名，并返回文件描述符，之后使用read或write直接使用文件描述符而不是文件名
*   read要求用户提供三个参数：文件描述符fd，buf缓冲区首址，传送的字节数n
*   提前读是指在读当前盘块时，将下一个可能要访问的盘块数据读入缓冲区中，以便需要时直接从缓存区中读取，提高文件的访问速度
*   延迟写是指先将数据写入缓存区，并置上“延迟写”标志，当缓冲区需要分配给其他文件时，才将缓冲区数据写入磁盘，来减少访问磁盘的次数，提高文件的访问速度

*   |          | 优点                                                     | 缺点                                                         |
    | -------- | -------------------------------------------------------- | ------------------------------------------------------------ |
    | 连续分配 | 可以随机访问(磁盘)，访问速度快                           | 要求有连续的存储空间，容易产生碎片，降低磁盘空间利用率，不利于文件的增长扩充 |
    | 链接分配 | 不要求连续的存储空间，能有效利用磁盘空间，有利于扩充文件 | 只适合顺序访问，不适合随机访问，链接指针占用一定的空间，降低了存储效率，可靠性较差 |
    | 索引分配 | 既支持顺序访问也支持随机访问，查找效率高，便于文件删除   | 索引表占用一定的存储空间                                     |

    将FCB分解成两部分：文件的基本信息和指向另一部分的指针，其他信息，将其他信息存放在磁盘的另一个地方，而文件的基本信息和指针放在目录中也存放在磁盘中，所以先要检索目录后再通过指针去读取另一块磁盘，来找齐FCB的所有内容，虽然加快了检索的速度，但是多了一次访问磁盘的次数

*   将FCB分解成两部分：文件名，指向索引结点的指针，**索引结点：**一个存放文件描述信息的数据结构，简称i结点
*   索引结点又分为磁盘索引结点和内存索引结点，当文件被打开时，将磁盘索引结点复制到内存的索引结点中
*   FCB(文件控制块)的有序集合就称为**文件目录**，一个FCB就是一个文件目录项，一个文件目录也可以作为一个文件，称为**目录文件**
*   索引表：当文件的逻辑结构是索引结构或索引顺序结构时，为文件建立一个索引表，记录文件中每个目录项，包含：指向变长记录的指针，记录的长度，而索引顺序结构中又将各目录按关键字进行排序分组，每组使用一个指针

*   当讨论文件的物理结构时，又引申出了文件分配表(FAT)，索引块，索引结点中的内容
    *   当使用**链接分配中的显式链接**时，使用一个FAT来保存所有文件的磁盘指针，将此表存放在内存中，虽然还是链接分配，必须一个指针一个指针地进行查找，但是因为在内存中，所以不需要进行磁盘引用
    *   当使用**索引分配**时，每个文件都有一个索引块，存放指向文件的各个物理块的指针
    *   当使用**混合索引分配**时，引申了UNIX系统中的索引结点的13个地址项：i.addr(0)~i.addr(12)
*   所以，索引结点是每个文件都有的，索引表和FAT是只有采用特定的分配方式时才有
*   当访问一个磁盘的时候，可以访问该磁盘上的所有内容，一个磁盘块很大可以存放很多信息，所以就可以一次访问多个目录项
*   FAT的每个表项中存放的是下一个块号或簇号



## 目录

*   FCB的有序集合称为文件目录，一个FCB就是一个文件目录项



### 目录结构

*   **单级目录结构：**整个文件系统中只建立一张目录表，每个文件占一个目录项

    *   当访问一个文件时，先按文件名在该目录下查找到相应的FCB，经合法性检查后执行相应的操作
    *   当建立一个文件时，必须先检索所有目录项，以确保没有“重名”的情况，然后在该目录中增设一项，把新文件的属性信息填入该项中
    *   当删除一个文件时，先从目录中找到该文件的目录项，回收该文件所占用的存储空间，然后清除该目录项
    *   单级目录结构实现了“按名存取”，但是存在**查找速度慢，文件不允许重名，不便于文件共享，不适用于多用户系统**

*   **两级目录结构：**将文件目录分为主文件目录，用户文件目录

    ![img](/Users/coffeeboy/Desktop/考研/assets/1-140F1162SXT.jpg)

    *   主文件目录项：记录用户名和相应用户文件目录所在的存储位置
    *   用户文件目录项：记录该用户文件的FCB信息
    *   当某用户对其文件进行访问时，搜索该用户对应的UFD再进行访问
    *   优点：
        *   解决了不同用户文件之间的重名问题，也在一定程度上保证了文件的安全，提高了检索的速度，文件系统可以在目录上实现访问限制
    *   缺点：
        *   缺乏灵活性，不能对文件分类

*   **树形目录结构：**对两级目录结构进行推广

    *   当用户要访问某个文件时，用文件的路径名标识文件，文件路径名是个字符串
    *   从根目录出发的路径称为**绝对路径**
    *   当层次太多时，每次从根目录查询会浪费时间，于是有了**当前目录(工作目录)**，进程对各文件的访问都是相对于当前目录进行的
    *   当用户要访问某个文件时，使用相对路径标识文件，**相对路径**是从当前目录出发到所找文件通路上所有目录名与数据文件名用分隔符`/`链接而成
    *   `/dev/hda`就是一个绝对路径，若当前目录为`/bin`，则`./ls`就是相对路径，`·`表示当前工作目录
    *   每个用户都有各自的“当前目录”，登录后自动进入该用户的“当前目录”，操作系统提供一条专门的系统调用，供用户随时改变“当前目录”
    *   优点：可以很方便地对文件进行分类，层次结构清晰，能更有效地进行文件的管理和保护
    *   缺点：需要按路径名逐次访问中间结点，增加了磁盘访问次数
    *   大多数操作系统如UNIX，Linux，Windows都采用了树形文件目录

*   **无环图目录结构：**

    *   树形目录结构能便于实现文件分类，但不便于实现文件共享，在树形目录结构的基础上，增加一些指向同一结点的有向边，使整个目录成为一个有向无环图

        ![img](/Users/coffeeboy/Desktop/考研/assets/1-140F11634005Q.jpg)

    *   为每个共享结点设置一个共享计数器

        *   每当图中增加对该结点的共享链时，计数器加1
        *   每当某用户提出删除该结点时，计数器减1
        *   当共享计数器为0时，才真正删除该结点，否则只删除请求用户的共享链

    *   对于共享文件，只存在一个真正的文件，任何改变都会为其他用户所见

    *   优点：方便地实现了文件的共享

    *   缺点：使系统的管理变得更加复杂



### 目录的操作

*   **搜索：**当用户使用一个文件时，需要搜索目录，来找到该文件的对应目录项
*   **创建文件：**当创建一个新文件时，需要在目录中增加一个目录项`mkdir`
*   **删除文件：**当删除一个文件时，需要在目录中删除相应的目录项`rmdir`
*   **创建目录：**在树形目录结构中，用户可创建自己的用户文件目录，并可再创建子目录
*   **删除目录：**
    *   不能删除非空目录，删除时必须要先删除目录中的所有文件，并递归地删除子目录之后才能删除该目录`rmdir`
    *   可删除非空目录，目录中的文件和子目录同时被删除`rm -rf`
*   **移动目录：**将文件或子目录在不同的父目录之间移动，文件的路径名也会随之改变
*   **显示目录：**用户可以请求显示目录的内容，如显示该用户目录中的所有文件及属性`ls`
*   **修改目录：**某些文件属性保存在目录中，因而这些属性的变化需要改变相应的目录项



### 目录实现

*   目录实现的方法有**线性列表**和**哈希表**
*   线性列表实现对应线性查找，哈希表实现对应散列查找
*   **线性列表：**采用文件名和数据块指针的线性列表
    *   当创建新文件时，必须首先搜索目录以确定没有同名的文件存在，然后在目录中增加一个新的目录项
    *   当删除文件时，根据给定的文件名搜索目录，然后释放分配给它的空间
    *   采用链表结构可以减少删除文件的时间
    *   优点：
        *   实现简单
    *   缺点：
        *   查找比较费时
*   **哈希表：**根据文件名得到一个值，并返回一个指向线性列表中元素的指针
    *   优点：查找非常迅速，插入和删除也较简单，不过需要一些措施来避免冲突(两个文件名哈希到同一位置)
    *   目录查询通过在磁盘上反复搜索完成，需要不断进行I/O操作，开销较大
    *   为了减少I/O操作，把当前使用的文件目录复制到内存中



### 文件共享

*   文件共享使多个用户共享同一个文件，系统中只需保留该文件的一个副本
*   现代常用的两种文件共享方法：基于**索引结点**的共享方式(硬链接)，利用**符号链**实现文件共享(软链接)
*   **硬链接：**
    *   在文件目录中只设置**文件名和指向相应索引结点的指针**
    *   文件的物理地址，其他的文件属性不再放在目录项中，而是放在索引结点中，索引结点中还有一个链接计数count，表示链接到本索引结点(即文件)上的用户目录项的数目
    *   当A新创建一个文件时，A便是该文件的所有者，count置1，用户B想要共享该文件时，在B的目录中增加一个目录项，并设置一个指针指向该文件的索引结点
    *   只有当count=0时，表示没有用户使用该文件，才删除该文件
*   **软链接：**
    *   当用户B共享用户A的文件F时，由系统创建一个LINK类型的新文件，也取名为F，并将该文件写入用户B的目录中，来实现用户B的目录与文件F的链接，也称为**符号链接**
    *   **B中的文件F只包含路径名**
    *   当用户B想要访问F时，操作系统查看是否是LINK类型的文件，根据该文件的路径名找到F，然后进行操作
    *   这种共享方式，只有文件主才有共享文件的索引结点的指针，共享该文件的其他用户只有路径名，这样不会发生读空指针的情况，当用户主删除该文件时，其他用户访问会失败并将符号链删除，不会产生任何影响
    *   因为是根据路径名逐个查找，所以要多次读磁盘，开销较大，符号链的索引结点也要消耗一定的磁盘空间
    *   利用符号链进行**网络文件共享**时，只需提供该文件所在机器的网络地址和文件路径名
*   软链接和硬链接都是静态共享方法，当两个进程同时对一个文件进行操作时成为动态共享
*   硬链接的查找速度比软链接的速度快



### 习题

*   路径名的一个分量未找到，说明路径名中的某个目录或文件不存在，不需要继续检索
*   文件在磁盘上通常采用连续存放方法，在硬盘上通常不采用连续存放方法，在内存上采用随机存放方法
*   对文件的访问控制，常由用户访问权限和文件属性共同限制，与用户优先级无关
*   防止文件受损常采用备份的方法，存取控制矩阵方法用于多用户之间的存取权限保护
*   建立符号链接时，将计数器count进行复制，且共享用户删除时，其他共享用户的count不变
*   用户进程的打开文件表关于同一个共享文件不一定相同，例如读写指针位置不一样
*   进程关闭文件时，文件的引用计数减1，引用计数变为0时，删除系统打开文件表中的表项



## 文件系统

### 文件系统结构

*   **文件系统(File System)**提供高效和便捷的磁盘访问，以便允许存储，定位，提取数据
*   一个合理的文件系统层次结构包括：设备，I/O控制，基本文件系统，文件组织模块， 逻辑文件系统，应用程序

*   **I/O控制：**(与硬件的接口)
    *   包括设备驱动程序和中断处理程序，在内存和磁盘系统之前传输信息
    *   设备驱动程序将输入的命令翻译成底层硬件的特定指令，硬件控制器利用这些指令使I/O设备与系统交互
*   **基本文件系统：**(管理缓存，向I/O发送命令)
    *   向对应的设备驱动程序发送通用命令，来读取和写入磁盘的物理块
    *   该层也管理内存缓冲区，并保存各种文件系统，目录和数据块的缓存
    *   在进行磁盘块传输前，分配合适的缓冲区，并对缓冲区进行管理
*   **文件组织模块：**(地址转换，空闲空间管理)
    *   组织文件及其逻辑块和物理块
    *   **文件组织模块将逻辑块地址转换为物理块地址**
    *   文件组织模块还包括空闲空间管理器，来跟踪未分配的块，根据需求提供给文件组织模块
*   **逻辑文件系统：**(管理目录结构和文件系统的所有结构，文件保护)
    *   用于管理元数据信息，**元数据：**包括文件系统的所有结构，而不包括实际数据(或文件内容)
    *   逻辑文件系统管理目录结构，以便根据给定文件名称为文件组织模块提供所需信息
    *   通过文件控制块FCB来维护文件结构
    *   也负责文件保护

>另一个版本：
>
>![img](/Users/coffeeboy/Desktop/考研/assets/1-140F11J145964.jpg)
>
>*   用户调用接口：
>    *   文件系统为用户提供与文件及目录有关的调用，如新建、打开、读写、关闭、删除文件，建立、删除目录等。此层由若干程序模块组成，每一模块对应一条系统调用，用户发出系统调用时，控制即转入相应的模块
>*   文件目录系统：
>    *   文件目录系统的主要功能是管理文件目录，其任务有管理活跃文件目录表、管理读写状态信息表、管理用户进程的打开文件表、管理与组织在存储设备上的文件目录结构、调用下一级存取控制模块
>*   存取控制模块：
>    *   实现文件保护主要由该级软件完成，它把用户的访问要求与FCB中指示的访问控制权限进行比较，以确认访问的合法性
>*   逻辑文件系统和文件信息缓冲区
>    *   逻辑文件系统与文件信息缓冲区的主要功能是根据文件的逻辑结构将用户要读写的逻辑记录转换成文件逻辑结构内相应块号
>*   物理文件系统：
>    *   物理文件系统的主要功能是把逻辑记录所在的相对块号转换成实际的物理地址
>*   分配模块：
>    *   分配模块的主要功能是管理辅存空间，即负责分配辅存空闲空间和回收辅存空间
>*   设备管理程序模块：
>    *   设备管理程序模块的主要功能是分配设备、分配设备读写用缓冲区、磁盘调度、启动设备、处理设备中断、释放设备读写缓冲区、释放设备等



### 文件系统布局

*   文件系统存放在磁盘上，多数磁盘划分为一个或多个分区，每个分区中有一个独立的文件系统
*   **文件系统在磁盘中的布局：**
*   文件系统中可能包含：启动存储在那里的操作系统的方式，总的块数，空闲块的数量和位置，目录结构以及各个具体文件

![img](/Users/coffeeboy/Desktop/考研/assets/15.png)

*   **主引导记录(Master Boot Record,MBR)：**
    *   位于磁盘的0号扇区，用来**引导计算机**，MBR后面的是分区表
    *   分区表：给出每个分区的起始和结束地址
    *   分区表中的一个分区被标记为活动分区，当计算机启动时，BIOS读入并执行MBR
    *   MBR做的第一件事就是**确定活动分区，读入它的第一块，即引导块**
*   **引导块(boot block)：**
    *   MBR执行引导块中的程序后，该程序负责**启动该分区中的操作系统**
    *   每个分区都从一个引导块开始，即使该分区中不包含一个可启动的操作系统，也不排除以后会在该分区安装一个操作系统，Windows系统称之为**分区引导扇区**
    *   除了都是从引导块开始，磁盘分区的其他布局都是随着文件系统的不同而变化的
*   **超级块(super block)：**
    *   包含文件系统的所有关键信息
    *   在计算机启动时，或者在该文件系统首次使用时，超级块会被读入内存
    *   超级块中的典型信息包含：分区的块的数量，块的大小，空闲块的数量和指针，空闲的FCB数量，FCB指针
*   **文件系统中空闲块的信息：**
    *   用位示图或指针链接的形式给出
    *   后面也许会跟一组i结点，每个文件对应一个结点，i结点说明了文件的一切
    *   接着可能是根目录，存放文件系统目录树的根部
    *   最后，磁盘的其他部分存放了其他所有的目录和文件



*   **文件系统在内存中的结构：**
    *   内存中的信息用于管理文件系统并通过缓存来提高性能
    *   这些数据在安装文件系统时被加载，在文件系统操作期间被更新，在卸载时被丢弃
    *   这些结构的类型可能包括：
        *   内存中的安装表：包含每个已安装文件系统分区的有关信息
        *   内存中的目录结构的缓存：包含最近访问目录的信息，对安装分区的目录，还可以包括一个指向分区表的指针
        *   整个系统的打开文件表：包含每个打开文件的FCB副本及其他信息
        *   每个进程的打开文件表：包含一个指向整个系统的打开文件表中的适当条目的指针，以及其他信息
    *   **创建一个新的文件**时，应用程序调用逻辑文件系统，逻辑文件系统知道目录结构的格式，将为文件分配一个新的FCB，然后，系统将相应的目录读入内存，使用新的文件名和FCB进行更新，并将它写回磁盘
    *   文件被创建后，就能用于I/O，不过需要先**打开文件**
        *   系统调用open()将文件名传递给逻辑文件系统，调用open()首先搜索整个系统的打开文件表，来确定这个文件是否已经被其他进程使用
            *   如果已经被使用，则在单个进程的打开文件表中创建一个条目，让其指向现有整个系统的打开文件表的相应条目，该算法在一个文件已经被打开时能节省大量开销，因为只需要一个指针即可
            *   如果还未被使用
                *   根据给定的文件名来搜索目录结构，部分目录结构通常换存在内存中来加快目录检索
                *   找到文件后，将该文件的FCB复制到整个系统的打开文件表中，打开文件表中不但存储FCB，而且跟踪打开该文件的进程的数量
                *   然后，在单个进程的打开文件表中创建一个条目，并且通过指针将整个系统打开文件表的条目与其他域(文件当前位置的指针，文件访问模式)相连
    *   调用open()返回一个指向单个进程的打开文件表中的适当条目的指针，之后所有对该文件的操作都通过该指针执行，一旦文件被打开，内核就不再使用文件名来访问文件，而是使用文件描述符(Windows中成为文件句柄)
    *   **关闭一个文件时**，删除单个进程打开文件表中的相应条目，整个系统的打开文件表的文件打开数量递减，当所有打开某个文件的用户都关闭该文件时，任何更新的元数据将复制到磁盘的目录结构中，并且整个系统的打开文件表的对应条目被删除



### 外存空闲空间管理

*   包含文件系统的分区通常称为**卷(volume)**，卷可以是磁盘的一部分，也可以是整个磁盘，还可以是多个磁盘组成RAID集

*   一个卷中，存放文件数据的空间(文件区)和FCB的空间(目录区)是分离的

*   由于存在很多种类的文件表示和存放格式，所以操作系统中一般都有很多不同的文件管理模块，通过这些模块可以访问不用格式的卷中的文件

*   卷在提供文件服务前，必须由对应的文件程序进行**初始化**，划分好目录区和文件区，建立**空闲空间管理表格和存放卷信息的超级块**

*   文件存储设备分成许多大小相同的物理块，并以块为单位交换信息，所以，文件存储设备的管理实质上是对空闲块的组织和管理，包括空闲块的组织，分配，回收

*   **空闲表法：**

    *   空闲表法属于连续分配方式，与内存的动态分配方式类似，为每个文件分配一块连续的存储空间
    *   系统为外存上的所有空闲区建立一个空闲表，每个空闲区对应一个空闲表项
    *   表项中包括：表项序号，该空闲区的第一个盘块号，该区的空闲盘块数
    *   再将所有空闲区按其起始盘块号递增的次序排列，和内存分配一样可以采用**首次适应算法和最佳适应算法**来进行分配
    *   当回收时也和内存回收一样，判断是否与空闲盘块表中的前区或后区相连进行合并

*   **空闲链表法：**

    *   有两种形式：空闲盘块链，空闲盘区链
    *   **空闲盘块链：**将磁盘上的所有空闲空间以**盘块**为单位构成一条链
        *   创建文件时，系统从链首开始，依次摘下适当数目的空闲盘块分配给文件
        *   删除文件时，将回收的盘块依次插入空闲盘块链的末尾
        *   优点：分配和回收一个盘块的过程非常简单
        *   缺点：为一个文件分配盘块时可能要重复多次操作，效率低，空闲盘块链过长
    *   **空闲盘区链：**将磁盘上的所有空闲空间以**盘区**为单位构成一条链
        *   每个盘区中包含：指示下一个空闲盘区的指针，能指明本盘区大小的信息
        *   分配盘区通常采用首次适应算法
        *   回收盘区时，同样也要将回收区与相邻接的空闲盘区合并
        *   优点：效率通过较高，空闲盘区链较短
        *   缺点：分配和回收的过程比较复杂

*   **位示图法：**

    *   利用二进制的一位来表示磁盘中一个盘块的使用情况，当为“0”时表示对应的盘块空闲，当为“1”时表示已分配

        ![img](/Users/coffeeboy/Desktop/考研/assets/3082328-20230517161620678-2008178443.png)

    *   盘块的分配：

        *   顺序扫描位示图，从中找出一个或一组其值为“0”的二进制位
        *   将找到的一个或一组二进制位，转换成与之对应的盘块号，若找到的其值为“0”的二进制位位于位示图的第i行，第j列，其对应的盘块号的计算公式：$b = n(i-1)+j$
        *   修改位示图，令$map[i,j]=0$

    *   盘块的回收：

        *   将回收盘块的盘块号转换成位示图中的行号和列号，转换公式为：

            $i = (b-1)DIVn+1$

            $j = (b-1)MODn + 1$

        *   DIV为整除，只取除数

        *   MOD为取余，只取余数

        *   修改位示图，令$map[i,j]=0$

    *   空闲表法和空闲链表法都不适用于大型文件系统，因为这会使空闲表或空闲链表太大

*   **成组链接法：**

    *   UNIX系统中采用的是成组链接法

    *   用来存放一组空闲盘块号(空闲盘块的块号)的盘块称为**成组链块**

    *   把顺序的n个空闲盘块号保存在第一个成组链块中，其最后一个空闲盘块(作为成组链块)，用来保存另一组空闲盘块号，直到所有空闲盘块都链接

    *   系统只需保存指向第一个成组链块的指针

         ![输入图片说明](/Users/coffeeboy/Desktop/考研/assets/223059_867acab5_508704.png)

    *   盘块的分配：

        *   从第一个成组链块的指针开始，将其对应的盘块分配给用户，然后将指针下移一格
        *   若指针指向了成组链块的最后一个盘块(即下一个成组链块)，要将该盘块读入内存，并将指针指向新的成组链块的第一条记录，然后重复执行直到分配完毕

    *   盘块的回收：

        *   将成组链块的指针上移一格，再记入回收盘块号，当成组链块的链接数达到n时，表示已满，便将现有已记录n个空闲盘块号的成组链块号记入新回收的盘块(作为新的成组链块)

    *   表示空闲空间的位向量表或第一个成组链块，以及卷中的目录区，文件区划分信息都要存放在磁盘中，一般放在卷头的位置，在UNIX系统中称为**超级块**

    *   在对卷中的文件进行操作前，超级块需要预先读入系统空闲的主存，并且经常保存主存超级块和磁盘卷中的超级块保持一致

    *   成组链块的最后一个空闲块也能进行分配



### 虚拟文件系统

*   **虚拟文件系统VFS**为应用程序提供了文件系统操作的统一接口，屏蔽了不同文件系统的差异和操作细节
*   用户程序通过VFS提供的统一调用函数(open,read)来操作不同文件系统的文件，而无须考虑具体的文件系统和实际的存储介质
*   虚拟文件系统采用面向对象的思想，抽象出一个通用的文件系统模型，定义了通用文件系统都支持的接口
*   新的文件系统只要支持并实现这些接口，即可安装和使用
*   如LInux中调用write()，在VFS中通过sys_write()函数处理，sys_write()找到具体的文件系统，将控制权交给该文件系统，最后由具体文件系统与物理介质交互并写入数据

![img](/Users/coffeeboy/Desktop/考研/assets/2002319-20210120233732775-1399948417.png)

*   为了实现VFS，Linux主要抽象了四种对象类型，每个VFS对象都存放在一个适当的数据结构中，其中包括**对象的属性和指向对象方法(函数)表的指针**

    *   **超级块对象：**表示一个已安装(或挂载)的特定文件系统
    *   **索引结点对象：**表示一个特定的文件
    *   **目录项对象：**表示一个特定的目录项
    *   **文件对象：**表示一个与进程相关的已打开文件

*   Linux将目录当作文件对象来处理，文件操作能同时应用于文件或目录

*   Linux中各对象的具体内容：

    *   超级块对象：
        *   对应于磁盘上特定扇区的文件系统超级块，用于存储已安装文件系统的元信息
        *   **元信息：**包含文件系统的基本属性信息，如文件系统类型，文件系统基本块的大小，文件系统所挂载的设备，操作方法(函数)指针
        *   其中操作方法指针指向该**超级块的操作方法表**，包含一系列可在超级块对象上调用的操作函数，主要有分配inode，销毁inode，读inode，写inode，文件同步等
    *   索引结点对象：
        *   索引结点中存储文件系统操作一个文件所需要的所有信息
        *   索引结点对一个文件是唯一的
        *   只有当文件被访问时，才在内存中创建索引结点对象，每个索引结点对象都会复制磁盘索引结点包含的一些数据
        *   该对象中有一个状态字段表示是否被修改，当其值为“脏”时，说明对应的磁盘索引结点必须被更新
        *   索引结点对象还提供许多操作接口，如创建新索引结点，创建硬链接，创建新目录
    *   目录项对象：
        *   由于VFS经常指向切换目录的操作，为了提高效率，引入了目录相关的概念
        *   目录项对象是一个路径名的组成部分，要么是目录名，要么是文件名
        *   目录项对象包含指向关联索引结点的指针，指向父目录的指针，指向子目录的指针
        *   目录项对象在磁盘上没有对应的数据结构，而是VFS在遍历路径时，将它们逐个解析成目录项对象
    *   文件对象：
        *   文件对象代表进程打开的一个文件
        *   可以通过open()调用打开一个文件，也可以通过close()调用关闭一个文件
        *   同一文件在内存中可能存在多个对应的文件对象，但对应的索引结点和目录项是唯一的
        *   文件对象包含：与该文件相关联的目录项对象，该文件的文件系统，文件指针，在该文件对象上调用的一系列操作函数

*   三个不同的进程打开同一个文件，其中两个进程使用同一个硬链接，每个硬链接对应一个目录项对象，这两个目录项对象指向同一个索引结点对象，这个索引结点对象标识的是超级块对象及随后的普通磁盘对象

    ![img](/Users/coffeeboy/Desktop/考研/assets/e23759ee7e051612a9246700f04232fc.jpeg)

*   VFS还有一个重要作用是**提高系统性能**，将最常使用的目录项对象放在目录项高速缓存的磁盘缓存中，来加速从文件路径名到最后一个路径分量的索引结点的转换过程

*   VFS并不是一个实际的文件系统，只存在于内存中，不存在于任何外存空间中，VFS在系统启动时建立，在系统关闭时消亡



### 分区和安装

*   一个磁盘可以划分为多个分区，每个分区都可以用于创建单独的文件系统，每个分区还可以包含不同的操作系统
*   当没有合适的文件系统时，可以使用原始磁盘，如UNIX交换空间可以使用原始磁盘格式，而不使用文件系统
*   Linux启动后，首先载入MBR，随后MBR识别活动分区，并且加载活动分区中的引导程序

![Linux文件系统的实现- 文章详情](/Users/coffeeboy/Desktop/考研/assets/250221581092754.png)

*   分区的第一块为**引导块(Boot block)**
    *   存储引导信息，有自身的格式，因为在引导时系统并未加载文件系统代码，不能解释文件系统的格式
    *   引导信息是一系列可以加载到内存中的连续块，加载到内存后从其第一条代码开始执行，引导程序便启动一个具体的操作系统
*   引导块之后是**超级块(Super block)**
    *   存储文件系统的有关信息，包括文件系统的类型，i结点的数目，数据块的数目
*   超级块之后为多个**索引结点(I nodes)**
    *   索引结点是实现文件存储的关键，每个文件对应一个索引结点，索引结点中包含多个指针，指向属于该文件的各个数据块
*   最后是**文件数据块(Data blocks)**



*   文件系统在进程使用前必须先安装，也称为**挂载**
*   Windows系统维护一个扩展的两级目录结构，用驱动器字母表示设备和卷
    *   卷具有常规树结构的目录，与驱动器号相关联，还含有指向已安装文件系统的指针
    *   操作系统先找到相应文件系统的指针，并且遍历该设备的目录结构，来查找指定的文件
    *   新版本的Windows允许文件系统安装在目录树下的任意位置，像UNIX一样
    *   在启动时，Windows操作系统自动发现所有设备，并且安装所有找到的文件系统
*   UNIX使用系统的根文件系统，由内核在引导阶段直接安装，其他文件系统要么由初始化脚本安装，要么由用户安装在**已安装文件系统的目录下**
    *   作为一个目录树，每个文件系统都拥有自己的根目录
    *   安装文件系统的这个目录称为安装点，安装就是将磁盘分区挂载到该安装点下，进入该目录就可以读取该分区的数据
    *   已安装文件系统属于安装点目录的一个子文件系统
    *   安装的实现是在目录inode的内存副本上加上一个标志，表示该目录是安装点
    *   还有一个域指向安装表的条目，表示哪个设备安装在哪里，这个条目还包括该设备的文件系统超级块的一个指针
*   UNIX本身是一个固定的目录树，只要安装就有，但是如果不给它分配存储空间，就不能对它进行操作，所有首先要给根目录分配空间，这样才能操作这个目录树



### 习题

*   **什么是文件系统？**
    *   操作系统中负责管理和存储文件信息的软件机构称为**文件管理系统**，简称**文件系统**
    *   文件系统由三部分组成：与文件管理有关的软件，被管理文件，实施文件管理所需的数据结构
*   **文件系统要完成哪些功能？**
    *   对用户而言：实现对文件的基本操作，让用户可以按名存取，组织成合适的结构，具有基本的文件共享和文件保护功能
    *   对操作系统而言：需要管理与磁盘的信息交换，完成文件逻辑结构和物理结构上的交换，组织文件在磁盘上的存放，采取好的文件排放顺序和磁盘调度方法来提升整个系统的性能

*   UNIX采用树形目录结构，文件信息存放在索引结点中，超级块是用来描述文件系统的
*   位示图方法是空闲块管理方法，用于管理磁盘空间
*   **文件的三种物理分配方式：**

|          | 访问第n条记录      | 优点                                                         | 缺点                                                         |
| -------- | ------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 连续分配 | 需访问磁盘1次      | 顺序存取时速度快，文件定长时可根据文件起始地址及记录长度进行随机访问 | 文件存储要求连续的存储空间，会产生碎片，不利于文件的动态扩充 |
| 链接分配 | 需访问磁盘n次      | 可解决外存的碎片问题，提高外存空间的利用率，动态增长较方便   | 只能按照文件的指针链顺序访问，查找效率低，指针信息存放消耗外存空间 |
| 索引分配 | m级需访问磁盘m+1次 | 可以随机访问，文件易于增删                                   | 索引表增加存储空间的开销，索引表的查找策略对文件系统效率影响较大 |

*   **文件打开的过程描述**
    *   检索目录，要求打开的文件应该是已经创建的文件，它应该登记在文件目录中，否则会出错，在检索到指定文件后，就将其磁盘iNode复制到活动iNode表中
    *   把参数mode所给出的打开方式与活动iNode中在创建文件时所记录的文件访问权限相比较，如果合法，则此次打开操作成功
    *   当打开合法时，为文件分配用户打开文件表表项和系统打开文件表表项，并为后者设置初值，通过指针建立表项与活动iNode之间的联系，再把文件描述符fd返回给调用者

*   **运行微信的流程：**
    *   双击微信图标
        *   也可以通过命令行输入命令来打开微信，当双击了微信图标之后，就告诉了操作系统，希望你帮我运行微信
    *   操作系统收到请求，去磁盘上找微信程序相关的信息，检测它的类型是不是可执行文件，同时通过程序首部信息确定代码和数据在可执行文件中的位置并且计算出对应的磁盘块地址
        *   对于Windows，可执行文件是PE(Portable Executable)，对于Linux，可执行文件是ELF(Executable and Linkable Format)，对于MAC，可执行文件是Mach-O(Mach Object)
    *   操作系统再创建一个进程，将微信的可执行文件映射到该进程结构，
    *   操作系统为微信程序设置CPU上下文环境，开始进行进程调度
    *   接下来执行微信的第一条指令
        *   发生缺页异常，将控制权交给操作系统
    *   操作系统分配一页物理内存，同时将代码从磁盘读入内存，然后继续执行微信程序，如果程序很大，那么反复讲页读入内存
    *   之后，微信程序执行相关函数(系统调用)，在显示器上显示微信图标
    *   操作系统接收到这个请求,然后找到显示设备,通常显示设备是由一个进程控制的,所以操作系统将要显示的「微信」图标给该进程
    *   控制设备的进程告诉设备的窗口系统它要显示「微信」图标,窗口系统在确定这是一个合法的操作之后,会将「微信」图标转换成像素,将像素写入设备的存储映像区
    *   视频硬件将像素转换成显示器可以接收的一组控制数据信号
    *   显示器解释数据信号,激发液晶屏



![文件管理](/Users/coffeeboy/Desktop/考研/assets/文件管理.png)



# I/O管理

## 概述

### I/O设备

#### I/O设备的分类

*   按**信息交换的单位**分类，I/O设备可分为：
    *   **块设备：**信息交换以数据块为单位，属于有结构设备，如磁盘等
        *   磁盘设备的基本特征是传输速率较高，可寻址，即可随机读/写任意一块
    *   **字符设备：**信息交换以字符为单位，属于无结构设备，如交互式终端机，打印机等
        *   基本特征是传输速率低，不可寻址，并且时常采用中断I/O方式
*   按**传输速率**分类，I/O设备可分为：
    *   **低速设备：**传输速率仅为每秒几个字节到数百字节的一类设备，如键盘，鼠标等
    *   **中速设备：**传输速率为每秒数千字节到数万字节的一类设备，如激光打印机等
    *   **高速设备：**传输速率在数百千字节到千兆字节的一类设备，如磁盘机，光盘机等



#### I/O接口

*   I/O接口(设备控制器)位于CPU与设备之间，既要与CPU通信，又要与设备通信，还要具有按CPU发来的命令去控制设备工作的功能
*   I/O接口主要由三部分组成：
    *   **设备控制器与CPU的接口：**该接口有三类信号线：数据线，地址线，控制线
        *   数据线通常与两类寄存器相连：数据寄存器，控制/状态寄存器
        *   数据寄存器：存放从设备送来的输入数据或从CPU送来的输出数据
        *   控制/状态寄存器：存放从CPU送来的控制信息或设备的状态信息
    *   **设备控制器与设备的接口：**一个设备控制器可以连接一个或多个设备，因此控制器中有一个或多个设备接口
        *   每个设备接口中都存在数据，控制和状态三种类型的信号
    *   **I/O逻辑：**用于实现对设备的控制，通过一组控制线与CPU交互，对从CPU收到的I/O命令进行译码
        *   CPU启动设备时，将启动命令发送给控制器，同时通过地址线把地址发送给控制器，由控制器的I/O逻辑对地址进行译码，并相应地对所选设备进行控制

![os_25](/Users/coffeeboy/Desktop/考研/assets/os_25.jpg)

*   设备控制器的主要功能：
    *   接收和识别CPU发来的命令，如磁盘控制器能接收读，写，查找等命令
    *   数据交换，包括设备和控制器之间的数据传输，以及控制器和主存之间的数据传输
    *   标识和报告设备的状态，以供CPU处理
    *   地址识别
    *   数据缓冲
    *   差错控制



#### I/O端口

*   **I/O端口**是指设备控制器中可被CPU直接访问的寄存器，主要有以下三种：
    *   **数据寄存器：**实现CPU和外存之间的数据缓冲
    *   **状态寄存器：**获取执行结果和设备的状态信息，来让CPU知道是否准备好
    *   **控制寄存器：**由CPU写入，以便启动命令或更改设备模式
*   为了实现CPU与I/O端口进行通信，有两种方法：
    *   **独立编址：**为每个端口分配一个I/O端口号，所有I/O端口形成I/O端口空间，普通用户程序不能对其进行访问，只有操作系统使用特殊的I/O指令才能访问端口
    *   **统一编址：**又称**内存映射I/O**，每个端口被分配唯一的内存地址，且不会有内存被分配这一地址，通常分配给端口的地址靠近地址空间的顶端



### I/O控制方式

*   设备管理的主要任务之一就是控制设备和内存或CPU之间的数据传送

*   外围设备和内存之间的输入/输出控制方式有4种：

    ![img](/Users/coffeeboy/Desktop/考研/assets/format,png.png)

    *   **程序直接控制方式：**

        *   计算机从外部设备读取的每个字，CPU需要对外设状态进行循环检查，直到确定该字已经在I/O控制器的数据寄存器中
        *   由于CPU的高速性和I/O设备的低速性，导致CPU绝大部分时间都处于等待I/O设备完成数据I/O的循环测试中，造成了CPU资源的极大浪费
        *   简单，易于实现，但是CPU和I/O设备只能串行工作，导致CPU的利用率相当低

    *   **中断驱动方式：**

        *   允许I/O设备主动打断CPU的运行并请求服务，从而释放CPU，使其向I/O控制器发送读命令后可以继续做其他有用的工作
        *   从I/O控制器的角度来看：
            *   I/O控制器从CPU接收一个读命令，然后从外部设备读数据
            *   一旦数据读入I/O控制器的数据寄存器，便通过控制线给CPU发出中断信号，表示数据已准备好，然后等待CPU请求数据
            *   I/O控制器收到CPU发出的取数据请求后，将数据放到数据总线上，传到CPU的寄存器中
        *   从CPU的角度来看：
            *   CPU发出读命令，保存当前运行程序的上下文(包括程序计数器和处理机寄存器)，转而执行其他程序
            *   在每个指令周期的末尾，CPU检查中断
            *   当有来自I/O控制器的中断时，CPU保存当前正在运行程序的上下文，转而去执行中断处理程序来处理该中断
            *   CPU从I/O控制器读一个字的数据传送到寄存器，并存入主存
            *   CPU恢复发出I/O命令的程序的上下文，然后继续执行
        *   中断驱动方式比程序直接控制方式有效，但由于数据中的每个字在存储器与I/O控制器之间的传输都必须通过CPU，导致了中断驱动方式会消耗较多的CPU时间

    *   **DMA方式：**

        *   中断驱动方式中，I/O设备与内存之间的数据交换必须经过CPU中的寄存器，所以速度受限，而DMA(直接存储器存取)方式的基本思想是在I/O设备和内存之间开辟直接的数据交换通路，不经过CPU

        *   DMA方式的特点：

            *   基本单位是数据块
            *   所传送的数据，是从设备直接送入内存的，或者相反
            *   仅在传送一个或多个数据块的开始和结束时，才需CPU干预，整块数据的传送是在DMA控制器的控制下完成的

        *   DMA控制器的组成：

            ![OS(十八)：设备管理之I/O控制方式- 无虑的小猪- 博客园](/Users/coffeeboy/Desktop/考研/assets/1680081-20230823172213082-88123805.png)

            

        *   DMA控制器中有4类寄存器：

            *   **命令/状态寄存器(CR)：**接收从CPU发来的I/O命令，有关控制信息，或设备的状态
            *   **内存地址寄存器(MAR)：**在输入时，它存放把数据从设备传送到内存的起始目标地址，在输出时，它存放由内存到设备的内存源地址
            *   **数据寄存器(DR)：**暂存从设备到内存或从内存到设备的数据
            *   **数据计数器(DC)：**存放本次要传送的字(节)数

        *   DMA方式的工作过程：

            *   CPU接收到I/O设备的DMA请求时，给DMA控制器发出一条命令，同时设置MAR和DC初值，启动DMA控制器，然后继续其他工作
            *   之后CPU就把控制操作委托给DMA控制器，由该控制器负责处理
            *   DMA控制器直接与存储器交互，传送整个数据块，每次传送一个字，这个过程不需要CPU的参与
            *   传送完成后，DMA控制器发送一个中断信号给处理器

        *   只有在传送开始和结束的时候才需要CPU的参与

        *   DMA方式与中断方式的主要区别是：中断方式在每个数据需要传输时中断CPU，而DMA方式则是在所要求传送的一批数据全部传送结束时才中断CPU，而且，中断方式的数据传送是在中断处理时由CPU控制完成的，而DMA方式则是在DMA控制器的控制下完成的

    *   **通道控制方式：**

        *   I/O通道指专门负责输入/输出的处理机，I/O通道方式是DMA方式的发展，可进一步减少CPU的干预，即把对**一个数据块的读或写**为单位的干预，转化为对**一组数据块的读或写及有关控制和管理**为单位的干预
        *   可以实现CPU，通道，I/O设备三者的并行操作，从而更有效地提高整个系统的资源利用率
        *   工作流程：
            *   当CPU要完成一组相关的读或写操作及有关控制时，只需向I/O通道发送一条I/O指令，来给出其所要执行的通道程序的首地址和要访问的I/O设备
            *   通道接到该指令后，执行通道程序便可完成CPU指定的I/O任务，数据传送结束时向CPU发送中断请求
        *   I/O通道与一般处理机的区别：通道指令的类型单一，没有自己的内存，通道所执行的通道程序是放在主机的内存中的，也就是说通道与CPU共享内存
        *   I/O通道与DMA方式的区别：DMA方式需要CPU来控制传输的数据块大小，传输的内存地址，而通道方式中这些信息都是由通道控制的，而且，DMA方式中，每个DMA控制器对应一台设备与内存传递数据，而一个通道可以控制多台设备与内存的数据交换



### I/O软件层次结构

*   将系统中的设备管理模块分为若干个层次，每层都是利用其下层提供的服务，完成输入/输出功能中的某些子功能，并屏蔽这些功能实现的细节，向高层提供服务
*   在层次式结构的I/O软件中，只要层次间的接口不变，对某一层次中的软件的修改就不会引起其下层或高层代码的变更
*   整个I/O软件可以视为具有4个层次的系统结构：
    *   **用户层I/O软件：**
        *   实现与用户交互的接口，用户可直接调用在用户层提供的，与I/O操作有关的库函数，对设备进行操作
        *   一般而言，大部分的I/O软件都在操作系统内部，但仍有一小部分在用户层，包括与用户程序链接在一起的库函数
        *   用户层软件必须通过一组系统调用来获取操作系统服务
    *   **设备独立性软件：**
        *   用于实现用户程序与设备驱动器的统一接口，设备命令，设备的保护及设备的分配与释放等，同时为设备管理和数据传送提供必要的存储空间
        *   设备独立性也称设备无关性，使得应用程序独立于具体使用的物理设备，为实现设备独立性而引入**逻辑设备和物理设备**
        *   使用逻辑设备名来请求使用某类设备，在系统实际执行时，必须将逻辑设备名映射成物理设备名使用
        *   使用逻辑设备名的好处：
            *   增加设备分配的灵活性
            *   易于实现I/O重定向，即用于I/O操作的设备可以更换，而不必改变应用程序
        *   为了实现设备独立性，必须在驱动程序的基础上设置一层**设备独立性软件**
        *   设备独立性软件的主要功能：
            *   执行所有设备的公有操作，包括：
                *   对设备的分配与回收
                *   将逻辑设备名映射为物理设备名
                *   对设备进行保护，禁止用户直接访问设备
                *   缓冲管理
                *   差错控制
                *   提供独立于设备的大小统一的逻辑块，屏蔽设备之间信息交换单位大小和传输速率的差异
            *   向用户层(或文件层)提供统一接口
                *   无论何种设备，它们向用户所提供的接口应是相同的，例如，read/write
    *   **设备驱动程序：**
        *   与硬件直接相关，负责具体实现系统对设备发出的操作指令，驱动I/O设备工作的驱动程序
        *   每类设备配置一个设备驱动程序，它是I/O进程与设备控制器之间的通信程序，通常以进程的形式存在
        *   设备驱动程序向上层用户应用程序提供一组标准接口，设备具体的差别被设备驱动程序所封装，用于接收上层软件发来的抽象I/O请求，如read/write，转换为具体要求后，发送给设备控制器，控制I/O设备工作
        *   也将由设备控制器发来的信号传送给上层软件，从而为I/O内核子系统隐藏设备控制器上的差异
    *   **中断处理程序：**
        *   用于保存被中断进程的CPU环境，转入相应的中断处理程序进行处理，处理完恢复被中断进程的现场后，返回到被中断进程
        *   中断处理层的主要任务：
            *   进行进程上下文的切换，对处理中断信号源进行测试，读取设备状态和修改进程状态
        *   中断处理与硬件紧密相连，应尽量加以屏蔽，放在操作系统的最底层
*   用户对设备的一次命令全过程：
    *   当用户要读取某设备的内容时，通过操作系统提供的read命令接口，经过了**用户层**
    *   用户发出的read命令，首先经过**设备独立层**进行解析，然后交往下层
    *   不同类型的设备对read命令的行为会有所不同，针对不同的设备，把read命令解析成不同的指令，经过了**设备驱动层**
    *   命令解析完成后，需要中断正在运行的进程，转而执行read命令，需要**中断处理程序**
    *   最后，命令真正到达硬件设备，硬件设备的控制器按照上层传达的命令操控硬件设备，完成相应的功能



### 应用程序I/O接口

*   在I/O系统与高层之间的接口中，根据设备类型的不同，又进一步分为若干接口：
*   **字符设备接口：**
    *   字符设备是指数据的存取和传输是以字符为单位的设备，如键盘，打印机等，基本特征是：传输速率低，不可寻址，并且在输入/输出时通常采用**中断驱动方式**
    *   get和put操作：由于字符设备不可寻址，只能采取顺序存取方式，通常为字符设备建立一个字符缓冲区，用户程序通过get操作从缓冲区获取字符，通过put操作将字符输出到缓冲区
    *   in-control指令：字符设备类型繁多，差异甚大，在接口中提供一种通用的in-control指令来处理(包含许多参数，每个参数表示一个与具体设备相关的特定功能)
    *   字符设备属于独占设备，为此接口中还需要提供打开和关闭操作，来实现互斥共享
*   **块设备接口：**
    *   块设备是指数据的存取和传输是以数据块为单位的设备，典型的块设备是磁盘，基本特征是：传输速率较高，可寻址，磁盘设备的I/O常采用**DMA方式**
    *   隐藏了磁盘的二维结构，二维结构中，每个扇区的地址需要用磁道号和扇区号来表示，块设备接口将磁盘的所有扇区从0-n-1依次编号，将二维结构变为一种线性序列
    *   将抽象命令映射为低层操作，块设备接口支持上层发来的对文件或设备的打开，读，写和关闭等抽象命令，该接口将上述命令映射为设备能识别等较低层的具体操作
    *   内存映射接口通过内存的字节数组来访问磁盘，而不提供读/写磁盘操作，映射文件到内存的系统调用返回包含文件副本的一个虚拟内存地址，只在需要访问内存映像时，才由虚拟存储器实际调页，内存映射文件的访问如同内存读写一样简单
*   **网络设备接口：**
    *   许多操作系统提供的网络I/O接口为网络套接字接口，套接字接口的系统调用使应用程序创建的本地套接字连接到远程应用程序创建的套接字，通过此连接发送和接收数据，使计算机能够通过网络与网络上的其他计算机进行通信或上网浏览
*   **阻塞/非阻塞I/O：**
    *   操作系统的I/O接口涉及两种模式：阻塞和非阻塞
    *   阻塞I/O是指当用户进程调用I/O操作时，进程就被阻塞，需要等待I/O操作完成，进程才被唤醒继续执行
    *   非阻塞I/O是指用户进程调用I/O操作时，不阻塞进程，该I/O调用返回一个错误返回值，通常，进程需要通过轮询的方式来查询I/O操作是否完成
    *   大多数操作系统提供的I/O接口都是采用阻塞I/O



### 习题

*   **I/O管理要完成哪些功能？**
    *   状态跟踪：要能实时掌握外部设备的状态
    *   设备存取：要实现对设备的存取操作
    *   设备分配：在多用户环境下，负责设备的分配与回收
    *   设备控制：包括设备的驱动，完成和故障的中断处理
*   共享设备是指一段时间内允许多个进程同时访问的设备
*   分配共享设备是不会引起进程死锁的
*   虚拟设备是指采用虚拟技术将一台独占设备转换为若干逻辑设备
*   引入虚拟设备是为了克服独占设备速度慢，利用率低的特点
*   每种设备对应的设备控制器都对应一组相应的控制命令，CPU通过控制命令控制设备控制器
*   设备映射表DMT中记录了逻辑设备所对应的物理设备
*   通道在收到该指令后，便从内存中取出本次要执行的通道程序，然后执行该通道程序，仅当通道完成规定的I/O任务后，才向CPU发出中断信号，因此通道用于完成内存与外设的信息交换
*   通道是一种特殊的处理器，所以属于硬件技术
*   设备的固有属性决定了设备的使用方式，设备独立性可以提高设备分配的灵活性和设备的利用率，设备安全性可以保证分配设备时不会导致永久阻塞
*   系统将数据从磁盘读到内存中的过程：
    *   初始化DMA控制器并启动磁盘
    *   从磁盘传输一块数据到内存缓冲区
    *   DMA控制器发出中断请求
    *   执行“DMA结束”中断服务程序
*   计算机系统为每台设备确定一个编号以确定区分和识别设备，这个确定的编号称为**设备的绝对号**



## 设备独立性软件

*   与设备无关的软件是I/O系统的最高层软件，它的下层是设备驱动程序，其间的界限因操作系统和设备的不同而有所差异
*   设备独立性软件包括执行所有设备公有操作的软件



### 高速缓存和缓冲区

*   **磁盘高速缓存(Disk Cache)：**

    *   操作系统中使用磁盘高速缓存技术来提高磁盘的I/O速度，对访问高速缓存要比访问原始磁盘数据更为高效
    *   磁盘高速缓存是指利用内存中的存储空间来暂存从磁盘中读出的一系列盘块中的信息
    *   磁盘高速缓存逻辑上属于磁盘，物理上则是驻留在内存中的盘块
    *   高速缓存在内存中分为两种形式：
        *   在内存中开辟一个单独的空间作为磁盘高速缓存，大小固定
        *   把未利用地内存空间作为一个缓冲池，供请求分页系统和磁盘I/O时共享

*   **缓冲区(Buffer)：**

    *   在设备管理子系统中，引入缓冲区的目的主要如下：

        *   缓和CPU与I/O设备间速度不匹配的矛盾
        *   减少对CPU的中断频率，放宽对CPU中断响应时间的限制
        *   解决基本数据单元大小(即数据粒度)不匹配的问题
        *   提高CPU和I/O设备之间的并行性

    *   实现方法有：

        *   采用硬件缓冲器，但由于成本太高，除了一些关键部位外，一般不采用硬件缓冲器
        *   采用缓冲区(位于内存区域)

    *   根据系统设置缓冲器的个数，缓冲技术可以分为：

        *   **单缓冲：**

            *   在主存中设置一个缓冲区，当设备和处理机交换数据时，先将数据写入缓冲区，然后需要数据的设备或处理机从缓冲区取走数据，在缓冲区写入或取出的过程中，另一方需要等待

            *   假设从磁盘把一块数据输入到缓冲区的时间为**T**，操作系统将该缓冲区中的数据传送到用户区的时间为**M**，而CPU对这一块数据处理的时间为**C**

                ![单/双缓冲区花费的时间- 可爱的黑精灵- 博客园](/Users/coffeeboy/Desktop/考研/assets/1487780-20210803152224689-1089280624.png)

            *   单缓冲区处理每块数据的用时为$max(C,T)+M$

        *   **双缓冲：**

            *   在单缓冲中，CPU在传送时间M内处于空闲状态，引入双缓冲

            *   设置两个缓冲区，尝试使CPU一直处于执行状态

            *   $T>M+C:$可使块设备连续输入

                ![img](/Users/coffeeboy/Desktop/考研/assets/1487780-20210804122125407-849854101.png)

            *   $T<M+C:$可使CPU不必等待设备输入

                ![img](/Users/coffeeboy/Desktop/考研/assets/1487780-20210804123229910-1672678713.png)

            *   双缓冲区处理一块数据的用时为$max(C+M,T)$

            *   双缓冲机制提高了处理机和输入设备的并行程度

            *   对于字符设备，若采用行输入方式，可采用双缓冲使用户在输入第一行后，在CPU执行第一行中的命令的同时，用户可继续向第二缓冲区输入下一行数据

            *   若两台机器之间通信仅配置了单缓冲，为了实现双向数据传输，必须在两台机器中都设置两个缓冲区，一个用作发送缓冲区，一个用作接收缓冲区

        *   **循环缓冲：**

            *   包含多个大小相等的缓冲区，每个缓冲区中有一个链接指针指向下一个缓冲区，最后一个缓冲区指针指向第一个缓冲区，多个缓冲区构成一个环形

            *   循环缓冲用于输入/输出时，还需要两个指针in和out

            *   对输入：首先要从设备接收数据到缓冲区中，in指针指向可以输入数据到第一个空缓冲区，当运行进程需要数据时，从循环缓冲区中取一个装满数据到缓冲区，并从此缓冲区中提取数据，out指针指向可以提取数据到第一个满缓冲区

            *   输出和输入相反

                ![boost circular buffer环形缓冲类- youxin - 博客园](/Users/coffeeboy/Desktop/考研/assets/231713400365010.gif)

        *   **缓冲池：**

            *   由多个系统公用的缓冲区组成，缓冲区按其使用状况可以形成三个队列：空缓冲队列，装满输入数据的缓冲队列(输入队列)，装满输出数据的缓冲队列(输出队列)

            *   还具有四种缓冲区：用于收容输入数据的工作缓冲区，用于提取输入数据的工作缓冲区，用于收容输出数据的工作缓冲区，用于提取输出数据的工作缓冲区

                ![操作系统学习(15)IO 缓存和buffer | Echo Blog](/Users/coffeeboy/Desktop/Note/1.png)

            *   输入进程输入数据时：从**空缓冲队列**的队首摘下一个空缓冲区，把它作为收容输入工作缓冲区，然后把输入数据输入其中，装满后再将它挂到**输入队列队尾**

            *   计算进程需要输入数据时：从**输入队列**取得一个缓冲区作为提取输入工作缓冲区，计算进程从中提取数据，数据用完后再将它挂到**空缓冲队列尾**

            *   计算进程需要输出数据时，从**空缓冲队列**的队首取得一个空缓冲区，作为收容输出工作缓冲区，当其中装满输出数据后，再将它挂到**输出队列队尾**

            *   输出进程需要输出数据时，从**输出队列**中取得一个装满输出数据的缓冲区，作为提取输出工作缓冲区，当数据提取完后，再将它挂到**空缓冲队列队尾**

*   **高速缓存与缓冲区的对比**

    *   高速缓存是可以保存数据拷贝的高速存储器，访问高速缓存比访问原始数据更高效，速度更快

    |          | 相同点                       | 存放数据                                                     | 目的                                                         |
    | -------- | ---------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
    | 高速缓存 | 都介于高速设备和低速设备之间 | 存放的是低速设备上的某些数据的复制数据，即高速缓存上有的，低速设备上面必然有 | 高速缓存存放的是高速设备经常要访问的数据，若高速设备要访问的数据不再高速缓存中，则高速设备就需要访问低速设备 |
    | 缓冲区   |                              | 存放的是低速设备传递给高速设备的数据(或相反)，而这些数据在低速设备(或高速设备)却不一定有备份，这些数据再从缓冲区传送到高速设备(或低速设备) | 高速设备和低速设备的通信都要经过缓冲区，高速设备永远不会直接去访问低速设备 |

    



### 设备分配和回收

*   **设备分配**是指根据用户的I/O请求分配所需的设备
*   分配的总原则是充分发挥设备的使用效率，尽可能地让设备忙碌，又要避免由于不合理的分配方法造成进程**死锁**
*   从设备的特性来看，采用三种使用方式可分为：**独占设备，共享设备，虚拟设备**
    *   独占式使用设备，进程分配到独占设备后，便由其独占，直至该进程释放该设备
    *   分时式共享使用设备，对于共享设备，可同时分配给多个进程，通过**分时**共享使用
    *   以SPOOling方式使用外部设备，SPOOLing技术实现了虚拟设备功能，可以将设备同时分配给多个进程，这种技术实质上就是实现了对设备的I/O操作的**批处理**



#### 设备分配的数据结构

*   设备分配的数据结构有**设备控制表(DCT)，控制器控制表(COCT)，通道控制表(CHCT)，系统设备表(SDT)**

    *   设备控制表(DCT)：一个设备控制表就表示一个设备，这个表的表项就是设备的各个属性，凡是因为请求本设备而未得到满足的进程，应将其PCB按某种策略排成一个设备请求队列，设备队列的队首指针指向该请求队列的队首PCB

        ![操作系统学习笔记（13）——设备分配和虚拟设备- 从未想过的想- 博客园](/Users/coffeeboy/Desktop/考研/assets/2531609-20211211104656849-985592524.png)

    *   设备控制器控制设备和内存交换数据，而设备控制器又需要请求通道为它服务，因此每个控制器控制表COCT有一个表项存放指向相应通道控制表(CHCT)的指针，而一个通道可为多个设备控制器服务，因此CHCT必定有一个指针，指向一个表，表中记录CHCT提供服务的那几个涉笔控制器，，CHCT与COCT的关系是一对多的关系

        ![img](/Users/coffeeboy/Desktop/考研/assets/v2-a233b27ce8e429aa4084c490ee519ecf_1440w-20231227150616360.webp)

    *   系统设备表SDT：整个系统中只有一张SDT，记录已连接到系统中的所有物理设备的情况，每个物理设备占一个表目

    *   在多道程序系统中，进程数多于资源数，因此要有一套合理的分配原则，主要考虑：

        *   I/O设备的固有属性
        *   I/O设备的分配算法
        *   I/O设备分配的安全性
        *   I/O设备的独立性



#### 设备分配的策略

*   **设备分配原则：**设备分配应根据设备特性，用户要求和系统配置情况
    *   充分发挥设备的使用效率
    *   避免造成进程死锁
    *   将用户程序和具体设备隔离开
*   **设备分配的方式：**分为静态分配和动态分配
    *   静态分配：
        *   主要用于对**独占设备**的分配
        *   在**用户作业开始执行前**，由系统一次性分配该作业所要求的全部设备，控制器
        *   一旦分配，这些设备，控制器就一直为该作业所占用，直到该作业被撤销
        *   静态分配方式不会出现死锁，设备的使用效率低
    *   动态分配：
        *   在**进程执行过程中**根据执行需要进行
        *   当进程需要设备时，通过**系统调用**命令向系统提出设备请求，由系统按某种策略给进程分配所需要的设备，控制器，使用完后就立即释放
        *   动态分配有利于提高设备利用率，但若分配算法使用不当，则有可能造成**进程死锁**
*   **设备分配算法：**常见的动态分配算法有**先请求先分配，优先级高者优先**
*   对于独占设备，既可以采用动态分配方式，也可以采用静态分配方式，但往往采用静态分配方式
*   共享设备可被多个进程所共享，一般采用动态分配方式，但在每个I/O传输的单位时间内只被一个进程所占用，通常采用先请求先分配和优先级高者优先的分配算法



#### 设备分配的安全性

*   设备分配的安全性：指设备分配中应防止发生进程阻塞
*   **安全分配方式：**每当进程发出I/O请求后便进入阻塞态，直到其I/O操作完成时才被唤醒，一旦进程已经获得某种设备后便阻塞，不能再请求任何资源，而在它阻塞时也不保持任何资源，优点是设备分配安全，缺点是**CPU和I/O设备是串行工作的**
*   **不安全分配方式：**进程在发出I/O请求后仍继续运行，需要时发出第二个，第三个，仅当进程所请求的设备已被另一进程占用时，才进入阻塞态， 优点是一个进程可同时操作多个设备，使进程推进迅速，缺点是可能**导致死锁**



#### 设备映射

*   为了提高设备分配的灵活性和设备的利用率，方便实现I/O重定向，引入设备独立性
*   设备独立性是指**应用程序独立于具体使用的物理设备**
*   为了实现设备独立性，在应用程序中使用**逻辑设备名**来请求使用某类设备，在系统中设置一张**逻辑设备表(Logical Unit Table,LUT)**
*   LUT用于将逻辑设备名映射为物理设备名，LUT表项中包括逻辑设备名，物理设备名，设备驱动程序入口地址
*   当进程用逻辑设备名来请求分配设备时，系统为它分配一台相应的物理设备，并在LUT中建立一个表目，当之后进程再利用该逻辑设备名请求I/O操作时，系统通过查找LUT来寻找对应的物理设备和驱动程序
*   系统中可采取两种方式设置逻辑设备表：
    *   在整个系统中只设置一张LUT，所有进程的设备分配情况都记录在同一张LUT中，因此不允许LUT中具有相同的逻辑设备名，主要适用于单用户系统
    *   为每个用户设置一张LUT，每当用户登录时，系统便为该用户建立一个进程，同时也建立一张LUT，并将该表放入进程的PCB中



### SPOOLing技术(假脱机技术)

*   为了缓和CPU的高速性与I/O设备低速性之间的矛盾，引入**脱机输入/输出技术**，是操作系统中采用的一项将**独占设备**改造成**共享设备**的技术

*   该技术利用专门的**外围控制机**，将低速I/O设备上的数据传送到高速磁盘上，或者相反

*   SPOOLing系统的组成：

    *   **输入井和输出井：**
        *   在磁盘上开辟出的两个存储区域
        *   输入井模拟脱机输入时的磁盘，用于收容I/O设备输入的数据
        *   输出井模拟脱机输出时的磁盘，用于收容用户程序的输出数据
        *   一个进程的输入(或输出)数据保存为一个文件，所有进程的数据输入(或输出)文件链接成一个输入(或输出)队列
    *   **输入缓冲区和输出缓冲区：**
        *   在内存中开辟的两个缓冲区
        *   输入缓冲区用于暂存由输入设备送来的数据，以后再传送到输入井
        *   输出缓冲区用于暂存从输出井送来的数据，以后再传送到输出设备
    *   **输入进程和输出进程：**
        *   输入/输出进程用于模拟脱机输入/输出时的外围控制机
        *   用户要求的数据从输入设备经过输入缓冲区送到输入井，当CPU需要输入数据时，直接从输入井读入内存
        *   用户要求输出的数据先从内存送到输出井，待输出设备空闲时，再将输出井中的数据经过输出缓冲区送到输出设备

    ![假脱机技术_脱机_04](/Users/coffeeboy/Desktop/考研/assets/resize,m_fixed,w_1184-3664555.)

*   共享打印机是使用SPOOLing技术的实例：

    *   当用户进程请求打印输出时，SPOOLing系统同意打印，但不真正立即把打印机分配给该进程，而由假脱机管理进程完成两任务
        *   在磁盘缓冲区中为之申请一个空闲盘块，并将要打印的数据送入其中暂存
        *   为用户进程申请一张空白的用户请求打印表，并将用户的打印要求填入其中，再将该表挂到假脱机文件队列上
    *   这两项工作完成后，虽然还没有实际的打印输出，但是对于用户进程而言打印任务已经完成

*   对用户而言，系统并非立即执行真实的打印操作，而只是立即将数据输出到缓冲区，真正的打印操作是在打印机空闲且该打印任务已排在等待队列队首时进行的

*   SPOOLing系统的特点：

    *   提高了I/O的速度，将对低速I/O设备执行的I/O操作演变成对磁盘缓冲区中数据的存取，如同输入/输出一样，缓和了CPU和低速I/O设备之间的速度不匹配的矛盾
    *   将独占设备改造为共享设备，在假脱机打印机系统中，实际上并没有为任何进程分配设备
    *   实现了虚拟设备功能，对每个进程而言，它们都认为自己独占了一个设备






### 设备驱动程序接口

*   要求每个设备驱动程序与操作系统之间都有着相同或相近的接口
*   对于每种设备类型，操作系统都要定义一组驱动程序必须支持的函数
*   驱动程序中通常包含一张表格，这张表格具有针对这些函数指向驱动程序自身的指针
*   装在驱动程序时，操作系统记录这个函数指针表的地址，当操作系统需要调用一个函数时，可以通过这张表格发出间接调用
*   这个函数指针表定义了驱动程序与操作系统其余部分之间的接口，给定类型的所有设备都必须服从这一要求
*   在UNIX/Windows中，设备是作为命令对象出现在文件系统中的，因此针对文件的常规保护规则也适用于I/O设备，系统管理员可以为每个设备设置适当的访问权限



### 习题

*   **什么是设备的独立性？引入设备的独立性有什么好处？**
    *   设备独立性是指：用户在编程序时使用的设备和实际设备无关，一个程序应独立于分配给它的某类设备的具体设备，即在用户程序中只指明I/O使用的设备类型即可
    *   设备独立性有以下优点：方便用户编程，使程序运行不受具体机器环境的限制，便于程序移植
*   在鼠标移动时，若有高优先级的操作产生，为了记录鼠标活动的情况，必须使用缓冲技术
*   由于磁盘驱动器和目标或源I/O设备间的吞吐量不同，必须采用缓冲技术
*   为了能使数据从用户作业空间传送到磁盘或从磁盘传送到用户作业空间，必须采用缓冲技术
*   为了便于多幅图形的存取及提高性能，可以采用缓冲技术，在显示当前一幅图形又要得到下一幅图形时，应采用双缓冲技术
*   SPOOLing系统主要包括三部分：输入井和输出井，输入缓冲区和输出缓冲区，输入进程和输出进程，由预输入程序，井管理程序，缓输出程序管理
*   构成SPOOLing系统的基本条件是不仅要有大容量，高速度的外存作为输入井和输出井，而且还要有SPOOLing软件
*   双缓冲区技术中，不存在等待磁盘块从缓冲区读入用户区的问题
*   重排I/O请求次序也就是进程I/O调度，使进程之间公平地共享磁盘访问，减少I/O完成所需要的平均等待时间
*   缓冲区结合预读和滞后写技术对于具有重复性及阵发性的I/O进程改善磁盘I/O性能很有帮助
*   优化文件物理块的分布可以减少寻找时间与延迟时间，从而提高磁盘性能
*   从高速缓存中复制的访问比磁盘I/O的机械操作要快很多
*   设备与输入井/输出井之间数据的传送是由系统实现的
*   当操作涉及到具体的磁盘类型，一般是由设备驱动程序完成，如为磁盘读操作计算磁道，扇区与磁头，向设备寄存器写命令
*   当操作涉及到安全与权限问题，由与设备无关的操作系统完成，如检查用户是否有权使用设备
*   SPOOLing系统的一种死锁情况：
    *   当输入缓冲区和输出缓冲区共享一块磁盘
    *   有输入数据，输入进程就要将输入数据传送到输入缓冲区，有输出数据，输出进程就要将输出数据传送到输出缓冲区
    *   进程P从输入缓冲区中读取数据经过处理后将输出数据传送到输出缓冲区
    *   当输入缓冲区占满时，输出缓冲区为0，而此时进程P经过了处理要将输出数据传送到输出缓冲区，但是输出缓冲区剩余空间为0，进程P阻塞，因为输入缓冲区满，输入进程阻塞，因为输出缓冲区为0，输出进程阻塞，所以所有进程阻塞，都在等待一个事件发生
    *   **解决方法：**磁盘上输入数据的数目i+磁盘上输出数据的数目o <= 缓冲区总空间，同时 i <= max -1



## 磁盘和固态硬盘

### 磁盘

*   **磁盘(Disk)**是由表面涂有磁性物质的物理盘块，通过一个称为**磁头**的导体线圈从磁盘存取数据
*   在读/写操作期间，磁头固定，磁盘在下面高速旋转
*   磁盘盘面上的数据存储在一组同心圆中，称为**磁道**
*   每个磁道与磁头一样宽，一个盘面上有上千个磁道
*   磁道又划分为几百个扇区，每个扇区固定存储大小，一个扇区称为一个**盘块**
*   相邻磁道及相邻扇区间通过一定的间隙分隔开，来避免精度错误
*   由于扇区按固定圆心角度划分，所以密度从最外道向里道增加，磁盘的存储能力受限于**最内道的最大记录密度**
*   磁盘安装在一个**磁盘驱动器**中，由**磁头臂，用于旋转磁盘的主轴，用于数据输入/输出的电子设备**组成
*   多个盘片垂直堆叠，组成磁盘组，每个盘面对应一个磁头，所有磁头固定在一起，与磁盘中心的距离相同且一起移动
*   所有盘片上相对位置相同的磁道组成**柱面**
*   扇区是磁盘可寻址的最小单位，磁盘上能存储的物理块数目由扇区数，磁道数，磁盘面数决定
*   磁盘地址用**柱面号 · 盘面号 · 扇区号**表示
*   磁盘按不同的方式可分为：
    *   **固定头磁盘：**磁头相对于盘片的径向方向固定，每个磁道一个磁头
    *   **活动头磁盘：**磁头可移动的，磁头臂可来回伸缩定位磁道
    *   **固定盘磁盘：**磁盘永久固定在磁盘驱动器内的
    *   **可换盘磁盘：**可移动和替换的



![在这里插入图片描述](/Users/coffeeboy/Desktop/考研/assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zNzY0MTgzMg==,size_16,color_FFFFFF,t_70.png)![img](/Users/coffeeboy/Desktop/考研/assets/20191123182101621.png)





### 磁盘的管理

*   **磁盘初始化：**一个新的磁盘只是一个磁性记录材料的空白盘
    *   在磁盘可以存储数据之前，必须将它分成扇区，以便磁盘控制器能够进行读写操作，这个过程称为**低级格式化(物理格式化)**
    *   低级格式化为每个扇区使用特殊的数据结构，填充磁盘
    *   每个扇区的数据结构通常由：头部，数据区域(通常512B)，尾部组成，头部和尾部包含了一些磁盘控制器的使用信息
    *   大多数磁盘在工厂时作为制造过程的一部分就已低级格式化，这种格式化能够让制造商测试磁盘，并且初始化逻辑块号到无损磁盘扇区的映射
    *   对许多磁盘，当磁盘控制器低级格式化时，还能指定在头部和尾部之间留下多长的数据区，通常选择256或512字节
*   **分区：**
    *   在可以使用磁盘存储文件之前，操作系统还要将自己的数据结构记录在磁盘上，分为两步：
        *   将磁盘分为由一个或多个柱面组成的分区(即C盘，D盘)，每个分区的起始扇区和大小记录在**磁盘主引导记录的分区表中**
        *   对物理分区进行**逻辑格式化(创建文件系统)**，操作系统将初始的文件系统数据结构存储到磁盘上，这些数据结构包括：空闲空间，已分配的空间，一个初始为空的目录
    *   因扇区的单位太小，为了提高效率，操作系统将多个相邻的扇区组合在一起，形成**一簇(Linux中称为块)**
    *   为了更高效地管理磁盘，一族只能存放一个文件的内容，文件所占用的空间只能是簇的整数倍，如果文件大小小于一簇(甚至是0字节)，也要占用一簇的空间
*   **引导块：**
    *   计算机启动时需要运行一个初始化程序(自举程序)，它初始化CPU，寄存器，设备控制器，内存，接着启动操作系统
    *   自举程序找到磁盘上的操作系统内核，将它加载到内存，并转到起始地址，从而开始操作系统的运行
    *   自举程序通常存放在ROM中，为了避免改变自举代码而需要改变ROM硬件的问题，通常只在ROM中保留很小的自举装入程序，而将完整功能的引导程序保存在磁盘的启动块上，启动块位于磁盘的固定位置，具有启动分区的磁盘称为**启动磁盘/系统磁盘**
    *   引导ROM中的代码指示磁盘控制器将引导块读入内存，然后开始执行，它可以从非固定的磁盘位置加载整个操作系统，并且开始运行操作系统
    *   例如Windows的引导过程：
        *   Windows允许将磁盘分为多个分区，有一个分区为**引导分区**，包含操作系统和设备驱动程序
        *   Windows系统将引导代码存储在磁盘的第0号扇区，称为**主引导记录(MBR)**
        *   引导首先运行ROM中的代码，这个代码指示系统从MBR中读取引导代码
        *   除了引导代码，MBR还包含：一个磁盘分区表，一个标志(来指示从哪个分区引导系统)
        *   当系统找到引导分区时，读取分区的第一个扇区，称为引导扇区，并继续余下的引导过程，包括加载各种系统服务
*   **坏块：**
    *   由于磁盘有移动部件且容错能力差，因此容易导致一个或多个扇区损坏
    *   部分磁盘甚至在出厂时就有坏块
    *   根据所用的磁盘和控制器，对坏块有多种处理方式
    *   对于简单磁盘，如采用IDE控制器的磁盘，坏块可手动处理，如MS-DOS的Format命令执行逻辑格式化时会扫描磁盘来检查坏块，坏块在FAT表上会标明，因此应用程序不会使用它们
    *   对于复杂的磁盘
        *   控制器维护磁盘内的坏块列表，这个列表在出厂低级格式化时就已初始化，并在磁盘的使用过程中不断更新
        *   低级格式化将一些块保留作为备用，操作系统看不到这些块，控制器可以采用备用块来逻辑地替代坏块，这种称为**扇区备用**
    *   对坏块地处理实质上就是用某种机制使系统不去使用坏块



### 磁盘调度算法

*   一次磁盘读写操作的时间由：**寻找(寻道)时间，旋转延迟时间，传输时间**决定
*   **寻找时间$T_s$：**活动头磁盘在读写信息前，将磁头移动到指定磁道所需要的时间，包括跨越n条磁道的时间，启动磁臂的时间s
    *   $T_s = m*n + s$
*   **旋转延迟时间$T_r$：**磁头定位到某一磁道的扇区所需要的时间，设磁盘的旋转速度为r，则
    *   $T_r = \frac{1}{2r}$
    *   对于硬盘，典型的旋转速度为5400转/分，相当于一周11.1ms，则$T_r=5.55ms$
    *   对于软盘，其旋转速度为300～600转/分，则$T_r = 50～100ms$
*   **传输时间$T_t$**：从磁盘读出或向磁盘写入数据所经历时间，这个时间取决于每次所读/写的字节数b和磁盘的旋转速度，则
    *   $T_t = \frac{b}{rN}$
    *   r为磁盘每秒的转数，N为一个磁道上的字节数
*   在磁盘存取时间中，寻道时间与磁盘调度算法相关，延迟时间和传输时间都与磁盘旋转速度有关，且为**线性相关**
*   **磁盘调度算法 ：**
    *   **先来先服务(FCFS)算法：**
        *   根据进程请求访问磁盘的先后顺序进行调度
        *   优点：具有公平性
        *   若只有少量进程需要访问，且大部分请求都是访问簇聚的文件扇区，则有望达到较好的性能
        *   若有大量进程竞争使用磁盘，则这种算法在性能上往往接近于随机调度
    *   **最短寻找时间优先(SSTF)算法：**
        *   选择调度处理的磁道是与当前磁头所在磁道距离最近的磁道，来使每次的寻找时间最短
        *   每次的寻找时间最短不代表平均的寻找时间最小，但能提供比FCFS算法更好的性能
        *   这种算法会产生“饥饿”现象
    *   **扫描(SCAN)算法/电梯调度算法：**
        *   在磁头当前移动方向上选择与当前磁头所在磁道距离最近的请求作为下一次服务的对象
        *   实际上是在最短寻找时间优先算法的基础上规定了**磁头运行的方向**
        *   该算法会到尾端而不管是否有需要
        *   该算法对最近扫描过的区域不公平，因此在访问局部性方面不如FCFS算法和SSTF算法
    *   **循环扫描(C-SCAN)算法：**
        *   在扫描算法的基础上规定磁头**单向移动**来提供服务，回返时直接快速移动到**起始端**而不服务任何请求
        *   由于SCAN算法偏向于处理那些接近最里或最外的磁道的访问请求，所以使用改进型的C-SCAN算法来避免这个问题
    *   采用SCAN算法或C-SCAN算法时，磁头总是严格地遵循从盘面的一端到另一端，这一点上可以进行改进，即**磁头移动只需要到达最远端的一个请求即可返回，不需要到达磁盘端点**，这种形式的SCAN算法和C-SCAN算法称为**LOOK调度和C-LOOK调度**
*   FCFS算法太过简单，性能较差，仅在请求队列长度接近于1时才较为理想
*   SSTF算法较为通用和自然
*   SCAN算法和C-SCAN算法在磁盘负载较大时比较占优势

|            | 优点                           | 缺点                                         |
| ---------- | ------------------------------ | -------------------------------------------- |
| FCFS算法   | 公平，简单                     | 平均寻道距离大，仅应用在磁盘I/O较少的场合    |
| SSTF算法   | 性能比FCFS算法好               | 不能保证平均寻道时间最短，可能出现“饥饿”现象 |
| SCAN算法   | 寻道性能较好，可避免”饥饿“现象 | 不利于远离磁头一端的访问请求                 |
| C-SCAN算法 | 消除了对两端磁道请求的不公平   |                                              |

*   除了减少寻找时间外，减少**延迟时间**也是提高磁盘传输效率的重要因素
*   可以对盘面扇区进行**交替编号**，对磁盘片组中的不同盘面**错位命名**
*   磁盘是连续自转设备，磁头读/写一个物理块后，需要经过短暂的处理时间才能开始读/写下一块
*   由于读取扇区的顺序是不可预测的，所以延迟时间不可避免
*   磁盘寻块时间分为：寻道时间，延迟时间，传输时间，寻道时间和延迟时间属于”找“的时间，可以通过一定的方法减少，但是传输时间是磁盘本身性质所决定的，不能通过一定的措施减少



### 固态硬盘

*   **固态硬盘(SSD)：**一种基于闪存技术的存储器，与U盘并无本质差别，只是容量更大，存取性能更好

*   一个SSD由一个或多个闪存芯片和闪存翻译层组成

*   闪存芯片替代传统旋转磁盘中的机械驱动器，而闪存翻译器将来自CPU的逻辑块读写请求翻译成对底层物理设备的读写控制信号，所以闪存翻译器相当于磁盘控制器

    ![存储器结构- 知乎](/Users/coffeeboy/Desktop/考研/assets/v2-917429960df29b0a0591dcf2ce7b9599_b.jpg)

*   一个闪存由B块组成，每块由P页组成

*   通常一页的大小是512B～4KB，每块由32～128页组成，块的大小为16KB～512KB

*   数据是以页为单位读写的，只有在一页所属的块整个被擦除后，才能写这一页

*   一旦擦除一块，块中的每页就都可以直接再写一次

*   某块进行若干次重复写后，就会磨损坏，不能再使用

*   随机写很慢：

    *   擦除块比较慢，通常比访问页高一个数量级
    *   如果写操作试图修改包含已有数据的页，那么这个块中所有的包含有用数据的页都必须复制到一个新(擦除过的)块中，然后才能进行对该页的写操作

*   SSD的优点：

    *   由半导体存储器构成，没有移动的部件，因而随机访问速度比机械磁盘要快的多
    *   没有任何机械噪声和震动，能耗更低，抗震性好，安全性高

*   **磨损均衡：**

    *   SSD的擦写寿命是有限的，一般是几百次到几千次
    *   为了弥补SSD的寿命缺陷，引入磨损均衡：
        *   动态磨损均衡：写入数据时，自动选择较新的闪存块，老的闪存块先不进行操作
        *   静态磨损均衡：这种技术较为先进，就算没有数据写入，SSD也会监测并自动进行数据分配，让老的闪存块承担无须写数据的存储任务，同时让较新的闪存块腾出空间，平常的读写操作在较新的闪存块中进行



### 习题

*   顺序访问按从前到后的顺序对数据进行读写操作，如磁带
*   直接访问或随机访问，则可以按任意的次序对数据进行读写操作，如光盘，磁盘，U盘等
*   文件以块为单位存放于磁盘中，文件的读写也以块为单位
*   操作系统的引导程序位于磁盘活动分区的引导扇区，因此必然产生在分区之后
*   分区是将磁盘分为由一个或多个柱面组成的分区(即C盘，D盘等形式)，每个分区的起始扇区和大小都记录在磁盘主引导记录的分区表中
*   对于高级格式化(创建文件系统)，操作系统将初始的文件系统数据结构存储到磁盘上
*   硬盘的操作系统引导扇区产生在对硬盘进行高级格式化的时候
*   旋转延迟的大小取决于磁盘空闲空间的分配程序
*   旋转延迟的大小与文件的物理结构有关
*   SSD的写速度慢于读速度，但不至于比常规机械硬盘差
*   传统机械硬盘转速很快，连续存取比随机存取快的多，因此SSD的优势主要体现在随机存取的速度上
*   低级格式化为磁盘的每个扇区采用特别的数据结构，包括检验码
*   位了磁盘存储文件，操作系统需要将自己的数据结构记录在磁盘上，分为两步：
    *   将磁盘分为由一个或多个柱面组成的分区，每个分区可以作为一个独立的磁盘
    *   在分区之后，进行逻辑格式化/高级格式化(创建文件系统)，操作系统将初始的文件系统数据结构存储到磁盘上，这些数据结构包括空闲和已分配到空间及一个初始为空的目录
*   在读磁盘的过程中，磁头旋转读取一个扇区后要对数据进行处理，在对数据进行处理的过程中，磁头仍然在转，所以扇区编号采用差错编号
*   Flash半导体存储器如U盘，固态磁盘，因为Flash半导体存储器的物理结构不需要考虑寻道时间和旋转延迟，可直接按I/O请求的先后顺序服务，采用先来先服务(FCFS)调度策略更高效
*   **设备分配的过程：**
    *   **分配设备：**首先根据I/O请求中的物理设备名查找**系统设备表(SDT)**，从中找出该设备的**DCT**，再根据DCT中的**设备状态字段**，可知该设备是否正忙，
        *   若忙，便将请求I/O进程的PCB挂到设备队列上
        *   若空闲，则按照一定的算法计算设备分配的安全性，若安全则将设备分配给请求进程，否则仍将其PCB挂到设备队列上
    *   **分配控制器：**系统把设备分配给请求I/O的进程后，再到其**DCT**中找出与该设备连接到控制器的**COCT**，从COCT中的状态字段中可知该控制器是否忙碌
        *   若忙，则将请求I/O进程的PCB挂到该控制器的等待队列上
        *   若空闲，则将控制器分配给进程
    *   **分配通道：**在该COCT中又可找到与该控制器连接的**通道的CHCT**，再根据CHCT内的状态信息，可知该通道是否忙碌
        *   若忙，则将请求I/O的进程挂到该通道的等待队列上
        *   若空闲，则将该通道分配给进程
    *   只有上述三者都分配成功时，这次设备的分配才算成功，然后便可启动该I/O设备进行数据传送
*   为使独占设备的分配具有更强的灵活性，提高分配的成功率，还可从以下两方面对基本的设备分配程序加以改进：
    *   **增加设备的独立性：**进程使用**逻辑设备名请求I/O**，这样，系统首先从SDT中找出第一个该类设备的DCT
        *   若该设备忙，则又查找第二个该类设备的DCT，仅当所有该类设备都忙时，才把进程挂到该类设备的等待队列上，只要有一个该类设备可用，系统便进一步计算分配该设备的安全性
    *   **考虑多通道情况：**采用多通路的I/O系统结构，对控制器和通道的分配同样经过多次重复直到没有一个控制器或通道可用
*   **提高磁盘I/O速度的方法：**
    *   提前读：在读磁盘当前块时，把下一个磁盘块也读入内存缓冲区
    *   延迟写：仅在缓冲区首部设置延迟写标志，然后释放此缓冲区并将其链入空闲缓冲区链表的尾部，当其他进程申请到此缓冲区时，才真正把缓冲区信息写入磁盘块
    *   虚拟盘：是指用内存空间去仿真磁盘，又叫RAM盘，虚拟盘是一种**易失性存储器**，虚拟盘常用于存放临时文件



![I_O管理 (1)](/Users/coffeeboy/Desktop/考研/assets/I_O管理 (1).png)
